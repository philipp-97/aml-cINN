{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Invertible Neural Networks (cINNs) on BrainScaleS-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Callable, Union\n",
    "\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.optim\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter, UninitializedParameter\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import hxtorch\n",
    "import _hxtorch\n",
    "import hxtorch.nn as hxnn\n",
    "\n",
    "import FrEIA.framework as Ff\n",
    "import FrEIA.modules as Fm\n",
    "\n",
    "import quantized_cINN.common as com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Generate toy dataset\n",
    "\n",
    "In order to prove the functioning of the implemented cINN with the limitations accompanying the use of BrainScaleS-2, an example dataset as easy as possible is needed. Here, we generate pictures with the size of four pixels, of which one is light and the other three are dark. The respective label indicates the position of the light pixel. The goal of this exercise is for the network to generate similar pictures having the light pixel in the correct place given a conditional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, n_samples=100000, img_size=(2, 2), transform=None):\n",
    "        self.n_samples = n_samples\n",
    "        self.img_size = img_size\n",
    "        self.transform = transform\n",
    "        self.data, self.targets = self._generate_data()\n",
    "\n",
    "    def _generate_data(self):\n",
    "        floor = 0.2\n",
    "        intensity = (0, 1)\n",
    "\n",
    "        high = self.img_size[0] * self.img_size[1]\n",
    "        labels = torch.randint(low=0, high=high, size=(self.n_samples, ))\n",
    "        imgs = floor * torch.rand((self.n_samples, 1, *self.img_size))\n",
    "        imgs[torch.arange(self.n_samples), :, labels%2, labels//2] += intensity[1] - floor \n",
    "        return imgs, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "    \n",
    "        X = self.data[idx].numpy()\n",
    "        y = self.targets[idx].reshape(-1).numpy()\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "        return X, y\n",
    "\n",
    "class ExampleData:\n",
    "\n",
    "    def __init__(self, config: object):\n",
    "        from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "        import torchvision.transforms as T\n",
    "\n",
    "        self.c = config\n",
    "\n",
    "        self.train_data = ExampleDataset(transform=T.ToTensor())\n",
    "        self.test_data = ExampleDataset(transform=T.ToTensor())\n",
    "\n",
    "        # Sample a fixed batch of 1024 validation examples\n",
    "        self.val_x, self.val_l = zip(*list(self.train_data[i] for i in range(1024)))\n",
    "        self.val_x = torch.stack(self.val_x, 0).to(config.device)\n",
    "        self.val_l = torch.LongTensor(self.val_l).to(config.device)\n",
    "\n",
    "        # Exclude the validation batch from the training data\n",
    "        self.train_data.data = self.train_data.data[1024:]\n",
    "        self.train_data.targets = self.train_data.targets[1024:]\n",
    "\n",
    "        ## Add the noise-augmentation to the (non-validation) training data:\n",
    "        #augm_func = lambda x: x + self.c.add_image_noise * torch.randn_like(x)\n",
    "        #self.train_data.transform = T.Compose([self.train_data.transform, augm_func])\n",
    "\n",
    "        self.train_loader = DataLoader(self.train_data,\n",
    "                                       batch_size=self.c.batch_size,\n",
    "                                       shuffle=True,\n",
    "                                       num_workers=self.c.n_workers,\n",
    "                                       pin_memory=True, drop_last=True)\n",
    "        self.test_loader = DataLoader(self.test_data,\n",
    "                                      batch_size=self.c.batch_size,\n",
    "                                      shuffle=False,\n",
    "                                      num_workers=self.c.n_workers,\n",
    "                                      pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG(com.baseCONFIG):\n",
    "    \"\"\"\n",
    "    Namspace for configuration\n",
    "    \"\"\"\n",
    "    # Data\n",
    "    data_mean = None\n",
    "    data_std = None\n",
    "    add_image_noise = None\n",
    "\n",
    "    img_size = (2, 2)\n",
    "    device = \"cpu\"\n",
    "    n_workers = 8\n",
    "\n",
    "    # Hardware simulation\n",
    "    mock = True\n",
    "\n",
    "    # Training\n",
    "    lr = 1e-3\n",
    "    batch_size = 256\n",
    "    weight_decay = 1e-5\n",
    "    gamma = 0.1\n",
    "    milestones = [20, 40]\n",
    "    betas = (0.9, 0.999)\n",
    "\n",
    "    n_epochs = 20\n",
    "\n",
    "    init_scale = 0.03\n",
    "    pre_low_lr = 0\n",
    "    \n",
    "    clip_grad_norm = 100.0\n",
    "\n",
    "    # Architecture\n",
    "    n_blocks = 8\n",
    "    internal_width = 16\n",
    "    clamping = 1.\n",
    "    fc_dropout = 0.0\n",
    "\n",
    "    # Logging/preview\n",
    "    loss_names = ['L']\n",
    "    preview_upscale = 3                         # Scale up the images for preview\n",
    "    sampling_temperature = 0.8                  # Sample at a reduced temperature for the preview\n",
    "    progress_bar = True                         # Show a progress bar of each epoch\n",
    "    eval_steps_interploation = 12\n",
    "    eval_seeds_interpolation  = (51, 89)\n",
    "\n",
    "    # Validation\n",
    "    pca_weights = [\n",
    "        [(0,0.55)],\n",
    "        [(1,0.1), (3, 0.4), (4, 0.5)],\n",
    "        [(2,0.33), (3, 0.33), (1, -0.33)]]\n",
    "    pca_gridsize = 10\n",
    "    pca_extent = 8.\n",
    "\n",
    "\n",
    "    # Paths\n",
    "    mnist_data = \"../mnist_data\"\n",
    "    save_dir = \"out/hx_mock/\"\n",
    "\n",
    "    load_file = \"out/hx_mock/hx_mock_example_checkpoint.pt\"\n",
    "    filename = \"out/hx_mock/hx_mock_example_cinn.pt\"\n",
    "    \n",
    "    loss_means_filename = save_dir + \"/val_losses_means.txt\"\n",
    "    loss_filename = save_dir + \"/val_losse.txt\"\n",
    "\n",
    "    # Checkpoints\n",
    "    checkpoint_save_interval =  50\n",
    "    checkpoint_save_overwrite = True\n",
    "    checkpoint_on_error = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "### Modules \n",
    "\n",
    "The input and output of the hardware needs to be approriately scaled, since its range is limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "class LinearScaling(nn.Module):\n",
    "\n",
    "    def __init__(self, weight: float=1., bias: float=0.,\n",
    "                 outrange=None, device=None, dtype=None):\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super(LinearScaling, self).__init__()\n",
    "\n",
    "        self.weight = Parameter(torch.tensor(weight), requires_grad=True)\n",
    "        self.bias = Parameter(torch.tensor(bias), requires_grad=True)\n",
    "        self.outrange = outrange\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * self.weight + self.bias\n",
    "        if self.outrange:\n",
    "            x = x.clamp(*self.outrange)\n",
    "        return x\n",
    "\n",
    "class MinMaxScaling(nn.Module):\n",
    "\n",
    "    def __init__(self, outrange, per_feature=False, size=None):\n",
    "        #assert (per_feature and not size) \"If you want per_feature \"\n",
    "        super(MinMaxScaling, self).__init__()\n",
    "        if size:\n",
    "            self.weight = torch.ones(size)\n",
    "            self.bias = torch.zeros(size)\n",
    "            self.per_feature = per_feature\n",
    "        else:\n",
    "            self.weight = torch.ones(1)\n",
    "            self.bias = torch.zeros(1)\n",
    "            self.per_feature = False\n",
    "        #self.register_parameter(\"factor__\", None)\n",
    "        #self.register_parameter(\"bias__\", None)\n",
    "\n",
    "        self.outrange = outrange\n",
    "        self.in_min = None\n",
    "        self.in_max = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            if self.per_feature:\n",
    "                self.in_min = torch.min(x, axis=0)[0]\n",
    "                self.in_max = torch.max(x, axis=0)[0]\n",
    "            else:\n",
    "                self.in_min = torch.tensor([torch.min(x)])\n",
    "                self.in_max = torch.tensor([torch.max(x)])\n",
    "\n",
    "        _norm = self.in_max - self.in_min\n",
    "        self.weight = (self.outrange[1] - self.outrange[0]) / _norm\n",
    "        self.bias = self.outrange[1] - self.weight * self.in_max\n",
    "        return self.weight * x + self.bias     \n",
    "        \n",
    "        \n",
    "class Scale(nn.Module):\n",
    "    def __init__(self, scale=1):\n",
    "        super(Scale, self).__init__()\n",
    "        self.scale = scale\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x * self.scale\n",
    "        return x\n",
    "    \n",
    "class DynamicScaling(nn.Module):\n",
    "    r\"\"\"Applies a linear scaling to the incoming data: :math:`y = x*w + b`\n",
    "    This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
    "    Args:\n",
    "        features: size of each output sample\n",
    "        bias: If set to ``False``, the layer will not learn an additive bias.\n",
    "            Default: ``True``\n",
    "    Shape:\n",
    "        - Input: :math:`(N, *, H)` where :math:`*` means any number of\n",
    "          additional dimensions and :math:`H = \\text{features}`.\n",
    "        - Output: :math:`(N, *, H)`.\n",
    "    Attributes:\n",
    "        weight: the learnable weights of the module of shape\n",
    "            :math:`(\\text{features})`. The values are\n",
    "            initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n",
    "            :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
    "        bias:   the learnable bias of the module of shape :math:`(\\text{features})`.\n",
    "                If :attr:`bias` is ``True``, the values are initialized from\n",
    "                :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
    "                :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
    "    \"\"\"\n",
    "    __constants__ = ['features']\n",
    "    features: int\n",
    "    weight: torch.Tensor\n",
    "\n",
    "    def __init__(self, features: int, bias: bool = True,\n",
    "                device=None, dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super(DynamicScaling, self).__init__()\n",
    "        self.features = features\n",
    "\n",
    "        self.weight = Parameter(torch.empty(features, **factory_kwargs))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty(features, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters_static()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        nn.init.kaiming_uniform_(torch.diag(self.weight), a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(torch.diag(self.weight))\n",
    "            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "            \n",
    "    def reset_parameters_static(self) -> None:\n",
    "        nn.init._no_grad_fill_(self.weight, 0.03)\n",
    "        nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return F.linear(input, torch.diag(self.weight), self.bias)\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return 'features={}, bias={}'.format(\n",
    "            self.features, self.bias is not None\n",
    "        )\n",
    "    \n",
    "class FixedRangeScaling(nn.Module):\n",
    "    r\"\"\"\n",
    "    \"\"\"\n",
    "    __constants__ = ['features', 'max_out']\n",
    "    per_feature: bool\n",
    "    features: int\n",
    "    max_out: int\n",
    "    weight: torch.Tensor\n",
    "\n",
    "    def __init__(self, features: int, max_out: int, per_feature: bool = False,\n",
    "                 device=None, dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super(FixedRangeScaling, self).__init__()\n",
    "        self.features = features\n",
    "        self.max_out = max_out\n",
    "        self.per_feature = per_feature\n",
    "\n",
    "        self.weight = Parameter(torch.empty(features, **factory_kwargs),\n",
    "                                requires_grad=False)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        nn.init.ones_(self.weight)\n",
    "\n",
    "    def forward(self, input_: torch.Tensor) -> torch.Tensor:\n",
    "        if self.training:\n",
    "            max_abs, _ = torch.max(torch.abs(input_), axis=0)\n",
    "            if not self.per_feature:\n",
    "                max_abs.fill_(max_abs.max())\n",
    "            max_abs[max_abs == 0.] = self.max_out\n",
    "            with torch.no_grad():\n",
    "                self.weight.data = self.max_out / max_abs\n",
    "        res = F.linear(input_, torch.diag(self.weight))\n",
    "        res[res > 0] = torch.floor(res[res > 0])\n",
    "        res[res < 0] = torch.ceil(res[res < 0])\n",
    "        return res\n",
    "            \n",
    "    def extra_repr(self) -> str:\n",
    "        return 'features={}, max_out={}, per_feature={}'.format(\n",
    "            self.features, self.max_out, self.per_feature\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EXAMPLEcINN_hx(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: object=CONFIG):\n",
    "        super().__init__()\n",
    "        #self.stop = False\n",
    "\n",
    "        self.c = config\n",
    "\n",
    "        self.cinn = self.build_inn()\n",
    "\n",
    "        self.trainable_parameters = []\n",
    "        for name, param in self.cinn.named_parameters():\n",
    "            #print(name, (name.split(\".\")[-2][-2:] == \"__\"))\n",
    "            if param.requires_grad and not (name.split(\".\")[-2][-2:] == \"__\"):\n",
    "                #print(\"accept\")\n",
    "                self.trainable_parameters.append(param)\n",
    "            continue\n",
    "\n",
    "        #for p in self.trainable_parameters:\n",
    "        #    print(p)\n",
    "        #    p.data = self.c.init_scale * torch.randn_like(p)\n",
    "\n",
    "        self.cinn.to(self.c.device)\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.trainable_parameters,\n",
    "                                          lr=self.c.lr,\n",
    "                                          weight_decay=self.c.weight_decay)\n",
    "        self.weight_scheduler = torch.optim.lr_scheduler.MultiStepLR(self.optimizer,\n",
    "                                                                #step_size=1,\n",
    "                                                                milestones=self.c.milestones,\n",
    "                                                                gamma=self.c.gamma)\n",
    "\n",
    "    def build_inn(self):\n",
    "        \n",
    "        def scale_input_total(x_in: torch.Tensor) -> torch.Tensor:\n",
    "            max_abs = torch.max(torch.abs(x_in))\n",
    "            factor = _hxtorch.constants.input_activation_max / max_abs if max_abs != 0 else 1\n",
    "            return x_in * factor\n",
    "\n",
    "        def fc_subnet(ch_in, ch_out):\n",
    "            net = OrderedDict([\n",
    "                (\"hx_input1\", FixedRangeScaling(features=ch_in,\n",
    "                                                max_out=31,\n",
    "                                                per_feature=False)),\n",
    "                (\"hx_lin_1\", hxnn.Linear(in_features=ch_in,\n",
    "                                         out_features=self.c.internal_width,\n",
    "                                         bias=False,\n",
    "                                         num_sends=2,\n",
    "                                         wait_between_events=2,\n",
    "                                         mock=self.c.mock,\n",
    "                                         signed_input=True,\n",
    "                                         )),\n",
    "                (\"relu1\", hxnn.ConvertingReLU(shift=1,\n",
    "                                              mock=self.c.mock)),\n",
    "                (\"hx_input2\", FixedRangeScaling(features=self.c.internal_width,\n",
    "                                                max_out=31,\n",
    "                                                per_feature=False)),\n",
    "                (\"hx_lin_2\", hxnn.Linear(in_features=self.c.internal_width,\n",
    "                                         out_features=ch_out,\n",
    "                                         bias=False,\n",
    "                                         num_sends=3,\n",
    "                                         wait_between_events=2,\n",
    "                                         mock=self.c.mock,\n",
    "                                         signed_input=True,\n",
    "                                         )),\n",
    "                (\"hx_output\", DynamicScaling(features=ch_out))\n",
    "            ])\n",
    "            return nn.Sequential(net)\n",
    "\n",
    "        cond = Ff.ConditionNode(4)\n",
    "\n",
    "        nodes = [Ff.InputNode(1, *self.c.img_size)]\n",
    "        nodes.append(Ff.Node(nodes[-1], Fm.Flatten, {}))\n",
    "\n",
    "        for k in range(self.c.n_blocks):\n",
    "            nodes.append(Ff.Node(nodes[-1], Fm.PermuteRandom,\n",
    "                                 {\"seed\": k}))\n",
    "            nodes.append(Ff.Node(nodes[-1], Fm.GLOWCouplingBlock,\n",
    "                                 {\"subnet_constructor\": fc_subnet,\n",
    "                                  \"clamp\": 1.},\n",
    "                                  conditions=cond))\n",
    "\n",
    "        nodes += [cond, Ff.OutputNode(nodes[-1])]\n",
    "        return Ff.ReversibleGraphNet(nodes, verbose=False)\n",
    "\n",
    "    def forward(self, x, l, jac=True):\n",
    "        return self.cinn(x, c=one_hot(l), jac=jac)\n",
    "\n",
    "    def reverse_sample(self, z, l, jac=True):\n",
    "        return self.cinn(z, c=one_hot(l), rev=True, jac=jac)\n",
    "\n",
    "    def save(self, name):\n",
    "        save_dict = {\"opt\": self.optimizer.state_dict(),\n",
    "                     \"net\": self.cinn.state_dict(),\n",
    "                     \"lr\": self.weight_scheduler.state_dict()}\n",
    "        torch.save(save_dict, name)\n",
    "\n",
    "    def load(self, name):\n",
    "        state_dicts = torch.load(name)\n",
    "        self.cinn.load_state_dict(state_dicts[\"net\"])\n",
    "        try:\n",
    "            self.optimizer.load_state_dict(state_dicts[\"opt\"])\n",
    "        except ValueError:\n",
    "            print(\"Cannot load optimizer for some reason or other\")\n",
    "        try:\n",
    "            self.weight_scheduler.load_state_dict(state_dicts[\"lr\"])\n",
    "        except ValueError:\n",
    "            print(\"Cannot load optimizer for some reason or other\")\n",
    "            \n",
    "def one_hot(labels, out=None):\n",
    "    '''\n",
    "    Convert LongTensor labels (contains labels 0-9), to a one hot vector.\n",
    "    Can be done in-place using the out-argument (faster, re-use of GPU memory)\n",
    "    '''\n",
    "    if out is None:\n",
    "        out = torch.zeros(labels.shape[0], 4).to(labels.device)\n",
    "    else:\n",
    "        out.zeros_()\n",
    "    out.scatter_(dim=1, index=labels.view(-1,1), value=1.)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000 \t00000/00386 \t0.01 \t0.302725\t0.259767\t1.00e-03\n",
      "000 \t00050/00386 \t0.08 \t-0.168324\t-0.456000\t1.00e-03\n",
      "000 \t00100/00386 \t0.15 \t-0.612051\t-0.638609\t1.00e-03\n",
      "000 \t00150/00386 \t0.22 \t-0.710921\t-0.699867\t1.00e-03\n",
      "000 \t00200/00386 \t0.29 \t-0.761237\t-0.733095\t1.00e-03\n",
      "000 \t00250/00386 \t0.36 \t-0.806850\t-0.800037\t1.00e-03\n",
      "000 \t00300/00386 \t0.42 \t-0.846039\t-0.783358\t1.00e-03\n",
      "000 \t00350/00386 \t0.49 \t-0.863312\t-0.844666\t1.00e-03\n",
      "001 \t00000/00386 \t0.54 \t-0.878027\t-0.841189\t1.00e-03\n",
      "001 \t00050/00386 \t0.61 \t-0.896206\t-0.864788\t1.00e-03\n",
      "001 \t00100/00386 \t0.68 \t-0.896564\t-0.883759\t1.00e-03\n",
      "001 \t00150/00386 \t0.75 \t-0.903395\t-0.844322\t1.00e-03\n",
      "001 \t00200/00386 \t0.81 \t-0.921366\t-0.886012\t1.00e-03\n",
      "001 \t00250/00386 \t0.88 \t-0.916233\t-0.834387\t1.00e-03\n",
      "001 \t00300/00386 \t0.94 \t-0.920377\t-0.837002\t1.00e-03\n",
      "001 \t00350/00386 \t1.01 \t-0.930367\t-0.896006\t1.00e-03\n",
      "002 \t00000/00386 \t1.07 \t-0.917111\t-0.865651\t1.00e-03\n",
      "002 \t00050/00386 \t1.13 \t-0.930493\t-0.841442\t1.00e-03\n",
      "002 \t00100/00386 \t1.21 \t-0.927605\t-0.844630\t1.00e-03\n",
      "002 \t00150/00386 \t1.27 \t-0.917547\t-0.837381\t1.00e-03\n",
      "002 \t00200/00386 \t1.34 \t-0.942036\t-0.842150\t1.00e-03\n",
      "002 \t00250/00386 \t1.41 \t-0.923458\t-0.851049\t1.00e-03\n",
      "002 \t00300/00386 \t1.48 \t-0.931240\t-0.868579\t1.00e-03\n",
      "002 \t00350/00386 \t1.54 \t-0.930567\t-0.862439\t1.00e-03\n",
      "003 \t00000/00386 \t1.59 \t-0.924538\t-0.910177\t1.00e-03\n",
      "003 \t00050/00386 \t1.66 \t-0.932413\t-0.906911\t1.00e-03\n",
      "003 \t00100/00386 \t1.73 \t-0.918933\t-0.913812\t1.00e-03\n",
      "003 \t00150/00386 \t1.80 \t-0.939326\t-0.890762\t1.00e-03\n",
      "003 \t00200/00386 \t1.87 \t-0.937851\t-0.883070\t1.00e-03\n",
      "003 \t00250/00386 \t1.94 \t-0.931193\t-0.839988\t1.00e-03\n",
      "003 \t00300/00386 \t2.01 \t-0.929279\t-0.915120\t1.00e-03\n",
      "003 \t00350/00386 \t2.07 \t-0.922176\t-0.833925\t1.00e-03\n",
      "004 \t00000/00386 \t2.13 \t-0.947206\t-0.935862\t1.00e-03\n",
      "004 \t00050/00386 \t2.19 \t-0.938755\t-0.899776\t1.00e-03\n",
      "004 \t00100/00386 \t2.26 \t-0.937503\t-0.885858\t1.00e-03\n",
      "004 \t00150/00386 \t2.33 \t-0.945782\t-0.921926\t1.00e-03\n",
      "004 \t00200/00386 \t2.40 \t-0.947616\t-0.829432\t1.00e-03\n",
      "004 \t00250/00386 \t2.46 \t-0.928675\t-0.938351\t1.00e-03\n",
      "004 \t00300/00386 \t2.53 \t-0.931429\t-0.867067\t1.00e-03\n",
      "004 \t00350/00386 \t2.60 \t-0.928286\t-0.926577\t1.00e-03\n",
      "005 \t00000/00386 \t2.65 \t-0.940397\t-0.867956\t1.00e-03\n",
      "005 \t00050/00386 \t2.72 \t-0.929782\t-0.870930\t1.00e-03\n",
      "005 \t00100/00386 \t2.78 \t-0.937810\t-0.865226\t1.00e-03\n",
      "005 \t00150/00386 \t2.85 \t-0.932808\t-0.867244\t1.00e-03\n",
      "005 \t00200/00386 \t2.92 \t-0.923001\t-0.895729\t1.00e-03\n",
      "005 \t00250/00386 \t2.99 \t-0.938552\t-0.909558\t1.00e-03\n",
      "005 \t00300/00386 \t3.05 \t-0.946883\t-0.847264\t1.00e-03\n",
      "005 \t00350/00386 \t3.12 \t-0.947819\t-0.906358\t1.00e-03\n",
      "006 \t00000/00386 \t3.17 \t-0.930011\t-0.864721\t1.00e-03\n",
      "006 \t00050/00386 \t3.24 \t-0.938038\t-0.829497\t1.00e-03\n",
      "006 \t00100/00386 \t3.31 \t-0.939285\t-0.869761\t1.00e-03\n",
      "006 \t00150/00386 \t3.38 \t-0.947019\t-0.941555\t1.00e-03\n",
      "006 \t00200/00386 \t3.44 \t-0.954097\t-0.889929\t1.00e-03\n",
      "006 \t00250/00386 \t3.51 \t-0.944775\t-0.869161\t1.00e-03\n",
      "006 \t00300/00386 \t3.58 \t-0.947289\t-0.894449\t1.00e-03\n",
      "006 \t00350/00386 \t3.65 \t-0.942411\t-0.853878\t1.00e-03\n",
      "007 \t00000/00386 \t3.70 \t-0.940508\t-0.916488\t1.00e-03\n",
      "007 \t00050/00386 \t3.77 \t-0.941390\t-0.807020\t1.00e-03\n",
      "007 \t00100/00386 \t3.83 \t-0.941459\t-0.924205\t1.00e-03\n",
      "007 \t00150/00386 \t3.90 \t-0.954167\t-0.904899\t1.00e-03\n",
      "007 \t00200/00386 \t3.97 \t-0.949760\t-0.868453\t1.00e-03\n",
      "007 \t00250/00386 \t4.04 \t-0.941888\t-0.854064\t1.00e-03\n",
      "007 \t00300/00386 \t4.11 \t-0.927061\t-0.912846\t1.00e-03\n",
      "007 \t00350/00386 \t4.17 \t-0.947581\t-0.922241\t1.00e-03\n",
      "008 \t00000/00386 \t4.23 \t-0.945275\t-0.888709\t1.00e-03\n",
      "008 \t00050/00386 \t4.29 \t-0.942646\t-0.912353\t1.00e-03\n",
      "008 \t00100/00386 \t4.36 \t-0.940035\t-0.912654\t1.00e-03\n",
      "008 \t00150/00386 \t4.43 \t-0.950152\t-0.890698\t1.00e-03\n",
      "008 \t00200/00386 \t4.50 \t-0.957784\t-0.901814\t1.00e-03\n",
      "008 \t00250/00386 \t4.56 \t-0.943813\t-0.907107\t1.00e-03\n",
      "008 \t00300/00386 \t4.63 \t-0.951645\t-0.962165\t1.00e-03\n",
      "008 \t00350/00386 \t4.70 \t-0.950632\t-0.862016\t1.00e-03\n",
      "009 \t00000/00386 \t4.75 \t-0.957554\t-0.959620\t1.00e-03\n",
      "009 \t00050/00386 \t4.84 \t-0.964565\t-0.873656\t1.00e-03\n",
      "009 \t00100/00386 \t4.93 \t-0.958309\t-0.843533\t1.00e-03\n",
      "009 \t00150/00386 \t5.00 \t-0.953233\t-0.855526\t1.00e-03\n",
      "009 \t00200/00386 \t5.06 \t-0.945835\t-0.847694\t1.00e-03\n",
      "009 \t00250/00386 \t5.13 \t-0.958138\t-0.840464\t1.00e-03\n",
      "009 \t00300/00386 \t5.20 \t-0.957819\t-0.909638\t1.00e-03\n",
      "009 \t00350/00386 \t5.27 \t-0.965324\t-0.953037\t1.00e-03\n",
      "010 \t00000/00386 \t5.32 \t-0.949077\t-0.877487\t1.00e-03\n",
      "010 \t00050/00386 \t5.39 \t-0.957719\t-0.968693\t1.00e-03\n",
      "010 \t00100/00386 \t5.46 \t-0.961039\t-0.868710\t1.00e-03\n",
      "010 \t00150/00386 \t5.53 \t-0.974941\t-0.824704\t1.00e-03\n",
      "010 \t00200/00386 \t5.60 \t-0.948687\t-0.898658\t1.00e-03\n",
      "010 \t00250/00386 \t5.66 \t-0.960172\t-0.920956\t1.00e-03\n",
      "010 \t00300/00386 \t5.73 \t-0.969834\t-0.875887\t1.00e-03\n",
      "010 \t00350/00386 \t5.80 \t-0.956839\t-0.882404\t1.00e-03\n",
      "011 \t00000/00386 \t5.85 \t-0.964197\t-0.896455\t1.00e-03\n",
      "011 \t00050/00386 \t5.92 \t-0.975445\t-0.945773\t1.00e-03\n",
      "011 \t00100/00386 \t5.98 \t-0.962697\t-0.847014\t1.00e-03\n",
      "011 \t00150/00386 \t6.05 \t-0.974379\t-0.937647\t1.00e-03\n",
      "011 \t00200/00386 \t6.12 \t-0.979522\t-0.918918\t1.00e-03\n",
      "011 \t00250/00386 \t6.19 \t-0.969275\t-0.890738\t1.00e-03\n",
      "011 \t00300/00386 \t6.26 \t-0.979488\t-0.906320\t1.00e-03\n",
      "011 \t00350/00386 \t6.33 \t-0.982220\t-0.903478\t1.00e-03\n",
      "012 \t00000/00386 \t6.39 \t-0.986199\t-0.932421\t1.00e-03\n",
      "012 \t00050/00386 \t6.46 \t-0.973855\t-0.918248\t1.00e-03\n",
      "012 \t00100/00386 \t6.53 \t-0.958354\t-0.908029\t1.00e-03\n",
      "012 \t00150/00386 \t6.59 \t-0.977733\t-0.872619\t1.00e-03\n",
      "012 \t00200/00386 \t6.67 \t-0.977695\t-0.958076\t1.00e-03\n",
      "012 \t00250/00386 \t6.73 \t-0.984374\t-0.874591\t1.00e-03\n",
      "012 \t00300/00386 \t6.80 \t-0.978873\t-0.895124\t1.00e-03\n",
      "012 \t00350/00386 \t6.87 \t-0.988709\t-0.889100\t1.00e-03\n",
      "013 \t00000/00386 \t6.93 \t-1.001041\t-0.872603\t1.00e-03\n",
      "013 \t00050/00386 \t7.00 \t-0.978873\t-0.892660\t1.00e-03\n",
      "013 \t00100/00386 \t7.07 \t-0.982860\t-0.929049\t1.00e-03\n",
      "013 \t00150/00386 \t7.14 \t-0.965210\t-0.956193\t1.00e-03\n",
      "013 \t00200/00386 \t7.21 \t-0.982035\t-0.862637\t1.00e-03\n",
      "013 \t00250/00386 \t7.28 \t-0.981574\t-0.942931\t1.00e-03\n",
      "013 \t00300/00386 \t7.35 \t-0.999395\t-0.880831\t1.00e-03\n",
      "013 \t00350/00386 \t7.41 \t-0.989355\t-0.855466\t1.00e-03\n",
      "014 \t00000/00386 \t7.47 \t-0.970186\t-0.899158\t1.00e-03\n",
      "014 \t00050/00386 \t7.53 \t-0.997328\t-0.953583\t1.00e-03\n",
      "014 \t00100/00386 \t7.60 \t-0.991598\t-0.973609\t1.00e-03\n",
      "014 \t00150/00386 \t7.66 \t-0.988455\t-0.852137\t1.00e-03\n",
      "014 \t00200/00386 \t7.73 \t-1.001085\t-0.883680\t1.00e-03\n",
      "014 \t00250/00386 \t7.80 \t-1.005479\t-0.902550\t1.00e-03\n",
      "014 \t00300/00386 \t7.87 \t-0.983889\t-0.837111\t1.00e-03\n",
      "014 \t00350/00386 \t7.94 \t-0.975397\t-0.834222\t1.00e-03\n",
      "015 \t00000/00386 \t7.99 \t-1.001872\t-0.883730\t1.00e-03\n",
      "015 \t00050/00386 \t8.06 \t-0.996159\t-0.903793\t1.00e-03\n",
      "015 \t00100/00386 \t8.13 \t-0.998635\t-0.984456\t1.00e-03\n",
      "015 \t00150/00386 \t8.20 \t-1.001445\t-0.915410\t1.00e-03\n",
      "015 \t00200/00386 \t8.27 \t-0.988350\t-0.926645\t1.00e-03\n",
      "015 \t00250/00386 \t8.33 \t-0.997318\t-0.938339\t1.00e-03\n",
      "015 \t00300/00386 \t8.40 \t-1.000740\t-0.936091\t1.00e-03\n",
      "015 \t00350/00386 \t8.47 \t-0.994605\t-0.915668\t1.00e-03\n",
      "016 \t00000/00386 \t8.53 \t-0.991590\t-0.906750\t1.00e-03\n",
      "016 \t00050/00386 \t8.60 \t-0.994535\t-1.033644\t1.00e-03\n",
      "016 \t00100/00386 \t8.67 \t-1.005120\t-0.868072\t1.00e-03\n",
      "016 \t00150/00386 \t8.74 \t-1.013309\t-0.924522\t1.00e-03\n",
      "016 \t00200/00386 \t8.81 \t-1.030614\t-0.875392\t1.00e-03\n",
      "016 \t00250/00386 \t8.88 \t-1.006842\t-0.920171\t1.00e-03\n",
      "016 \t00300/00386 \t8.95 \t-1.005246\t-0.950592\t1.00e-03\n",
      "016 \t00350/00386 \t9.02 \t-1.023200\t-0.847178\t1.00e-03\n",
      "017 \t00000/00386 \t9.08 \t-1.017596\t-0.990123\t1.00e-03\n",
      "017 \t00050/00386 \t9.15 \t-1.015487\t-0.928183\t1.00e-03\n",
      "017 \t00100/00386 \t9.22 \t-1.005367\t-0.862780\t1.00e-03\n",
      "017 \t00150/00386 \t9.29 \t-1.003557\t-1.004655\t1.00e-03\n",
      "017 \t00200/00386 \t9.35 \t-1.004318\t-0.970635\t1.00e-03\n",
      "017 \t00250/00386 \t9.42 \t-1.022349\t-0.941149\t1.00e-03\n",
      "017 \t00300/00386 \t9.49 \t-1.024673\t-0.985909\t1.00e-03\n",
      "017 \t00350/00386 \t9.56 \t-1.007595\t-0.845113\t1.00e-03\n",
      "018 \t00000/00386 \t9.61 \t-1.003001\t-1.008407\t1.00e-03\n",
      "018 \t00050/00386 \t9.69 \t-1.044337\t-0.938643\t1.00e-03\n",
      "018 \t00100/00386 \t9.76 \t-1.034525\t-0.926552\t1.00e-03\n",
      "018 \t00150/00386 \t9.83 \t-1.004084\t-0.983859\t1.00e-03\n",
      "018 \t00200/00386 \t9.90 \t-1.021590\t-0.971637\t1.00e-03\n",
      "018 \t00250/00386 \t9.97 \t-1.030590\t-0.882030\t1.00e-03\n",
      "018 \t00300/00386 \t10.04 \t-1.014447\t-0.954074\t1.00e-03\n",
      "018 \t00350/00386 \t10.11 \t-1.032309\t-0.904318\t1.00e-03\n",
      "019 \t00000/00386 \t10.16 \t-1.025670\t-0.837277\t1.00e-03\n",
      "019 \t00050/00386 \t10.23 \t-1.024336\t-0.920662\t1.00e-03\n",
      "019 \t00100/00386 \t10.30 \t-1.031028\t-0.863342\t1.00e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "019 \t00150/00386 \t10.37 \t-1.022751\t-0.923397\t1.00e-03\n",
      "019 \t00200/00386 \t10.44 \t-1.031283\t-0.916898\t1.00e-03\n",
      "019 \t00250/00386 \t10.51 \t-1.054445\t-0.941422\t1.00e-03\n",
      "019 \t00300/00386 \t10.57 \t-1.020628\t-0.993447\t1.00e-03\n",
      "019 \t00350/00386 \t10.65 \t-1.042296\t-0.866701\t1.00e-03\n"
     ]
    }
   ],
   "source": [
    "config = CONFIG()\n",
    "if not config.mock:\n",
    "    hxtorch.init_hardware()\n",
    "\n",
    "data = ExampleData(config)\n",
    "\n",
    "model_floating = EXAMPLEcINN_hx(config)\n",
    "#model_floating.load(config.save_dir + \"hx_mock_example_cinn_50epochs_mock.pt\")\n",
    "\n",
    "t_start = time()\n",
    "\n",
    "model_floating.train()\n",
    "nll_mean = []\n",
    "\n",
    "val_losses_means = np.array([])\n",
    "val_losses = np.array([])\n",
    "\n",
    "\n",
    "try:\n",
    "    for i_epoch in range(-config.pre_low_lr, config.n_epochs):\n",
    "        if i_epoch < 0:\n",
    "            for param_group in model.optimizer.param_groups:\n",
    "                param_group['lr'] = config.lr * 2e-2\n",
    "\n",
    "        for i_batch, (x, l) in enumerate(data.train_loader):\n",
    "\n",
    "            x, l = x.to(config.device), l.to(config.device)\n",
    "            z, log_j = model_floating(x, l)\n",
    "\n",
    "            nll = torch.mean(z**2) / 2 - torch.mean(log_j) / np.prod(config.img_size)\n",
    "            nll.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model_floating.trainable_parameters,\n",
    "                                           config.clip_grad_norm)\n",
    "\n",
    "            nll_mean.append(nll.item())\n",
    "\n",
    "            model_floating.optimizer.step()\n",
    "            model_floating.optimizer.zero_grad()\n",
    "\n",
    "            print_interval = 10 if not config.mock else 50\n",
    "            if not i_batch % print_interval:\n",
    "                with torch.no_grad():\n",
    "                    z, log_j = model_floating(data.val_x, data.val_l)\n",
    "                    nll_val = torch.mean(z**2) / 2 - torch.mean(log_j) / np.prod(config.img_size)\n",
    "\n",
    "                print('%.3i \\t%.5i/%.5i \\t%.2f \\t%.6f\\t%.6f\\t%.2e' % (i_epoch,\n",
    "                                                                i_batch, len(data.train_loader),\n",
    "                                                                (time() - t_start)/60.,\n",
    "                                                                np.mean(nll_mean),\n",
    "                                                                nll_val.item(),\n",
    "                                                                model_floating.optimizer.param_groups[0]['lr'],\n",
    "                                                                ), flush=True)\n",
    "                \n",
    "                val_losses_means = np.append(val_losses_means, np.mean(nll_mean))\n",
    "                val_losses = np.append(val_losses, nll_val.item())\n",
    "                \n",
    "                nll_mean = []\n",
    "                \n",
    "            if (i_batch % config.checkpoint_save_interval) == 0:\n",
    "                model_floating.save(config.filename + 'floating_checkpoint_%.4i' % (i_batch * (1-config.checkpoint_save_overwrite)))\n",
    "\n",
    "        model_floating.weight_scheduler.step()\n",
    "\n",
    "        #if (i_epoch % config.checkpoint_save_interval) == 0:\n",
    "        #    model_floating.save(config.filename + 'floating_checkpoint_%.4i' % (i_epoch * (1-config.checkpoint_save_overwrite)))\n",
    "\n",
    "    model_floating.save(config.filename)\n",
    "    np.savetxt(config.loss_means_filename, val_losses_means)\n",
    "    np.savetxt(config.loss_filename, val_losses)\n",
    "\n",
    "except BaseException as b:\n",
    "    if config.checkpoint_on_error:\n",
    "        model_floating.save(config.filename + \"floating_ABORT\")\n",
    "    raise b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_config = CONFIG\n",
    "load_model = EXAMPLEcINN_hx(load_config)\n",
    "load_model.load(load_config.save_dir + \"hx_mock_example_cinn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples(model, data, config, label):\n",
    "    '''Produces and shows cINN samples for a given label.'''\n",
    "\n",
    "    N_samples = 100\n",
    "    l = torch.LongTensor(N_samples).to(config.device)\n",
    "    l[:] = label\n",
    "\n",
    "    z = 1.0 * torch.randn(N_samples, np.prod(config.img_size)).to(config.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        samples = model.reverse_sample(z, l)[0].cpu().numpy()\n",
    "\n",
    "    full_image = np.zeros((config.img_size[0]*10, config.img_size[1]*10))\n",
    "\n",
    "    qwe = []\n",
    "    for k in range(N_samples):\n",
    "        i, j = k // 10, k % 10\n",
    "        full_image[config.img_size[0] * i : config.img_size[1] * (i + 1),\n",
    "                   config.img_size[0] * j : config.img_size[1] * (j + 1)] = samples[k, 0]\n",
    "        qwe.append(np.argmax(samples[k, 0]))\n",
    "    qwe = np.array(qwe)\n",
    "    print(f\"{len(qwe[qwe==0])/len(qwe)}\\t{len(qwe[qwe==1])/len(qwe)}\\t{len(qwe[qwe==2])/len(qwe)}\\t{len(qwe[qwe==3])/len(qwe)}\")\n",
    "        \n",
    "\n",
    "    full_image = np.clip(full_image, 0, 1)\n",
    "    plt.figure()\n",
    "    plt.title(F'Generated digits for c={label}')\n",
    "    plt.imshow(full_image, vmin=0, vmax=1, cmap='gray')\n",
    "    plt.savefig(config.save_dir + f\"/eval_{label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration run - floating model\n",
      "0.74\t0.08\t0.12\t0.06\n",
      "0.01\t0.98\t0.01\t0.0\n",
      "0.1\t0.05\t0.68\t0.17\n",
      "0.0\t0.02\t0.07\t0.91\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Calibration run - floating model\")\n",
    "for k in range(4):\n",
    "    show_samples(load_model, data, config, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0351,  0.6105, -1.5245,  0.9682,  0.7312,  0.7136,  0.4641, -1.3218,\n",
      "         -0.3367, -0.5885],\n",
      "        [-1.1072, -1.9708, -0.3163, -0.8902, -0.7194, -0.2035, -0.7731, -1.8471,\n",
      "          1.0730,  0.6621],\n",
      "        [ 0.2240,  0.9835, -0.6787,  0.3568, -1.7117,  2.2486,  0.5351, -0.6314,\n",
      "          1.2296, -0.3926]])\n",
      "tensor([2.2486, 2.2486, 2.2486, 2.2486, 2.2486, 2.2486, 2.2486, 2.2486, 2.2486,\n",
      "        2.2486])\n",
      "Parameter containing:\n",
      "tensor([13.7864, 13.7864, 13.7864, 13.7864, 13.7864, 13.7864, 13.7864, 13.7864,\n",
      "        13.7864, 13.7864])\n",
      "tensor([[  0.,   8., -22.,  13.,  10.,   9.,   6., -19.,  -5.,  -9.],\n",
      "        [-16., -28.,  -5., -13., -10.,  -3., -11., -26.,  14.,   9.],\n",
      "        [  3.,  13., -10.,   4., -24.,  31.,   7.,  -9.,  16.,  -6.]])\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "max_out = 31\n",
    "weight = Parameter(torch.empty(16), requires_grad=False)\n",
    "per_feature = False\n",
    "\n",
    "#x = torch.Tensor([[31, 0, -31], [-10.5, 0, 7]])\n",
    "x = torch.randn(3, 10)\n",
    "x[torch.abs(x) < 0.5] = x[torch.abs(x) < 0.5]\n",
    "print(x)\n",
    "\n",
    "max_abs, _ = torch.max(torch.abs(x), axis=0)\n",
    "if not per_feature:\n",
    "    max_abs.fill_(max_abs.max())\n",
    "#print(max_abs)\n",
    "max_abs[max_abs == 0] = max_out\n",
    "print(max_abs)\n",
    "weight = nn.Parameter(max_out / max_abs, requires_grad=False)\n",
    "print(weight)\n",
    "out = torch.floor(x * weight)\n",
    "print(out)\n",
    "out_diag = torch.floor(F.linear(x, torch.diag(weight)))\n",
    "#print(out_diag)\n",
    "\n",
    "print(\"-------------------\")\n",
    "max_abss = torch.max(torch.abs(x))\n",
    "factor = _hxtorch.constants.input_activation_max / max_abss if max_abss != 0 else 1\n",
    "            #factor = torch.Tensor(_hxtorch.constants.input_activation_max).repeat(max_abs.size()) /  \\\n",
    "                #max_abs if max_abs != 0 else 1\n",
    "res = torch.floor(x * factor)\n",
    "#print(res)\n",
    "\n",
    "assert out.all() == out_diag.all()\n",
    "assert out.all() == res.all()\n",
    "assert out.all() < 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
