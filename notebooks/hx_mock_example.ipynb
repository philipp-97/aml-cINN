{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Invertible Neural Networks (cINNs) on BrainScaleS-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Callable, Union\n",
    "\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.optim\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter, UninitializedParameter\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import hxtorch\n",
    "import _hxtorch\n",
    "import hxtorch.nn as hxnn\n",
    "\n",
    "import FrEIA.framework as Ff\n",
    "import FrEIA.modules as Fm\n",
    "\n",
    "import quantized_cINN.common as com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Generate toy dataset\n",
    "\n",
    "In order to prove the functioning of the implemented cINN with the limitations accompanying the use of BrainScaleS-2, an example dataset as easy as possible is needed. Here, we generate pictures with the size of four pixels, of which one is light and the other three are dark. The respective label indicates the position of the light pixel. The goal of this exercise is for the network to generate similar pictures having the light pixel in the correct place given a conditional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, n_samples=100000, img_size=(2, 2), transform=None):\n",
    "        self.n_samples = n_samples\n",
    "        self.img_size = img_size\n",
    "        self.transform = transform\n",
    "        self.data, self.targets = self._generate_data()\n",
    "\n",
    "    def _generate_data(self):\n",
    "        floor = 0.2\n",
    "        intensity = (0, 1)\n",
    "\n",
    "        high = self.img_size[0] * self.img_size[1]\n",
    "        labels = torch.randint(low=0, high=high, size=(self.n_samples, ))\n",
    "        imgs = floor * torch.rand((self.n_samples, 1, *self.img_size))\n",
    "        imgs[torch.arange(self.n_samples), :, labels%2, labels//2] += intensity[1] - floor \n",
    "        return imgs, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "    \n",
    "        X = self.data[idx].numpy()\n",
    "        y = self.targets[idx].reshape(-1).numpy()\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "        return X, y\n",
    "\n",
    "class ExampleData:\n",
    "\n",
    "    def __init__(self, config: object):\n",
    "        from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "        import torchvision.transforms as T\n",
    "\n",
    "        self.c = config\n",
    "\n",
    "        self.train_data = ExampleDataset(transform=T.ToTensor())\n",
    "        self.test_data = ExampleDataset(transform=T.ToTensor())\n",
    "\n",
    "        # Sample a fixed batch of 1024 validation examples\n",
    "        self.val_x, self.val_l = zip(*list(self.train_data[i] for i in range(1024)))\n",
    "        self.val_x = torch.stack(self.val_x, 0).to(config.device)\n",
    "        self.val_l = torch.LongTensor(self.val_l).to(config.device)\n",
    "\n",
    "        # Exclude the validation batch from the training data\n",
    "        self.train_data.data = self.train_data.data[1024:]\n",
    "        self.train_data.targets = self.train_data.targets[1024:]\n",
    "\n",
    "        ## Add the noise-augmentation to the (non-validation) training data:\n",
    "        #augm_func = lambda x: x + self.c.add_image_noise * torch.randn_like(x)\n",
    "        #self.train_data.transform = T.Compose([self.train_data.transform, augm_func])\n",
    "\n",
    "        self.train_loader = DataLoader(self.train_data,\n",
    "                                       batch_size=self.c.batch_size,\n",
    "                                       shuffle=True,\n",
    "                                       num_workers=self.c.n_workers,\n",
    "                                       pin_memory=True, drop_last=True)\n",
    "        self.test_loader = DataLoader(self.test_data,\n",
    "                                      batch_size=self.c.batch_size,\n",
    "                                      shuffle=False,\n",
    "                                      num_workers=self.c.n_workers,\n",
    "                                      pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG(com.baseCONFIG):\n",
    "    \"\"\"\n",
    "    Namspace for configuration\n",
    "    \"\"\"\n",
    "    # Data\n",
    "    data_mean = None\n",
    "    data_std = None\n",
    "    add_image_noise = None\n",
    "\n",
    "    img_size = (2, 2)\n",
    "    device = \"cpu\"\n",
    "    n_workers = 8\n",
    "\n",
    "    # Hardware simulation\n",
    "    mock = False\n",
    "\n",
    "    # Training\n",
    "    lr = 1e-3\n",
    "    batch_size = 256\n",
    "    weight_decay = 1e-5\n",
    "    gamma = 0.1\n",
    "    milestones = [20, 40]\n",
    "    betas = (0.9, 0.999)\n",
    "\n",
    "    n_epochs = 5\n",
    "\n",
    "    init_scale = 0.03\n",
    "    pre_low_lr = 0\n",
    "    \n",
    "    clip_grad_norm = 100.0\n",
    "\n",
    "    # Architecture\n",
    "    n_blocks = 8\n",
    "    internal_width = 16\n",
    "    clamping = 1.\n",
    "    fc_dropout = 0.0\n",
    "\n",
    "    # Logging/preview\n",
    "    loss_names = ['L']\n",
    "    preview_upscale = 3                         # Scale up the images for preview\n",
    "    sampling_temperature = 0.8                  # Sample at a reduced temperature for the preview\n",
    "    progress_bar = True                         # Show a progress bar of each epoch\n",
    "    eval_steps_interploation = 12\n",
    "    eval_seeds_interpolation  = (51, 89)\n",
    "\n",
    "    # Validation\n",
    "    pca_weights = [\n",
    "        [(0,0.55)],\n",
    "        [(1,0.1), (3, 0.4), (4, 0.5)],\n",
    "        [(2,0.33), (3, 0.33), (1, -0.33)]]\n",
    "    pca_gridsize = 10\n",
    "    pca_extent = 8.\n",
    "\n",
    "\n",
    "    # Paths\n",
    "    mnist_data = \"../mnist_data\"\n",
    "    save_dir = \"out/hx_mock/\"\n",
    "\n",
    "    load_file = \"out/hx_mock/hx_mock_example_checkpoint.pt\"\n",
    "    filename = \"out/hx_mock/hx_mock_example_cinn.pt\"\n",
    "\n",
    "    # Checkpoints\n",
    "    checkpoint_save_interval =  50\n",
    "    checkpoint_save_overwrite = True\n",
    "    checkpoint_on_error = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "### Modules \n",
    "\n",
    "The input and output of the hardware needs to be approriately scaled, since its range is limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "class LinearScaling(nn.Module):\n",
    "\n",
    "    def __init__(self, weight: float=1., bias: float=0.,\n",
    "                 outrange=None, device=None, dtype=None):\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super(LinearScaling, self).__init__()\n",
    "\n",
    "        self.weight = Parameter(torch.tensor(weight), requires_grad=True)\n",
    "        self.bias = Parameter(torch.tensor(bias), requires_grad=True)\n",
    "        self.outrange = outrange\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * self.weight + self.bias\n",
    "        if self.outrange:\n",
    "            x = x.clamp(*self.outrange)\n",
    "        return x\n",
    "\n",
    "class MinMaxScaling(nn.Module):\n",
    "\n",
    "    def __init__(self, outrange, per_feature=False, size=None):\n",
    "        #assert (per_feature and not size) \"If you want per_feature \"\n",
    "        super(MinMaxScaling, self).__init__()\n",
    "        if size:\n",
    "            self.weight = torch.ones(size)\n",
    "            self.bias = torch.zeros(size)\n",
    "            self.per_feature = per_feature\n",
    "        else:\n",
    "            self.weight = torch.ones(1)\n",
    "            self.bias = torch.zeros(1)\n",
    "            self.per_feature = False\n",
    "        #self.register_parameter(\"factor__\", None)\n",
    "        #self.register_parameter(\"bias__\", None)\n",
    "\n",
    "        self.outrange = outrange\n",
    "        self.in_min = None\n",
    "        self.in_max = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            if self.per_feature:\n",
    "                self.in_min = torch.min(x, axis=0)[0]\n",
    "                self.in_max = torch.max(x, axis=0)[0]\n",
    "            else:\n",
    "                self.in_min = torch.tensor([torch.min(x)])\n",
    "                self.in_max = torch.tensor([torch.max(x)])\n",
    "\n",
    "        _norm = self.in_max - self.in_min\n",
    "        self.weight = (self.outrange[1] - self.outrange[0]) / _norm\n",
    "        self.bias = self.outrange[1] - self.weight * self.in_max\n",
    "        return self.weight * x + self.bias     \n",
    "        \n",
    "        \n",
    "class Scale(nn.Module):\n",
    "    def __init__(self, scale=1):\n",
    "        super(Scale, self).__init__()\n",
    "        self.scale = scale\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x * self.scale\n",
    "        return x\n",
    "    \n",
    "class DynamicScaling(nn.Module):\n",
    "    r\"\"\"Applies a linear scaling to the incoming data: :math:`y = x*w + b`\n",
    "    This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
    "    Args:\n",
    "        features: size of each output sample\n",
    "        bias: If set to ``False``, the layer will not learn an additive bias.\n",
    "            Default: ``True``\n",
    "    Shape:\n",
    "        - Input: :math:`(N, *, H)` where :math:`*` means any number of\n",
    "          additional dimensions and :math:`H = \\text{features}`.\n",
    "        - Output: :math:`(N, *, H)`.\n",
    "    Attributes:\n",
    "        weight: the learnable weights of the module of shape\n",
    "            :math:`(\\text{features})`. The values are\n",
    "            initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n",
    "            :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
    "        bias:   the learnable bias of the module of shape :math:`(\\text{features})`.\n",
    "                If :attr:`bias` is ``True``, the values are initialized from\n",
    "                :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
    "                :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
    "    \"\"\"\n",
    "    __constants__ = ['features']\n",
    "    features: int\n",
    "    weight: torch.Tensor\n",
    "\n",
    "    def __init__(self, features: int, bias: bool = True,\n",
    "                device=None, dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super(DynamicScaling, self).__init__()\n",
    "        self.features = features\n",
    "\n",
    "        self.weight = Parameter(torch.empty(features, **factory_kwargs))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty(features, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters_static()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        nn.init.kaiming_uniform_(torch.diag(self.weight), a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(torch.diag(self.weight))\n",
    "            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "            \n",
    "    def reset_parameters_static(self) -> None:\n",
    "        nn.init._no_grad_fill_(self.weight, 0.03)\n",
    "        nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return F.linear(input, torch.diag(self.weight), self.bias)\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return 'features={}, bias={}'.format(\n",
    "            self.features, self.bias is not None\n",
    "        )\n",
    "    \n",
    "class FixedRangeScaling(nn.Module):\n",
    "    r\"\"\"\n",
    "    \"\"\"\n",
    "    __constants__ = ['features', 'max_out']\n",
    "    per_feature: bool\n",
    "    features: int\n",
    "    max_out: int\n",
    "    weight: torch.Tensor\n",
    "\n",
    "    def __init__(self, features: int, max_out: int, per_feature: bool = False,\n",
    "                 device=None, dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super(FixedRangeScaling, self).__init__()\n",
    "        self.features = features\n",
    "        self.max_out = max_out\n",
    "        self.per_feature = per_feature\n",
    "\n",
    "        self.weight = Parameter(torch.empty(features, **factory_kwargs),\n",
    "                                requires_grad=False)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        nn.init.ones_(self.weight)\n",
    "\n",
    "    def forward(self, input_: torch.Tensor) -> torch.Tensor:\n",
    "        if self.training:\n",
    "            max_abs, _ = torch.max(torch.abs(input_), axis=0)\n",
    "            if not self.per_feature:\n",
    "                max_abs.fill_(max_abs.max())\n",
    "            max_abs[max_abs == 0.] = self.max_out\n",
    "            with torch.no_grad():\n",
    "                self.weight.data = self.max_out / max_abs\n",
    "        res = F.linear(input_, torch.diag(self.weight))\n",
    "        res[res > 0] = torch.floor(res[res > 0])\n",
    "        res[res < 0] = torch.ceil(res[res < 0])\n",
    "        return res\n",
    "            \n",
    "    def extra_repr(self) -> str:\n",
    "        return 'features={}, max_out={}, per_feature={}'.format(\n",
    "            self.features, self.max_out, self.per_feature\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EXAMPLEcINN_hx(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: object=CONFIG):\n",
    "        super().__init__()\n",
    "        #self.stop = False\n",
    "\n",
    "        self.c = config\n",
    "\n",
    "        self.cinn = self.build_inn()\n",
    "\n",
    "        self.trainable_parameters = []\n",
    "        for name, param in self.cinn.named_parameters():\n",
    "            #print(name, (name.split(\".\")[-2][-2:] == \"__\"))\n",
    "            if param.requires_grad and not (name.split(\".\")[-2][-2:] == \"__\"):\n",
    "                #print(\"accept\")\n",
    "                self.trainable_parameters.append(param)\n",
    "            continue\n",
    "\n",
    "        #for p in self.trainable_parameters:\n",
    "        #    print(p)\n",
    "        #    p.data = self.c.init_scale * torch.randn_like(p)\n",
    "\n",
    "        self.cinn.to(self.c.device)\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.trainable_parameters,\n",
    "                                          lr=self.c.lr,\n",
    "                                          weight_decay=self.c.weight_decay)\n",
    "        self.weight_scheduler = torch.optim.lr_scheduler.MultiStepLR(self.optimizer,\n",
    "                                                                #step_size=1,\n",
    "                                                                milestones=self.c.milestones,\n",
    "                                                                gamma=self.c.gamma)\n",
    "\n",
    "    def build_inn(self):\n",
    "        \n",
    "        def scale_input_total(x_in: torch.Tensor) -> torch.Tensor:\n",
    "            max_abs = torch.max(torch.abs(x_in))\n",
    "            factor = _hxtorch.constants.input_activation_max / max_abs if max_abs != 0 else 1\n",
    "            return x_in * factor\n",
    "\n",
    "        def fc_subnet(ch_in, ch_out):\n",
    "            net = OrderedDict([\n",
    "                (\"hx_input1\", FixedRangeScaling(features=ch_in,\n",
    "                                                max_out=31,\n",
    "                                                per_feature=True)),\n",
    "                (\"hx_lin_1\", hxnn.Linear(in_features=ch_in,\n",
    "                                         out_features=self.c.internal_width,\n",
    "                                         bias=False,\n",
    "                                         num_sends=2,\n",
    "                                         wait_between_events=2,\n",
    "                                         mock=self.c.mock,\n",
    "                                         signed_input=True,\n",
    "                                         )),\n",
    "                (\"relu1\", hxnn.ConvertingReLU(shift=1,\n",
    "                                              mock=self.c.mock)),\n",
    "                (\"hx_input2\", FixedRangeScaling(features=self.c.internal_width,\n",
    "                                                max_out=31,\n",
    "                                                per_feature=True)),\n",
    "                (\"hx_lin_2\", hxnn.Linear(in_features=self.c.internal_width,\n",
    "                                         out_features=ch_out,\n",
    "                                         bias=False,\n",
    "                                         num_sends=3,\n",
    "                                         wait_between_events=2,\n",
    "                                         mock=self.c.mock,\n",
    "                                         signed_input=True,\n",
    "                                         )),\n",
    "                (\"hx_output\", DynamicScaling(features=ch_out))\n",
    "            ])\n",
    "            return nn.Sequential(net)\n",
    "\n",
    "        cond = Ff.ConditionNode(4)\n",
    "\n",
    "        nodes = [Ff.InputNode(1, *self.c.img_size)]\n",
    "        nodes.append(Ff.Node(nodes[-1], Fm.Flatten, {}))\n",
    "\n",
    "        for k in range(self.c.n_blocks):\n",
    "            nodes.append(Ff.Node(nodes[-1], Fm.PermuteRandom,\n",
    "                                 {\"seed\": k}))\n",
    "            nodes.append(Ff.Node(nodes[-1], Fm.GLOWCouplingBlock,\n",
    "                                 {\"subnet_constructor\": fc_subnet,\n",
    "                                  \"clamp\": 1.},\n",
    "                                  conditions=cond))\n",
    "\n",
    "        nodes += [cond, Ff.OutputNode(nodes[-1])]\n",
    "        return Ff.ReversibleGraphNet(nodes, verbose=False)\n",
    "\n",
    "    def forward(self, x, l, jac=True):\n",
    "        return self.cinn(x, c=one_hot(l), jac=jac)\n",
    "\n",
    "    def reverse_sample(self, z, l, jac=True):\n",
    "        return self.cinn(z, c=one_hot(l), rev=True, jac=jac)\n",
    "\n",
    "    def save(self, name):\n",
    "        save_dict = {\"opt\": self.optimizer.state_dict(),\n",
    "                     \"net\": self.cinn.state_dict(),\n",
    "                     \"lr\": self.weight_scheduler.state_dict()}\n",
    "        torch.save(save_dict, name)\n",
    "\n",
    "    def load(self, name):\n",
    "        state_dicts = torch.load(name)\n",
    "        self.cinn.load_state_dict(state_dicts[\"net\"])\n",
    "        try:\n",
    "            self.optimizer.load_state_dict(state_dicts[\"opt\"])\n",
    "        except ValueError:\n",
    "            print(\"Cannot load optimizer for some reason or other\")\n",
    "        try:\n",
    "            self.weight_scheduler.load_state_dict(state_dicts[\"lr\"])\n",
    "        except ValueError:\n",
    "            print(\"Cannot load optimizer for some reason or other\")\n",
    "            \n",
    "def one_hot(labels, out=None):\n",
    "    '''\n",
    "    Convert LongTensor labels (contains labels 0-9), to a one hot vector.\n",
    "    Can be done in-place using the out-argument (faster, re-use of GPU memory)\n",
    "    '''\n",
    "    if out is None:\n",
    "        out = torch.zeros(labels.shape[0], 4).to(labels.device)\n",
    "    else:\n",
    "        out.zeros_()\n",
    "    out.scatter_(dim=1, index=labels.view(-1,1), value=1.)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/spack_views/visionary-dls/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000 \t00000/00386 \t0.26 \t1.068135\t0.851725\t1.00e-03\n",
      "000 \t00010/00386 \t1.18 \t0.423112\t0.034712\t1.00e-03\n",
      "000 \t00020/00386 \t2.10 \t-0.107234\t-0.293509\t1.00e-03\n",
      "000 \t00030/00386 \t3.02 \t-0.412709\t-0.559287\t1.00e-03\n",
      "000 \t00040/00386 \t3.94 \t-0.689677\t-0.810154\t1.00e-03\n",
      "000 \t00050/00386 \t4.86 \t-0.936307\t-1.056160\t1.00e-03\n",
      "000 \t00060/00386 \t5.77 \t-1.131788\t-1.186694\t1.00e-03\n",
      "000 \t00070/00386 \t6.69 \t-1.275168\t-1.334654\t1.00e-03\n",
      "000 \t00080/00386 \t7.61 \t-1.345150\t-1.391723\t1.00e-03\n",
      "000 \t00090/00386 \t8.53 \t-1.408250\t-1.451540\t1.00e-03\n",
      "000 \t00100/00386 \t9.45 \t-1.441146\t-1.487376\t1.00e-03\n",
      "000 \t00110/00386 \t10.37 \t-1.485944\t-1.546785\t1.00e-03\n",
      "000 \t00120/00386 \t11.29 \t-1.516798\t-1.545801\t1.00e-03\n",
      "000 \t00130/00386 \t12.21 \t-1.563448\t-1.576569\t1.00e-03\n",
      "000 \t00140/00386 \t13.12 \t-1.589134\t-1.596376\t1.00e-03\n",
      "000 \t00150/00386 \t14.04 \t-1.604579\t-1.619686\t1.00e-03\n",
      "000 \t00160/00386 \t14.96 \t-1.629165\t-1.629660\t1.00e-03\n",
      "000 \t00170/00386 \t15.88 \t-1.624033\t-1.645641\t1.00e-03\n",
      "000 \t00180/00386 \t16.80 \t-1.644880\t-1.671198\t1.00e-03\n",
      "000 \t00190/00386 \t17.72 \t-1.648250\t-1.649827\t1.00e-03\n",
      "000 \t00200/00386 \t18.64 \t-1.668206\t-1.684645\t1.00e-03\n",
      "000 \t00210/00386 \t19.56 \t-1.682225\t-1.676232\t1.00e-03\n",
      "000 \t00220/00386 \t20.47 \t-1.685052\t-1.703166\t1.00e-03\n",
      "000 \t00230/00386 \t21.39 \t-1.700644\t-1.722991\t1.00e-03\n",
      "000 \t00240/00386 \t22.31 \t-1.708389\t-1.742572\t1.00e-03\n",
      "000 \t00250/00386 \t23.23 \t-1.708824\t-1.727388\t1.00e-03\n",
      "000 \t00260/00386 \t24.15 \t-1.719074\t-1.719173\t1.00e-03\n",
      "000 \t00270/00386 \t25.06 \t-1.725826\t-1.756756\t1.00e-03\n",
      "000 \t00280/00386 \t25.98 \t-1.741768\t-1.769679\t1.00e-03\n",
      "000 \t00290/00386 \t26.90 \t-1.754661\t-1.747689\t1.00e-03\n",
      "000 \t00300/00386 \t27.82 \t-1.736516\t-1.739568\t1.00e-03\n",
      "000 \t00310/00386 \t28.73 \t-1.744210\t-1.764315\t1.00e-03\n",
      "000 \t00320/00386 \t29.65 \t-1.750792\t-1.758787\t1.00e-03\n",
      "000 \t00330/00386 \t30.57 \t-1.751173\t-1.783878\t1.00e-03\n",
      "000 \t00340/00386 \t31.49 \t-1.762774\t-1.744388\t1.00e-03\n",
      "000 \t00350/00386 \t32.41 \t-1.752605\t-1.737588\t1.00e-03\n",
      "000 \t00360/00386 \t33.32 \t-1.748120\t-1.796606\t1.00e-03\n",
      "000 \t00370/00386 \t34.24 \t-1.761432\t-1.778834\t1.00e-03\n",
      "000 \t00380/00386 \t35.16 \t-1.756338\t-1.789179\t1.00e-03\n",
      "001 \t00000/00386 \t35.75 \t-1.768067\t-1.761389\t1.00e-03\n",
      "001 \t00010/00386 \t36.67 \t-1.750794\t-1.782184\t1.00e-03\n",
      "001 \t00020/00386 \t37.59 \t-1.774231\t-1.773469\t1.00e-03\n",
      "001 \t00030/00386 \t38.51 \t-1.770703\t-1.765871\t1.00e-03\n",
      "001 \t00040/00386 \t39.43 \t-1.771980\t-1.769938\t1.00e-03\n",
      "001 \t00050/00386 \t40.35 \t-1.773441\t-1.785471\t1.00e-03\n",
      "001 \t00060/00386 \t41.27 \t-1.759561\t-1.777365\t1.00e-03\n",
      "001 \t00070/00386 \t42.19 \t-1.774404\t-1.799586\t1.00e-03\n",
      "001 \t00080/00386 \t43.11 \t-1.772170\t-1.809661\t1.00e-03\n",
      "001 \t00090/00386 \t44.03 \t-1.789973\t-1.794069\t1.00e-03\n",
      "001 \t00100/00386 \t44.95 \t-1.790759\t-1.809509\t1.00e-03\n",
      "001 \t00110/00386 \t45.86 \t-1.770268\t-1.770381\t1.00e-03\n",
      "001 \t00120/00386 \t46.78 \t-1.789712\t-1.786612\t1.00e-03\n",
      "001 \t00130/00386 \t47.70 \t-1.786615\t-1.814853\t1.00e-03\n",
      "001 \t00140/00386 \t48.62 \t-1.783301\t-1.784089\t1.00e-03\n",
      "001 \t00150/00386 \t49.54 \t-1.804219\t-1.781690\t1.00e-03\n",
      "001 \t00160/00386 \t50.46 \t-1.782459\t-1.815804\t1.00e-03\n",
      "001 \t00170/00386 \t51.38 \t-1.803852\t-1.804755\t1.00e-03\n",
      "001 \t00180/00386 \t52.30 \t-1.801144\t-1.833959\t1.00e-03\n",
      "001 \t00190/00386 \t53.22 \t-1.800030\t-1.814989\t1.00e-03\n",
      "001 \t00200/00386 \t54.14 \t-1.806970\t-1.821817\t1.00e-03\n",
      "001 \t00210/00386 \t55.06 \t-1.803398\t-1.830345\t1.00e-03\n",
      "001 \t00220/00386 \t55.98 \t-1.799318\t-1.814347\t1.00e-03\n",
      "001 \t00230/00386 \t56.90 \t-1.811908\t-1.822817\t1.00e-03\n",
      "001 \t00240/00386 \t57.82 \t-1.813011\t-1.829291\t1.00e-03\n",
      "001 \t00250/00386 \t58.74 \t-1.809458\t-1.802356\t1.00e-03\n",
      "001 \t00260/00386 \t59.65 \t-1.809263\t-1.829965\t1.00e-03\n",
      "001 \t00270/00386 \t60.57 \t-1.811315\t-1.838238\t1.00e-03\n",
      "001 \t00280/00386 \t61.49 \t-1.802454\t-1.815530\t1.00e-03\n",
      "001 \t00290/00386 \t62.41 \t-1.802216\t-1.827964\t1.00e-03\n",
      "001 \t00300/00386 \t63.33 \t-1.819621\t-1.847123\t1.00e-03\n",
      "001 \t00310/00386 \t64.25 \t-1.804739\t-1.838206\t1.00e-03\n",
      "001 \t00320/00386 \t65.17 \t-1.833587\t-1.835113\t1.00e-03\n",
      "001 \t00330/00386 \t66.09 \t-1.829533\t-1.838532\t1.00e-03\n",
      "001 \t00340/00386 \t67.01 \t-1.829193\t-1.847745\t1.00e-03\n",
      "001 \t00350/00386 \t67.93 \t-1.826158\t-1.842111\t1.00e-03\n",
      "001 \t00360/00386 \t68.85 \t-1.822920\t-1.832270\t1.00e-03\n",
      "001 \t00370/00386 \t69.77 \t-1.835852\t-1.864417\t1.00e-03\n",
      "001 \t00380/00386 \t70.69 \t-1.821756\t-1.848931\t1.00e-03\n",
      "002 \t00000/00386 \t71.29 \t-1.841971\t-1.840006\t1.00e-03\n",
      "002 \t00010/00386 \t72.21 \t-1.832934\t-1.842132\t1.00e-03\n",
      "002 \t00020/00386 \t73.13 \t-1.836789\t-1.833774\t1.00e-03\n",
      "002 \t00030/00386 \t74.04 \t-1.827891\t-1.856900\t1.00e-03\n",
      "002 \t00040/00386 \t74.96 \t-1.843576\t-1.847213\t1.00e-03\n",
      "002 \t00050/00386 \t75.88 \t-1.851270\t-1.819926\t1.00e-03\n",
      "002 \t00060/00386 \t76.80 \t-1.845870\t-1.850260\t1.00e-03\n",
      "002 \t00070/00386 \t77.72 \t-1.831984\t-1.831423\t1.00e-03\n",
      "002 \t00080/00386 \t78.64 \t-1.841634\t-1.869223\t1.00e-03\n",
      "002 \t00090/00386 \t79.57 \t-1.836420\t-1.865802\t1.00e-03\n",
      "002 \t00100/00386 \t80.49 \t-1.840732\t-1.837576\t1.00e-03\n",
      "002 \t00110/00386 \t81.41 \t-1.841232\t-1.872863\t1.00e-03\n",
      "002 \t00120/00386 \t82.33 \t-1.848179\t-1.821546\t1.00e-03\n",
      "002 \t00130/00386 \t83.25 \t-1.843489\t-1.856028\t1.00e-03\n",
      "002 \t00140/00386 \t84.18 \t-1.845274\t-1.867314\t1.00e-03\n",
      "002 \t00150/00386 \t85.10 \t-1.848608\t-1.856036\t1.00e-03\n",
      "002 \t00160/00386 \t86.02 \t-1.832840\t-1.873702\t1.00e-03\n",
      "002 \t00170/00386 \t86.94 \t-1.857988\t-1.863222\t1.00e-03\n",
      "002 \t00180/00386 \t87.86 \t-1.835697\t-1.860078\t1.00e-03\n",
      "002 \t00190/00386 \t88.78 \t-1.846729\t-1.864181\t1.00e-03\n",
      "002 \t00200/00386 \t89.69 \t-1.888151\t-1.863884\t1.00e-03\n",
      "002 \t00210/00386 \t90.62 \t-1.849999\t-1.881562\t1.00e-03\n",
      "002 \t00220/00386 \t91.54 \t-1.854887\t-1.872095\t1.00e-03\n",
      "002 \t00230/00386 \t92.45 \t-1.863407\t-1.868744\t1.00e-03\n",
      "002 \t00240/00386 \t93.38 \t-1.854674\t-1.884382\t1.00e-03\n",
      "002 \t00250/00386 \t94.30 \t-1.868399\t-1.864020\t1.00e-03\n",
      "002 \t00260/00386 \t95.21 \t-1.863417\t-1.889187\t1.00e-03\n",
      "002 \t00270/00386 \t96.13 \t-1.881871\t-1.884237\t1.00e-03\n",
      "002 \t00280/00386 \t97.06 \t-1.850028\t-1.891013\t1.00e-03\n",
      "002 \t00290/00386 \t97.98 \t-1.875076\t-1.878747\t1.00e-03\n",
      "002 \t00300/00386 \t98.90 \t-1.880158\t-1.897750\t1.00e-03\n",
      "002 \t00310/00386 \t99.83 \t-1.863097\t-1.891374\t1.00e-03\n",
      "002 \t00320/00386 \t100.75 \t-1.877018\t-1.896091\t1.00e-03\n",
      "002 \t00330/00386 \t101.68 \t-1.891712\t-1.894671\t1.00e-03\n",
      "002 \t00340/00386 \t102.60 \t-1.894228\t-1.901844\t1.00e-03\n",
      "002 \t00350/00386 \t103.52 \t-1.894297\t-1.903787\t1.00e-03\n",
      "002 \t00360/00386 \t104.45 \t-1.890099\t-1.879888\t1.00e-03\n",
      "002 \t00370/00386 \t105.37 \t-1.892434\t-1.908042\t1.00e-03\n",
      "002 \t00380/00386 \t106.28 \t-1.885140\t-1.874278\t1.00e-03\n",
      "003 \t00000/00386 \t106.88 \t-1.877840\t-1.886069\t1.00e-03\n",
      "003 \t00010/00386 \t107.80 \t-1.889734\t-1.899675\t1.00e-03\n",
      "003 \t00020/00386 \t108.72 \t-1.893279\t-1.890959\t1.00e-03\n",
      "003 \t00030/00386 \t109.64 \t-1.880632\t-1.899945\t1.00e-03\n",
      "003 \t00040/00386 \t110.56 \t-1.892046\t-1.876218\t1.00e-03\n",
      "003 \t00050/00386 \t111.48 \t-1.896519\t-1.904756\t1.00e-03\n",
      "003 \t00060/00386 \t112.39 \t-1.896091\t-1.896178\t1.00e-03\n",
      "003 \t00070/00386 \t113.31 \t-1.898386\t-1.902847\t1.00e-03\n",
      "003 \t00080/00386 \t114.23 \t-1.885643\t-1.915501\t1.00e-03\n",
      "003 \t00090/00386 \t115.15 \t-1.901937\t-1.917285\t1.00e-03\n",
      "003 \t00100/00386 \t116.07 \t-1.905983\t-1.888528\t1.00e-03\n",
      "003 \t00110/00386 \t116.99 \t-1.901809\t-1.925129\t1.00e-03\n",
      "003 \t00120/00386 \t117.91 \t-1.907768\t-1.903622\t1.00e-03\n",
      "003 \t00130/00386 \t118.84 \t-1.899159\t-1.914343\t1.00e-03\n",
      "003 \t00140/00386 \t119.77 \t-1.892270\t-1.918006\t1.00e-03\n",
      "003 \t00150/00386 \t120.70 \t-1.912346\t-1.910899\t1.00e-03\n",
      "003 \t00160/00386 \t121.62 \t-1.919837\t-1.910378\t1.00e-03\n",
      "003 \t00170/00386 \t122.54 \t-1.908609\t-1.924062\t1.00e-03\n",
      "003 \t00180/00386 \t123.46 \t-1.908703\t-1.931149\t1.00e-03\n",
      "003 \t00190/00386 \t124.38 \t-1.910527\t-1.927101\t1.00e-03\n",
      "003 \t00200/00386 \t125.30 \t-1.909263\t-1.905454\t1.00e-03\n",
      "003 \t00210/00386 \t126.22 \t-1.904163\t-1.918946\t1.00e-03\n",
      "003 \t00220/00386 \t127.14 \t-1.907287\t-1.922304\t1.00e-03\n",
      "003 \t00230/00386 \t128.06 \t-1.908487\t-1.921734\t1.00e-03\n",
      "003 \t00240/00386 \t128.99 \t-1.912874\t-1.922181\t1.00e-03\n",
      "003 \t00250/00386 \t129.91 \t-1.898555\t-1.939115\t1.00e-03\n",
      "003 \t00260/00386 \t130.84 \t-1.920853\t-1.929237\t1.00e-03\n",
      "003 \t00270/00386 \t131.76 \t-1.910484\t-1.911819\t1.00e-03\n",
      "003 \t00280/00386 \t132.69 \t-1.910487\t-1.949551\t1.00e-03\n",
      "003 \t00290/00386 \t133.61 \t-1.901237\t-1.926454\t1.00e-03\n",
      "003 \t00300/00386 \t134.54 \t-1.918076\t-1.914649\t1.00e-03\n",
      "003 \t00310/00386 \t135.46 \t-1.913457\t-1.920820\t1.00e-03\n",
      "003 \t00320/00386 \t136.39 \t-1.908211\t-1.940013\t1.00e-03\n",
      "003 \t00330/00386 \t137.31 \t-1.913085\t-1.932312\t1.00e-03\n",
      "003 \t00340/00386 \t138.22 \t-1.927219\t-1.934131\t1.00e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "003 \t00350/00386 \t139.14 \t-1.931298\t-1.923430\t1.00e-03\n",
      "003 \t00360/00386 \t140.06 \t-1.927461\t-1.952020\t1.00e-03\n",
      "003 \t00370/00386 \t140.98 \t-1.919500\t-1.887288\t1.00e-03\n",
      "003 \t00380/00386 \t141.90 \t-1.906447\t-1.942555\t1.00e-03\n",
      "004 \t00000/00386 \t142.49 \t-1.918944\t-1.957811\t1.00e-03\n",
      "004 \t00010/00386 \t143.41 \t-1.929285\t-1.928326\t1.00e-03\n",
      "004 \t00020/00386 \t144.34 \t-1.918571\t-1.931168\t1.00e-03\n",
      "004 \t00030/00386 \t145.25 \t-1.916368\t-1.903895\t1.00e-03\n",
      "004 \t00040/00386 \t146.17 \t-1.920843\t-1.955951\t1.00e-03\n",
      "004 \t00050/00386 \t147.09 \t-1.929709\t-1.945561\t1.00e-03\n",
      "004 \t00060/00386 \t148.01 \t-1.942571\t-1.941762\t1.00e-03\n",
      "004 \t00070/00386 \t148.93 \t-1.919461\t-1.911211\t1.00e-03\n",
      "004 \t00080/00386 \t149.85 \t-1.921940\t-1.926642\t1.00e-03\n",
      "004 \t00090/00386 \t150.77 \t-1.927855\t-1.932355\t1.00e-03\n",
      "004 \t00100/00386 \t151.69 \t-1.915111\t-1.942052\t1.00e-03\n",
      "004 \t00110/00386 \t152.61 \t-1.938407\t-1.941173\t1.00e-03\n",
      "004 \t00120/00386 \t153.52 \t-1.937039\t-1.940641\t1.00e-03\n",
      "004 \t00130/00386 \t154.44 \t-1.935758\t-1.942324\t1.00e-03\n",
      "004 \t00140/00386 \t155.36 \t-1.925964\t-1.957848\t1.00e-03\n",
      "004 \t00150/00386 \t156.28 \t-1.934542\t-1.967964\t1.00e-03\n",
      "004 \t00160/00386 \t157.20 \t-1.924143\t-1.949651\t1.00e-03\n",
      "004 \t00170/00386 \t158.12 \t-1.920063\t-1.945832\t1.00e-03\n",
      "004 \t00180/00386 \t159.04 \t-1.933870\t-1.916975\t1.00e-03\n",
      "004 \t00190/00386 \t159.96 \t-1.926808\t-1.934668\t1.00e-03\n",
      "004 \t00200/00386 \t160.87 \t-1.907995\t-1.930839\t1.00e-03\n",
      "004 \t00210/00386 \t161.79 \t-1.930479\t-1.955794\t1.00e-03\n",
      "004 \t00220/00386 \t162.72 \t-1.927870\t-1.947278\t1.00e-03\n",
      "004 \t00230/00386 \t163.64 \t-1.930006\t-1.925860\t1.00e-03\n",
      "004 \t00240/00386 \t164.56 \t-1.928080\t-1.922012\t1.00e-03\n",
      "004 \t00250/00386 \t165.48 \t-1.924250\t-1.943863\t1.00e-03\n",
      "004 \t00260/00386 \t166.40 \t-1.917612\t-1.955196\t1.00e-03\n",
      "004 \t00270/00386 \t167.32 \t-1.930702\t-1.937883\t1.00e-03\n",
      "004 \t00280/00386 \t168.24 \t-1.938800\t-1.947730\t1.00e-03\n",
      "004 \t00290/00386 \t169.16 \t-1.946192\t-1.965554\t1.00e-03\n",
      "004 \t00300/00386 \t170.08 \t-1.942667\t-1.960590\t1.00e-03\n",
      "004 \t00310/00386 \t171.00 \t-1.950058\t-1.940519\t1.00e-03\n",
      "004 \t00320/00386 \t171.92 \t-1.932196\t-1.928305\t1.00e-03\n",
      "004 \t00330/00386 \t172.84 \t-1.935362\t-1.945050\t1.00e-03\n",
      "004 \t00340/00386 \t173.76 \t-1.942846\t-1.948465\t1.00e-03\n",
      "004 \t00350/00386 \t174.68 \t-1.940517\t-1.954788\t1.00e-03\n",
      "004 \t00360/00386 \t175.60 \t-1.947282\t-1.951196\t1.00e-03\n",
      "004 \t00370/00386 \t176.52 \t-1.950573\t-1.914731\t1.00e-03\n",
      "004 \t00380/00386 \t177.44 \t-1.938036\t-1.958415\t1.00e-03\n"
     ]
    }
   ],
   "source": [
    "config = CONFIG()\n",
    "if not config.mock:\n",
    "    hxtorch.init_hardware()\n",
    "\n",
    "data = ExampleData(config)\n",
    "\n",
    "model_floating = EXAMPLEcINN_hx(config)\n",
    "#model_floating.load(config.save_dir + \"hx_mock_example_cinn_50epochs_mock.pt\")\n",
    "\n",
    "t_start = time()\n",
    "\n",
    "model_floating.train()\n",
    "nll_mean = []\n",
    "\n",
    "val_losses_means = np.array([])\n",
    "val_losses = np.array([])\n",
    "\n",
    "\n",
    "try:\n",
    "    for i_epoch in range(-config.pre_low_lr, config.n_epochs):\n",
    "        if i_epoch < 0:\n",
    "            for param_group in model.optimizer.param_groups:\n",
    "                param_group['lr'] = config.lr * 2e-2\n",
    "\n",
    "        for i_batch, (x, l) in enumerate(data.train_loader):\n",
    "\n",
    "            x, l = x.to(config.device), l.to(config.device)\n",
    "            z, log_j = model_floating(x, l)\n",
    "\n",
    "            nll = torch.mean(z**2) / 2 - torch.mean(log_j) / np.prod(config.img_size)\n",
    "            nll.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model_floating.trainable_parameters,\n",
    "                                           config.clip_grad_norm)\n",
    "\n",
    "            nll_mean.append(nll.item())\n",
    "\n",
    "            model_floating.optimizer.step()\n",
    "            model_floating.optimizer.zero_grad()\n",
    "\n",
    "            print_interval = 10 if not config.mock else 50\n",
    "            if not i_batch % print_interval:\n",
    "                with torch.no_grad():\n",
    "                    z, log_j = model_floating(data.val_x, data.val_l)\n",
    "                    nll_val = torch.mean(z**2) / 2 - torch.mean(log_j) / np.prod(config.img_size)\n",
    "\n",
    "                print('%.3i \\t%.5i/%.5i \\t%.2f \\t%.6f\\t%.6f\\t%.2e' % (i_epoch,\n",
    "                                                                i_batch, len(data.train_loader),\n",
    "                                                                (time() - t_start)/60.,\n",
    "                                                                np.mean(nll_mean),\n",
    "                                                                nll_val.item(),\n",
    "                                                                model_floating.optimizer.param_groups[0]['lr'],\n",
    "                                                                ), flush=True)\n",
    "                \n",
    "                val_losses_means = np.append(val_losses_means, np.mean(nll_mean))\n",
    "                val_losses = np.append(val_losses, nll_val.item())\n",
    "                \n",
    "                nll_mean = []\n",
    "                \n",
    "            if (i_batch % config.checkpoint_save_interval) == 0:\n",
    "                model_floating.save(config.filename + 'floating_checkpoint_%.4i' % (i_batch * (1-config.checkpoint_save_overwrite)))\n",
    "\n",
    "        model_floating.weight_scheduler.step()\n",
    "\n",
    "        #if (i_epoch % config.checkpoint_save_interval) == 0:\n",
    "        #    model_floating.save(config.filename + 'floating_checkpoint_%.4i' % (i_epoch * (1-config.checkpoint_save_overwrite)))\n",
    "\n",
    "    model_floating.save(config.filename)\n",
    "\n",
    "except BaseException as b:\n",
    "    if config.checkpoint_on_error:\n",
    "        model_floating.save(config.filename + \"floating_ABORT\")\n",
    "    raise b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(config.save_dir + \"/val_losses_means_50epochs_mock_1epoch_hw_w8mock.txt\", val_losses_means)\n",
    "np.savetxt(config.save_dir + \"/val_losses_50epochs_mock_1epoch_hw_w8mock.txt\", val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_config = CONFIG\n",
    "load_model = EXAMPLEcINN_hx(load_config)\n",
    "load_model.load(load_config.save_dir + \"hx_mock_example_cinn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples(model, data, config, label):\n",
    "    '''Produces and shows cINN samples for a given label.'''\n",
    "\n",
    "    N_samples = 100\n",
    "    l = torch.LongTensor(N_samples).to(config.device)\n",
    "    l[:] = label\n",
    "\n",
    "    z = 1.0 * torch.randn(N_samples, np.prod(config.img_size)).to(config.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        samples = model.reverse_sample(z, l)[0].cpu().numpy()\n",
    "\n",
    "    full_image = np.zeros((config.img_size[0]*10, config.img_size[1]*10))\n",
    "\n",
    "    qwe = []\n",
    "    for k in range(N_samples):\n",
    "        i, j = k // 10, k % 10\n",
    "        full_image[config.img_size[0] * i : config.img_size[1] * (i + 1),\n",
    "                   config.img_size[0] * j : config.img_size[1] * (j + 1)] = samples[k, 0]\n",
    "        qwe.append(np.argmax(samples[k, 0]))\n",
    "    qwe = np.array(qwe)\n",
    "    print(f\"{len(qwe[qwe==0])/len(qwe)}\\t{len(qwe[qwe==1])/len(qwe)}\\t{len(qwe[qwe==2])/len(qwe)}\\t{len(qwe[qwe==3])/len(qwe)}\")\n",
    "        \n",
    "\n",
    "    full_image = np.clip(full_image, 0, 1)\n",
    "    plt.figure()\n",
    "    plt.title(F'Generated digits for c={label}')\n",
    "    plt.imshow(full_image, vmin=0, vmax=1, cmap='gray')\n",
    "    plt.savefig(config.save_dir + f\"/eval_{label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration run - floating model\n",
      "0.96\t0.0\t0.0\t0.04\n",
      "0.0\t0.98\t0.02\t0.0\n",
      "0.0\t0.02\t0.98\t0.0\n",
      "0.09\t0.03\t0.0\t0.88\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Calibration run - floating model\")\n",
    "for k in range(4):\n",
    "    show_samples(load_model, data, config, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0351,  0.6105, -1.5245,  0.9682,  0.7312,  0.7136,  0.4641, -1.3218,\n",
      "         -0.3367, -0.5885],\n",
      "        [-1.1072, -1.9708, -0.3163, -0.8902, -0.7194, -0.2035, -0.7731, -1.8471,\n",
      "          1.0730,  0.6621],\n",
      "        [ 0.2240,  0.9835, -0.6787,  0.3568, -1.7117,  2.2486,  0.5351, -0.6314,\n",
      "          1.2296, -0.3926]])\n",
      "tensor([2.2486, 2.2486, 2.2486, 2.2486, 2.2486, 2.2486, 2.2486, 2.2486, 2.2486,\n",
      "        2.2486])\n",
      "Parameter containing:\n",
      "tensor([13.7864, 13.7864, 13.7864, 13.7864, 13.7864, 13.7864, 13.7864, 13.7864,\n",
      "        13.7864, 13.7864])\n",
      "tensor([[  0.,   8., -22.,  13.,  10.,   9.,   6., -19.,  -5.,  -9.],\n",
      "        [-16., -28.,  -5., -13., -10.,  -3., -11., -26.,  14.,   9.],\n",
      "        [  3.,  13., -10.,   4., -24.,  31.,   7.,  -9.,  16.,  -6.]])\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "max_out = 31\n",
    "weight = Parameter(torch.empty(16), requires_grad=False)\n",
    "per_feature = False\n",
    "\n",
    "#x = torch.Tensor([[31, 0, -31], [-10.5, 0, 7]])\n",
    "x = torch.randn(3, 10)\n",
    "x[torch.abs(x) < 0.5] = x[torch.abs(x) < 0.5]\n",
    "print(x)\n",
    "\n",
    "max_abs, _ = torch.max(torch.abs(x), axis=0)\n",
    "if not per_feature:\n",
    "    max_abs.fill_(max_abs.max())\n",
    "#print(max_abs)\n",
    "max_abs[max_abs == 0] = max_out\n",
    "print(max_abs)\n",
    "weight = nn.Parameter(max_out / max_abs, requires_grad=False)\n",
    "print(weight)\n",
    "out = torch.floor(x * weight)\n",
    "print(out)\n",
    "out_diag = torch.floor(F.linear(x, torch.diag(weight)))\n",
    "#print(out_diag)\n",
    "\n",
    "print(\"-------------------\")\n",
    "max_abss = torch.max(torch.abs(x))\n",
    "factor = _hxtorch.constants.input_activation_max / max_abss if max_abss != 0 else 1\n",
    "            #factor = torch.Tensor(_hxtorch.constants.input_activation_max).repeat(max_abs.size()) /  \\\n",
    "                #max_abs if max_abs != 0 else 1\n",
    "res = torch.floor(x * factor)\n",
    "#print(res)\n",
    "\n",
    "assert out.all() == out_diag.all()\n",
    "assert out.all() == res.all()\n",
    "assert out.all() < 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
