{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.optim\n",
    "import torch.nn as nn\n",
    "\n",
    "import hxtorch\n",
    "import _hxtorch\n",
    "import hxtorch.nn as hxnn\n",
    "\n",
    "import FrEIA.framework as Ff\n",
    "import FrEIA.modules as Fm\n",
    "\n",
    "import quantized_cINN.common as com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, n_samples=100000, img_size=(2, 2), transform=None):\n",
    "        self.n_samples = n_samples\n",
    "        self.img_size = img_size\n",
    "        self.transform = transform\n",
    "        self.data, self.targets = self._generate_data()\n",
    "\n",
    "    def _generate_data(self):\n",
    "        floor = 0.2\n",
    "        intensity = (0, 1)\n",
    "\n",
    "        high = self.img_size[0] * self.img_size[1]\n",
    "        labels = torch.randint(low=0, high=high, size=(self.n_samples, ))\n",
    "        imgs = floor * torch.rand((self.n_samples, 1, *self.img_size))\n",
    "        imgs[torch.arange(self.n_samples), :, labels%2, labels//2] += intensity[1] - floor \n",
    "        return imgs, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "    \n",
    "        X = self.data[idx].numpy()\n",
    "        y = self.targets[idx].reshape(-1).numpy()\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "        return X, y\n",
    "\n",
    "class ExampleData:\n",
    "\n",
    "    def __init__(self, config: object):\n",
    "        from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "        import torchvision.transforms as T\n",
    "\n",
    "        self.c = config\n",
    "\n",
    "        self.train_data = ExampleDataset(transform=T.ToTensor())\n",
    "        self.test_data = ExampleDataset(transform=T.ToTensor())\n",
    "\n",
    "        # Sample a fixed batch of 1024 validation examples\n",
    "        self.val_x, self.val_l = zip(*list(self.train_data[i] for i in range(1024)))\n",
    "        self.val_x = torch.stack(self.val_x, 0).to(config.device)\n",
    "        self.val_l = torch.LongTensor(self.val_l).to(config.device)\n",
    "\n",
    "        # Exclude the validation batch from the training data\n",
    "        self.train_data.data = self.train_data.data[1024:]\n",
    "        self.train_data.targets = self.train_data.targets[1024:]\n",
    "\n",
    "        ## Add the noise-augmentation to the (non-validation) training data:\n",
    "        #augm_func = lambda x: x + self.c.add_image_noise * torch.randn_like(x)\n",
    "        #self.train_data.transform = T.Compose([self.train_data.transform, augm_func])\n",
    "\n",
    "        self.train_loader = DataLoader(self.train_data,\n",
    "                                       batch_size=self.c.batch_size,\n",
    "                                       shuffle=True,\n",
    "                                       num_workers=self.c.n_workers,\n",
    "                                       pin_memory=True, drop_last=True)\n",
    "        self.test_loader = DataLoader(self.test_data,\n",
    "                                      batch_size=self.c.batch_size,\n",
    "                                      shuffle=False,\n",
    "                                      num_workers=self.c.n_workers,\n",
    "                                      pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## configuaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG(com.baseCONFIG):\n",
    "    \"\"\"\n",
    "    Namspace for configuration\n",
    "    \"\"\"\n",
    "    # Data\n",
    "    data_mean = None\n",
    "    data_std = None\n",
    "    add_image_noise = None\n",
    "\n",
    "    img_size = (2, 2)\n",
    "    device = \"cpu\"\n",
    "    n_workers = 8\n",
    "\n",
    "    mock = True\n",
    "\n",
    "    # Training\n",
    "    lr = 1e-3\n",
    "    batch_size = 256\n",
    "    weight_decay = 1e-5\n",
    "    gamma = 0.1\n",
    "    milestones = [20, 40]\n",
    "    betas = (0.9, 0.999)\n",
    "\n",
    "    n_epochs = 20\n",
    "\n",
    "    init_scale = 0.03\n",
    "    pre_low_lr = 0\n",
    "    \n",
    "    clip_grad_norm = 100.0\n",
    "\n",
    "    # Architecture\n",
    "    n_blocks = 8\n",
    "    internal_width = 16\n",
    "    clamping = 1.0\n",
    "    fc_dropout = 0.0\n",
    "\n",
    "    # Logging/preview\n",
    "    loss_names = ['L']\n",
    "    preview_upscale = 3                         # Scale up the images for preview\n",
    "    sampling_temperature = 0.8                  # Sample at a reduced temperature for the preview\n",
    "    progress_bar = True                         # Show a progress bar of each epoch\n",
    "    eval_steps_interploation = 12\n",
    "    eval_seeds_interpolation  = (51, 89)\n",
    "\n",
    "    # Validation\n",
    "    pca_weights = [\n",
    "        [(0,0.55)],\n",
    "        [(1,0.1), (3, 0.4), (4, 0.5)],\n",
    "        [(2,0.33), (3, 0.33), (1, -0.33)]]\n",
    "    pca_gridsize = 10\n",
    "    pca_extent = 8.\n",
    "\n",
    "\n",
    "    # Paths\n",
    "    mnist_data = \"aml-cinn/mnist_data\"\n",
    "    save_dir = \"out_hx_mock/\"\n",
    "\n",
    "    load_file = \"out_hx_mock/hx_mock_example_checkpoint.pt\"\n",
    "    filename = \"out_hx_mock/hx_mock_example_cinn.pt\"\n",
    "\n",
    "    checkpoint_save_interval =  20\n",
    "    checkpoint_save_overwrite = True\n",
    "    checkpoint_on_error = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShiftNScale(nn.Module):\n",
    "\n",
    "    def __init__(self, shift=0., scale=1.):\n",
    "        super().__init__()\n",
    "        self.shift = shift\n",
    "        self.scale = scale\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"Subnet output scaling\")\n",
    "        print(f\"\\tbefore scaling\\trange ({torch.min(x):.2f}, {torch.max(x):.2f})\\tvalue {torch.mean(x):.2f}+/-{torch.std(x):.2f}\")\n",
    "        x = (x - torch.mean(x)) / torch.std(x)\n",
    "        x = x * self.scale + self.shift\n",
    "        print(f\"\\tafter scaling\\trange ({torch.min(x):.2f}, {torch.max(x):.2f})\\tvalue {torch.mean(x):.2f}+/-{torch.std(x):.2f}\")\n",
    "        return x\n",
    "\n",
    "class EXAMPLEcINN_hx(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: object=CONFIG):\n",
    "        super().__init__()\n",
    "        self.stop = False\n",
    "\n",
    "        self.c = config\n",
    "\n",
    "        self.cinn = self.build_inn()\n",
    "\n",
    "        self.trainable_parameters = [p for p in self.cinn.parameters() if p.requires_grad]\n",
    "        for p in self.trainable_parameters:\n",
    "            p.data = self.c.init_scale * torch.randn_like(p)\n",
    "\n",
    "        self.cinn.to(self.c.device)\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.trainable_parameters,\n",
    "                                          lr=self.c.lr,\n",
    "                                          weight_decay=self.c.weight_decay)\n",
    "        self.weight_scheduler = torch.optim.lr_scheduler.MultiStepLR(self.optimizer,\n",
    "                                                                #step_size=1,\n",
    "                                                                milestones=self.c.milestones,\n",
    "                                                                gamma=self.c.gamma)\n",
    "\n",
    "    def build_inn(self):\n",
    "\n",
    "        def fc_subnet(ch_in, ch_out):\n",
    "            net = OrderedDict([\n",
    "                (\"lin_1\", hxnn.Linear(in_features=ch_in,\n",
    "                                      out_features=self.c.internal_width,\n",
    "                                      bias=True,\n",
    "                                      num_sends=2,\n",
    "                                      wait_between_events=2,\n",
    "                                      mock=self.c.mock,\n",
    "                                      input_transform=self.scale_input_clamp)),\n",
    "                (\"relu1\", hxnn.ConvertingReLU(shift=1,\n",
    "                                              mock=True)),\n",
    "                #(\"relu1\", nn.ReLU()),\n",
    "                (\"lin_2\", hxnn.Linear(in_features=self.c.internal_width,\n",
    "                                      out_features=ch_out,\n",
    "                                      bias=False,\n",
    "                                      num_sends=3,\n",
    "                                      wait_between_events=2,\n",
    "                                      mock=self.c.mock,\n",
    "                                      input_transform=self.scale_input_clamp)),\n",
    "                (\"resca\", ShiftNScale())\n",
    "            ])\n",
    "            return nn.Sequential(net)\n",
    "\n",
    "        cond = Ff.ConditionNode(4)\n",
    "\n",
    "        nodes = [Ff.InputNode(1, *self.c.img_size)]\n",
    "        nodes.append(Ff.Node(nodes[-1], Fm.Flatten, {}))\n",
    "\n",
    "        for k in range(self.c.n_blocks):\n",
    "            nodes.append(Ff.Node(nodes[-1], Fm.PermuteRandom,\n",
    "                                 {\"seed\": k}))\n",
    "            nodes.append(Ff.Node(nodes[-1], Fm.GLOWCouplingBlock,\n",
    "                                 {\"subnet_constructor\": fc_subnet,\n",
    "                                  \"clamp\": self.c.clamping},\n",
    "                                  conditions=cond))\n",
    "\n",
    "        nodes += [cond, Ff.OutputNode(nodes[-1])]\n",
    "        return Ff.ReversibleGraphNet(nodes, verbose=False)\n",
    "\n",
    "    @staticmethod\n",
    "    def scale_input_clamp(x_in: torch.Tensor) -> torch.Tensor:\n",
    "        print(f\"Subnet input scaling\")\n",
    "        print(f\"\\tbefore scaling\\trange ({torch.min(x_in):.2f}, {torch.max(x_in):.2f})\\tvalue {torch.mean(x_in):.2f}+/-{torch.std(x_in):.2f}\")\n",
    "\n",
    "        max_in = torch.max(torch.cat((x_in, -x_in)))\n",
    "        shift = _hxtorch.constants.input_activation_max // 2\n",
    "        factor = shift / max_in if max_in > 0 else 1\n",
    "        x_in = x_in * factor + shift\n",
    "        print(f\"\\tafter scaling\\trange ({torch.min(x_in):.2f}, {torch.max(x_in):.2f})\\tvalue {torch.mean(x_in):.2f}+/-{torch.std(x_in):.2f}\")\n",
    "        return x_in\n",
    "\n",
    "    def forward(self, x, l, jac=True):\n",
    "        if self.stop:\n",
    "            raise\n",
    "        self.stop = True\n",
    "        print(x[0])\n",
    "        return self.cinn(x, c=one_hot(l), jac=jac)\n",
    "\n",
    "    def reverse_sample(self, z, l, jac=True):\n",
    "        return self.cinn(z, c=one_hot(l), rev=True, jac=jac)\n",
    "\n",
    "    def save(self, name):\n",
    "        save_dict = {\"opt\": self.optimizer.state_dict(),\n",
    "                     \"net\": self.cinn.state_dict(),\n",
    "                     \"lr\": self.weight_scheduler.state_dict()}\n",
    "        torch.save(save_dict, name)\n",
    "\n",
    "    def load(self, name):\n",
    "        state_dicts = torch.load(name)\n",
    "        self.cinn.load_state_dict(state_dicts[\"net\"])\n",
    "        try:\n",
    "            self.optimizer.load_state_dict(state_dicts[\"opt\"])\n",
    "        except ValueError:\n",
    "            print(\"Cannot load optimizer for some reason or other\")\n",
    "        try:\n",
    "            self.weight_scheduler.load_state_dict(state_dicts[\"lr\"])\n",
    "        except ValueError:\n",
    "            print(\"Cannot load optimizer for some reason or other\")\n",
    "\n",
    "    def fuse_model(self):\n",
    "        for m in self.cinn.modules():\n",
    "            if type(m) == nn.Sequential:\n",
    "                try:\n",
    "                    torch.quantization.fuse_modules(m, [\"lin_1\", \"relu1\"], inplace=True)\n",
    "                except AssertionError:\n",
    "                    print(\"fuse_model failed here:\", m)\n",
    "\n",
    "    def quantize(self, calibration: callable=None):\n",
    "        self.eval()\n",
    "        self.fuse_model()\n",
    "        self.qconfig = torch.quantization.default_qconfig\n",
    "\n",
    "        torch.quantization.prepare(self, inplace=True)\n",
    "\n",
    "        if calibration:\n",
    "            calibration(self)\n",
    "\n",
    "        torch.quantization.convert(self, inplace=True)\n",
    "\n",
    "            \n",
    "def one_hot(labels, out=None):\n",
    "    '''\n",
    "    Convert LongTensor labels (contains labels 0-9), to a one hot vector.\n",
    "    Can be done in-place using the out-argument (faster, re-use of GPU memory)\n",
    "    '''\n",
    "    if out is None:\n",
    "        out = torch.zeros(labels.shape[0], 4).to(labels.device)\n",
    "    else:\n",
    "        out.zeros_()\n",
    "    out.scatter_(dim=1, index=labels.view(-1,1), value=1.)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1137, 0.9166]],\n",
      "\n",
      "        [[0.0083, 0.0546]]])\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (0.00, 1.00)\tvalue 0.27+/-0.41\n",
      "\tafter scaling\trange (15.00, 30.00)\tvalue 19.04+/-6.14\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (0.00, 3.00)\tvalue 0.15+/-0.42\n",
      "\tafter scaling\trange (15.00, 30.00)\tvalue 15.76+/-2.08\n",
      "Subnet output scaling\n",
      "\tbefore scaling\trange (-7.00, 7.00)\tvalue -0.34+/-2.00\n",
      "\tafter scaling\trange (-3.33, 3.67)\tvalue -0.00+/-1.00\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (-3.33, inf)\tvalue inf+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet output scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (-3.33, inf)\tvalue inf+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet output scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet output scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet output scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet output scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet output scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet output scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet output scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet output scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet output scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet output scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet output scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet output scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet output scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet input scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "Subnet output scaling\n",
      "\tbefore scaling\trange (nan, nan)\tvalue nan+/-nan\n",
      "\tafter scaling\trange (nan, nan)\tvalue nan+/-nan\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-6e382787ef1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_on_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mmodel_floating\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"floating_ABORT\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-6e382787ef1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mi_batch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                     \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_floating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                     \u001b[0mnll_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_j\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spack_views/visionary-dls/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-350c5ea976ba>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, l, jac)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "config = CONFIG()\n",
    "config.n_epochs = 5\n",
    "data = ExampleData(config)\n",
    "\n",
    "model_floating = EXAMPLEcINN_hx(config)\n",
    "\n",
    "t_start = time()\n",
    "\n",
    "model_floating.train()\n",
    "nll_mean = []\n",
    "\n",
    "\n",
    "try:\n",
    "    for i_epoch in range(-config.pre_low_lr, config.n_epochs):\n",
    "        if i_epoch < 0:\n",
    "            for param_group in model.optimizer.param_groups:\n",
    "                param_group['lr'] = config.lr * 2e-2\n",
    "\n",
    "        for i_batch, (x, l) in enumerate(data.train_loader):\n",
    "\n",
    "            x, l = x.to(config.device), l.to(config.device)\n",
    "            z, log_j = model_floating(x, l)\n",
    "\n",
    "            nll = torch.mean(z**2) / 2 - torch.mean(log_j) / np.prod(config.img_size)\n",
    "            nll.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model_floating.trainable_parameters,\n",
    "                                           config.clip_grad_norm)\n",
    "\n",
    "            nll_mean.append(nll.item())\n",
    "\n",
    "            model_floating.optimizer.step()\n",
    "            model_floating.optimizer.zero_grad()\n",
    "\n",
    "            if not i_batch % 50:\n",
    "                with torch.no_grad():\n",
    "                    z, log_j = model_floating(data.val_x, data.val_l)\n",
    "                    nll_val = torch.mean(z**2) / 2 - torch.mean(log_j) / np.prod(config.img_size)\n",
    "\n",
    "                print('%.3i \\t%.5i/%.5i \\t%.2f \\t%.6f\\t%.6f\\t%.2e' % (i_epoch,\n",
    "                                                                i_batch, len(data.train_loader),\n",
    "                                                                (time() - t_start)/60.,\n",
    "                                                                np.mean(nll_mean),\n",
    "                                                                nll_val.item(),\n",
    "                                                                model_floating.optimizer.param_groups[0]['lr'],\n",
    "                                                                ), flush=True)\n",
    "                nll_mean = []\n",
    "\n",
    "        model_floating.weight_scheduler.step()\n",
    "\n",
    "        if (i_epoch % config.checkpoint_save_interval) == 0:\n",
    "            model_floating.save(config.filename + 'floating_checkpoint_%.4i' % (i_epoch * (1-config.checkpoint_save_overwrite)))\n",
    "\n",
    "    #model_fp32.save(config.filename)\n",
    "\n",
    "except BaseException as b:\n",
    "    if config.checkpoint_on_error:\n",
    "        model_floating.save(config.filename + \"floating_ABORT\")\n",
    "    raise b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples(model, data, config, label):\n",
    "    '''produces and shows cINN samples for a given label (0-9)'''\n",
    "\n",
    "    N_samples = 100\n",
    "    l = torch.LongTensor(N_samples).to(config.device)\n",
    "    l[:] = label\n",
    "\n",
    "    z = 1.0 * torch.randn(N_samples, np.prod(config.img_size)).to(config.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        samples = model.reverse_sample(z, l)[0].cpu().numpy()\n",
    "        samples = data.unnormalize(samples)\n",
    "\n",
    "    full_image = np.zeros((config.img_size[0]*10, config.img_size[1]*10))\n",
    "\n",
    "    qwe = []\n",
    "    for k in range(N_samples):\n",
    "        i, j = k // 10, k % 10\n",
    "        full_image[config.img_size[0] * i : config.img_size[1] * (i + 1),\n",
    "                   config.img_size[0] * j : config.img_size[1] * (j + 1)] = samples[k, 0]\n",
    "        qwe.append(np.argmax(samples[k, 0]))\n",
    "    qwe = np.array(qwe)\n",
    "    print(f\"{len(qwe[qwe==0])/len(qwe)}\\t{len(qwe[qwe==1])/len(qwe)}\\t{len(qwe[qwe==2])/len(qwe)}\\t{len(qwe[qwe==3])/len(qwe)}\")\n",
    "        \n",
    "\n",
    "    full_image = np.clip(full_image, 0, 1)\n",
    "    plt.figure()\n",
    "    plt.title(F'Generated digits for c={label}')\n",
    "    plt.imshow(full_image, vmin=0, vmax=1, cmap='gray')\n",
    "    plt.savefig(config.save_dir + f\"/eval_{label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (quant): QuantStub()\n",
      "  (lin_1): LinearReLU(\n",
      "    (0): Linear(in_features=6, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (relu1): Identity()\n",
      "  (lin_2): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (dequa): DeQuantStub()\n",
      ") QConfig(activation=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric))\n",
      "Sequential(\n",
      "  (quant): QuantStub()\n",
      "  (lin_1): LinearReLU(\n",
      "    (0): Linear(in_features=6, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (relu1): Identity()\n",
      "  (lin_2): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (dequa): DeQuantStub()\n",
      ") QConfig(activation=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric))\n",
      "Sequential(\n",
      "  (quant): QuantStub()\n",
      "  (lin_1): LinearReLU(\n",
      "    (0): Linear(in_features=6, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (relu1): Identity()\n",
      "  (lin_2): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (dequa): DeQuantStub()\n",
      ") QConfig(activation=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric))\n",
      "Sequential(\n",
      "  (quant): QuantStub()\n",
      "  (lin_1): LinearReLU(\n",
      "    (0): Linear(in_features=6, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (relu1): Identity()\n",
      "  (lin_2): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (dequa): DeQuantStub()\n",
      ") QConfig(activation=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric))\n",
      "Sequential(\n",
      "  (quant): QuantStub()\n",
      "  (lin_1): LinearReLU(\n",
      "    (0): Linear(in_features=6, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (relu1): Identity()\n",
      "  (lin_2): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (dequa): DeQuantStub()\n",
      ") QConfig(activation=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric))\n",
      "Sequential(\n",
      "  (quant): QuantStub()\n",
      "  (lin_1): LinearReLU(\n",
      "    (0): Linear(in_features=6, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (relu1): Identity()\n",
      "  (lin_2): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (dequa): DeQuantStub()\n",
      ") QConfig(activation=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric))\n",
      "Sequential(\n",
      "  (quant): QuantStub()\n",
      "  (lin_1): LinearReLU(\n",
      "    (0): Linear(in_features=6, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (relu1): Identity()\n",
      "  (lin_2): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (dequa): DeQuantStub()\n",
      ") QConfig(activation=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric))\n",
      "Sequential(\n",
      "  (quant): QuantStub()\n",
      "  (lin_1): LinearReLU(\n",
      "    (0): Linear(in_features=6, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (relu1): Identity()\n",
      "  (lin_2): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (dequa): DeQuantStub()\n",
      ") QConfig(activation=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric))\n",
      "Sequential(\n",
      "  (quant): QuantStub()\n",
      "  (lin_1): LinearReLU(\n",
      "    (0): Linear(in_features=6, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (relu1): Identity()\n",
      "  (lin_2): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (dequa): DeQuantStub()\n",
      ") QConfig(activation=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric))\n",
      "Sequential(\n",
      "  (quant): QuantStub()\n",
      "  (lin_1): LinearReLU(\n",
      "    (0): Linear(in_features=6, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (relu1): Identity()\n",
      "  (lin_2): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (dequa): DeQuantStub()\n",
      ") QConfig(activation=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric))\n",
      "Sequential(\n",
      "  (quant): QuantStub()\n",
      "  (lin_1): LinearReLU(\n",
      "    (0): Linear(in_features=6, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (relu1): Identity()\n",
      "  (lin_2): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (dequa): DeQuantStub()\n",
      ") QConfig(activation=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric))\n",
      "Sequential(\n",
      "  (quant): QuantStub()\n",
      "  (lin_1): LinearReLU(\n",
      "    (0): Linear(in_features=6, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (relu1): Identity()\n",
      "  (lin_2): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (dequa): DeQuantStub()\n",
      ") QConfig(activation=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric))\n",
      "Sequential(\n",
      "  (quant): QuantStub()\n",
      "  (lin_1): LinearReLU(\n",
      "    (0): Linear(in_features=6, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (relu1): Identity()\n",
      "  (lin_2): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (dequa): DeQuantStub()\n",
      ") QConfig(activation=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric))\n",
      "Sequential(\n",
      "  (quant): QuantStub()\n",
      "  (lin_1): LinearReLU(\n",
      "    (0): Linear(in_features=6, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (relu1): Identity()\n",
      "  (lin_2): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (dequa): DeQuantStub()\n",
      ") QConfig(activation=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric))\n",
      "Sequential(\n",
      "  (quant): QuantStub()\n",
      "  (lin_1): LinearReLU(\n",
      "    (0): Linear(in_features=6, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (relu1): Identity()\n",
      "  (lin_2): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (dequa): DeQuantStub()\n",
      ") QConfig(activation=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric))\n",
      "Sequential(\n",
      "  (quant): QuantStub()\n",
      "  (lin_1): LinearReLU(\n",
      "    (0): Linear(in_features=6, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (relu1): Identity()\n",
      "  (lin_2): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (dequa): DeQuantStub()\n",
      ") QConfig(activation=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric))\n",
      "Pre-Calibrated state dict with Observer\n",
      "OrderedDict([('cinn.module_list.1.perm', tensor([2, 3, 1, 0])), ('cinn.module_list.1.perm_inv', tensor([3, 2, 0, 1])), ('cinn.module_list.2.subnet1.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.2.subnet1.quant.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.2.subnet1.quant.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.2.subnet1.lin_1.0.weight', tensor([[-6.3718e-02,  2.2704e-02,  1.5997e-02, -9.9484e-02, -4.8681e-40,\n",
      "          8.9261e-02],\n",
      "        [ 1.2351e-01, -7.3390e-02, -1.3032e-01, -1.1414e-01,  1.5680e-01,\n",
      "          1.6682e-39],\n",
      "        [ 9.0425e-03,  3.9725e-03,  2.2071e-32, -1.9854e-38,  1.7462e-05,\n",
      "          9.9035e-03],\n",
      "        [ 1.1287e-01,  1.0318e-01, -6.9996e-02, -9.0046e-02,  1.1976e-01,\n",
      "          1.6756e-01],\n",
      "        [ 1.0469e-01,  7.9483e-02, -9.0949e-02, -1.0548e-01,  1.3954e-01,\n",
      "          1.9798e-01],\n",
      "        [-7.5446e-02,  1.2797e-01, -7.1518e-02, -7.6847e-02,  1.8507e-38,\n",
      "          1.6983e-01],\n",
      "        [ 8.4478e-02, -1.4780e-01,  2.1776e-01, -2.3118e-01,  1.2755e-01,\n",
      "          3.2281e-02],\n",
      "        [ 5.2725e-02, -2.1961e-01, -6.3929e-02, -1.0089e-01,  3.2166e-02,\n",
      "          2.0766e-38],\n",
      "        [-8.9426e-02, -1.1587e-01, -1.5234e-01,  2.3180e-01, -9.5839e-02,\n",
      "         -7.0867e-02],\n",
      "        [-4.5741e-02,  1.0398e-02,  1.6892e-01,  1.9478e-01, -1.3361e-01,\n",
      "         -2.3566e-01],\n",
      "        [ 1.7593e-03,  2.1866e-03, -1.3687e-03,  6.7889e-39, -8.3514e-08,\n",
      "          4.1697e-04],\n",
      "        [-4.9310e-02, -1.2655e-01,  2.7561e-01, -1.5909e-01,  5.5200e-02,\n",
      "          4.8816e-02],\n",
      "        [-1.3342e-01, -1.2408e-01,  2.3926e-01, -1.9257e-01, -1.0131e-01,\n",
      "         -1.5783e-01],\n",
      "        [-1.4271e-01, -1.4846e-01,  1.9418e-01, -1.7250e-01,  6.1550e-02,\n",
      "          7.6993e-02],\n",
      "        [-2.4360e-02, -5.0244e-02, -1.5711e-01,  2.0950e-01, -2.8397e-03,\n",
      "         -1.1578e-01],\n",
      "        [-1.9798e-01, -3.3995e-02, -1.7687e-01,  2.1523e-01,  2.2162e-38,\n",
      "          9.9054e-02]])), ('cinn.module_list.2.subnet1.lin_1.0.bias', tensor([ 0.0044,  0.0433, -0.0320,  0.1170,  0.1164,  0.0322,  0.1263,  0.0925,\n",
      "         0.0981,  0.1856, -0.0047,  0.1293,  0.1568,  0.1274,  0.1370,  0.1260])), ('cinn.module_list.2.subnet1.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.2.subnet1.lin_1.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.2.subnet1.lin_1.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.2.subnet1.lin_2.weight', tensor([[ 1.7042e-01,  1.0280e-01, -4.1664e-03,  8.4079e-02,  6.1928e-02,\n",
      "          3.6950e-02,  4.9250e-02,  9.6221e-02, -5.9871e-02, -1.2794e-03,\n",
      "          1.6340e-10,  8.3309e-02,  1.0954e-01,  1.5614e-01, -9.5581e-02,\n",
      "         -3.6528e-02],\n",
      "        [ 4.6724e-02,  6.8902e-02,  1.9120e-02,  5.7261e-02,  1.0294e-01,\n",
      "          7.5369e-02,  3.0319e-02,  5.8504e-02,  1.2393e-01, -1.1065e-01,\n",
      "         -4.8163e-09, -4.0231e-02, -1.4908e-02, -1.0915e-01,  5.0379e-02,\n",
      "          1.2185e-01],\n",
      "        [ 6.8445e-02,  1.4451e-01,  3.0307e-03,  1.4453e-01,  1.2112e-01,\n",
      "          1.3399e-01,  2.0955e-01,  1.4736e-01, -2.2887e-01, -1.6428e-01,\n",
      "          1.1175e-09,  1.8594e-01,  1.1091e-01,  2.1010e-01, -2.0547e-01,\n",
      "         -1.2220e-01],\n",
      "        [ 9.5804e-03,  2.0005e-01, -1.2366e-02,  1.4348e-01,  1.4211e-01,\n",
      "          1.5041e-01, -1.2007e-01,  6.1561e-02,  1.6726e-01, -1.3492e-01,\n",
      "         -4.9227e-09, -1.8739e-01, -2.5404e-01, -1.8849e-01,  1.5063e-01,\n",
      "          1.8574e-01]])), ('cinn.module_list.2.subnet1.lin_2.bias', tensor([0.0466, 0.0555, 0.0238, 0.0282])), ('cinn.module_list.2.subnet1.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.2.subnet1.lin_2.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.2.subnet1.lin_2.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.2.subnet2.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.2.subnet2.quant.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.2.subnet2.quant.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.2.subnet2.lin_1.0.weight', tensor([[-1.7315e-01, -1.0738e-01, -1.0674e-01, -1.1952e-38, -1.9613e-01,\n",
      "          1.9768e-01],\n",
      "        [-1.3333e-01, -7.8222e-02, -1.3455e-01, -1.6781e-02, -1.9426e-01,\n",
      "          2.4632e-01],\n",
      "        [-1.0701e-01, -1.1280e-01, -1.0828e-02, -2.6257e-02,  1.9461e-01,\n",
      "         -1.4867e-01],\n",
      "        [ 1.9222e-02,  2.2558e-03,  5.1502e-38, -3.3565e-02,  1.6159e-16,\n",
      "         -1.0697e-38],\n",
      "        [-1.9254e-01, -1.5399e-01, -3.6427e-02, -3.4836e-38, -1.9415e-01,\n",
      "          2.0557e-01],\n",
      "        [-6.6881e-02, -5.1754e-02, -1.0850e-01, -7.3560e-02,  1.4847e-01,\n",
      "          1.4773e-01],\n",
      "        [-1.3434e-01, -1.7858e-01, -1.9441e-38, -5.9823e-02,  2.1260e-01,\n",
      "         -2.2426e-01],\n",
      "        [-8.8198e-02, -1.2222e-01,  5.5693e-04, -7.0622e-02,  2.0466e-01,\n",
      "         -1.6069e-01],\n",
      "        [-6.2820e-16,  1.7744e-25,  1.9362e-38,  6.2844e-38, -2.2778e-13,\n",
      "          2.5168e-38],\n",
      "        [ 7.4629e-02,  9.0458e-02,  1.6015e-01,  9.2684e-02, -8.5881e-02,\n",
      "          2.3848e-02],\n",
      "        [-5.8425e-02, -3.4366e-02, -1.9281e-01, -1.3979e-01, -2.6889e-02,\n",
      "          2.2646e-01],\n",
      "        [ 1.3728e-01, -7.3751e-02, -2.2668e-38,  8.3395e-02, -1.2385e-01,\n",
      "         -1.2362e-01],\n",
      "        [-1.3133e-01, -1.1015e-01, -6.3018e-02, -2.4378e-02, -1.7900e-01,\n",
      "          2.2910e-01],\n",
      "        [ 1.0448e-01, -3.1433e-02, -2.1835e-02,  9.4880e-02, -6.5993e-02,\n",
      "         -5.7926e-02],\n",
      "        [ 5.2025e-02, -2.0624e-01,  4.8537e-38,  1.1180e-01, -9.5572e-02,\n",
      "         -1.0091e-01],\n",
      "        [ 9.7226e-03, -7.1584e-03, -1.2087e-02, -3.6312e-03, -5.3518e-06,\n",
      "         -1.3028e-14]])), ('cinn.module_list.2.subnet2.lin_1.0.bias', tensor([ 1.0832e-01,  1.2581e-01,  7.9915e-02, -3.1265e-02,  8.2558e-02,\n",
      "         1.1347e-01,  1.2553e-01,  9.4819e-02, -5.8261e-13,  1.3163e-01,\n",
      "         1.8253e-01,  6.9647e-02,  1.0059e-01,  2.1179e-02,  7.6320e-02,\n",
      "        -2.6854e-02])), ('cinn.module_list.2.subnet2.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.2.subnet2.lin_1.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.2.subnet2.lin_1.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.2.subnet2.lin_2.weight', tensor([[ 1.9358e-01,  1.2141e-01, -7.4102e-02, -3.2118e-03,  1.6749e-01,\n",
      "         -3.1822e-02, -1.1204e-02,  2.7908e-03,  1.1073e-38,  1.0711e-01,\n",
      "         -3.7921e-02,  7.4352e-02,  1.3092e-01,  9.2867e-02,  9.9356e-02,\n",
      "          6.0947e-03],\n",
      "        [-4.2537e-02, -5.4692e-02,  1.4670e-01,  3.1573e-02, -1.5069e-02,\n",
      "         -3.5292e-02,  1.4677e-01,  1.3348e-01, -2.2444e-38,  4.0336e-02,\n",
      "         -5.4831e-02,  8.6481e-02, -7.4145e-02,  4.7290e-03,  1.3402e-01,\n",
      "         -3.6415e-03],\n",
      "        [ 1.6613e-01,  1.5877e-01, -2.4389e-01, -5.5170e-03,  2.4339e-01,\n",
      "         -1.7409e-01, -2.1551e-01, -2.3239e-01, -2.3019e-38,  1.4690e-01,\n",
      "         -5.3303e-02,  1.4269e-01,  1.6527e-01,  1.1441e-01,  1.0984e-01,\n",
      "         -6.8214e-04],\n",
      "        [-2.3357e-01, -2.4047e-01,  2.1016e-01, -2.8818e-02, -2.2629e-01,\n",
      "         -1.3549e-01,  2.0468e-01,  1.6411e-01, -3.8820e-39,  5.7137e-02,\n",
      "         -2.0118e-01,  9.7636e-02, -2.2969e-01,  5.7923e-02,  8.4984e-02,\n",
      "          2.3359e-03]])), ('cinn.module_list.2.subnet2.lin_2.bias', tensor([0.0316, 0.0321, 0.0390, 0.0349])), ('cinn.module_list.2.subnet2.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.2.subnet2.lin_2.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.2.subnet2.lin_2.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.3.perm', tensor([3, 2, 0, 1])), ('cinn.module_list.3.perm_inv', tensor([2, 3, 1, 0])), ('cinn.module_list.4.subnet1.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.4.subnet1.quant.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.4.subnet1.quant.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.4.subnet1.lin_1.0.weight', tensor([[-7.4000e-02, -1.0740e-01, -3.2874e-02, -4.5923e-02,  2.1407e-01,\n",
      "         -1.0263e-01],\n",
      "        [-1.0640e-01,  1.8263e-02, -7.5568e-03,  1.3001e-01, -1.8716e-01,\n",
      "          1.9735e-01],\n",
      "        [ 8.2141e-02, -1.8764e-01,  1.4368e-01, -6.8110e-38, -1.8023e-01,\n",
      "         -5.6967e-02],\n",
      "        [-2.1414e-02, -1.8354e-02,  4.2434e-40,  2.1649e-02, -4.0020e-38,\n",
      "          6.8457e-03],\n",
      "        [-3.3533e-04, -4.8876e-02, -2.2840e-01, -1.8414e-01,  1.6397e-01,\n",
      "          1.4493e-01],\n",
      "        [ 6.0188e-02, -2.1310e-01,  1.7891e-01,  3.3711e-38, -8.3268e-02,\n",
      "         -1.6092e-01],\n",
      "        [-6.6887e-02, -6.4118e-02, -1.4349e-01, -1.5453e-01,  2.0367e-01,\n",
      "         -1.4788e-01],\n",
      "        [ 1.2953e-02, -7.8155e-02, -1.7404e-01, -6.9951e-02,  2.0858e-01,\n",
      "          2.0711e-01],\n",
      "        [ 1.2469e-01, -6.5800e-02,  1.5871e-01, -2.8567e-02, -1.5636e-01,\n",
      "         -1.7365e-01],\n",
      "        [-1.2865e-01,  1.2592e-01, -4.7869e-39,  1.2110e-01,  8.2756e-02,\n",
      "         -1.5202e-01],\n",
      "        [-6.3771e-02, -5.0830e-02, -7.4978e-02, -1.1790e-01,  2.3907e-01,\n",
      "         -1.2274e-01],\n",
      "        [ 2.5867e-02, -3.4493e-03, -2.3046e-01, -1.8265e-01,  1.9421e-01,\n",
      "         -1.0708e-01],\n",
      "        [-2.5348e-01,  6.2143e-02, -6.2250e-39,  1.1553e-01,  2.9613e-02,\n",
      "         -1.4039e-01],\n",
      "        [-5.4309e-02,  1.6056e-01,  6.4375e-02,  1.5458e-01, -1.7331e-01,\n",
      "         -1.4629e-01],\n",
      "        [-3.8031e-02,  1.3287e-01, -4.0173e-38,  1.0020e-01, -1.0388e-01,\n",
      "         -6.6041e-02],\n",
      "        [-1.2925e-01, -6.8421e-02, -5.4380e-02,  1.6329e-01, -2.1905e-01,\n",
      "          1.7974e-01]])), ('cinn.module_list.4.subnet1.lin_1.0.bias', tensor([ 0.1058,  0.1139,  0.0787, -0.0447,  0.2013,  0.1766,  0.1565,  0.1693,\n",
      "         0.0804,  0.0739,  0.1302,  0.1833,  0.0570,  0.0848, -0.0007,  0.1442])), ('cinn.module_list.4.subnet1.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.4.subnet1.lin_1.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.4.subnet1.lin_1.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.4.subnet1.lin_2.weight', tensor([[-1.7383e-02,  1.3179e-01,  6.6573e-02, -3.3248e-02,  3.1977e-03,\n",
      "          8.3517e-02, -4.8819e-02, -6.9899e-03,  7.4097e-02,  6.5504e-02,\n",
      "         -7.3560e-02, -2.7354e-02,  8.8424e-02,  6.2392e-02,  8.5751e-02,\n",
      "          6.5268e-02],\n",
      "        [ 1.1998e-01,  9.1656e-02,  1.4420e-01, -3.2759e-02,  2.7082e-02,\n",
      "          1.0187e-01,  1.7794e-01, -1.5059e-02,  9.6756e-02,  5.3518e-02,\n",
      "          7.5322e-02, -1.8611e-02,  7.6486e-02,  9.3861e-02, -1.4598e-02,\n",
      "         -5.2994e-05],\n",
      "        [-1.9622e-01,  1.5062e-01,  1.6810e-01, -3.9774e-02, -1.7533e-01,\n",
      "          1.4446e-01, -2.2439e-01, -1.8592e-01,  1.8559e-01,  3.9384e-02,\n",
      "         -2.2194e-01, -2.2457e-01,  7.4890e-02,  1.4892e-01,  1.1609e-01,\n",
      "          2.2291e-01],\n",
      "        [ 1.6496e-01, -9.2654e-02,  1.1993e-01, -2.3512e-03, -1.7327e-01,\n",
      "          1.5480e-01,  1.3705e-01, -1.7403e-01,  1.8593e-01,  2.1610e-01,\n",
      "          1.5898e-01,  5.6097e-03,  1.5618e-01,  1.6559e-01,  7.4089e-02,\n",
      "         -2.1173e-01]])), ('cinn.module_list.4.subnet1.lin_2.bias', tensor([0.0465, 0.1263, 0.0181, 0.0521])), ('cinn.module_list.4.subnet1.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.4.subnet1.lin_2.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.4.subnet1.lin_2.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.4.subnet2.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.4.subnet2.quant.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.4.subnet2.quant.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.4.subnet2.lin_1.0.weight', tensor([[ 1.4506e-01, -7.9618e-02, -1.1082e-01, -1.0888e-01,  9.3376e-02,\n",
      "          1.4648e-38],\n",
      "        [ 7.2653e-02, -1.3579e-01, -1.1494e-01,  1.2505e-01,  1.5833e-01,\n",
      "         -3.7069e-02],\n",
      "        [-1.0066e-01,  1.1099e-01, -1.1496e-01, -1.1716e-01, -6.5617e-38,\n",
      "          1.6204e-01],\n",
      "        [ 3.9160e-02,  6.3537e-02, -1.2869e-01,  2.1009e-01,  1.1019e-01,\n",
      "          1.4007e-01],\n",
      "        [-1.9626e-02, -1.9578e-01,  2.1671e-01, -1.8792e-01,  1.0739e-01,\n",
      "          3.3844e-02],\n",
      "        [ 4.6281e-02, -2.1231e-01, -1.3436e-01, -1.1813e-01,  1.2834e-01,\n",
      "         -4.2072e-38],\n",
      "        [-4.7815e-02, -6.6039e-02,  2.1999e-01, -1.0689e-01, -1.6990e-01,\n",
      "         -1.5520e-01],\n",
      "        [ 1.7004e-01,  1.6136e-01, -7.7334e-02, -9.0977e-02,  1.4858e-01,\n",
      "          1.0232e-01],\n",
      "        [-1.3014e-01,  1.3992e-01, -1.7991e-01, -1.7229e-01,  1.6200e-38,\n",
      "          1.1457e-01],\n",
      "        [-8.1062e-02, -1.9262e-01,  2.1998e-01, -2.0350e-01,  1.3269e-02,\n",
      "          9.8050e-03],\n",
      "        [ 1.0729e-01, -5.2312e-02, -9.8134e-02, -9.8954e-02,  1.7388e-01,\n",
      "         -7.0331e-39],\n",
      "        [-3.5135e-02, -7.0855e-02, -1.2966e-01,  3.0879e-01, -2.3056e-02,\n",
      "         -6.6920e-02],\n",
      "        [ 1.2380e-01,  1.2546e-01, -2.5985e-02, -4.7200e-02,  1.2043e-01,\n",
      "          1.2755e-01],\n",
      "        [ 1.4680e-01, -1.0981e-01, -1.3407e-01, -1.5346e-01,  1.5628e-01,\n",
      "          3.7172e-38],\n",
      "        [ 7.8048e-03,  9.9662e-03, -1.0659e-01,  2.3456e-01, -2.1512e-02,\n",
      "         -1.8067e-02],\n",
      "        [-2.1232e-01, -2.3168e-01, -1.2065e-01,  1.2044e-01,  5.4862e-38,\n",
      "          3.5762e-38]])), ('cinn.module_list.4.subnet2.lin_1.0.bias', tensor([0.0319, 0.1339, 0.0577, 0.1505, 0.1533, 0.1127, 0.1691, 0.1313, 0.0997,\n",
      "        0.1595, 0.0307, 0.0997, 0.0789, 0.0555, 0.0969, 0.0152])), ('cinn.module_list.4.subnet2.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.4.subnet2.lin_1.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.4.subnet2.lin_1.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.4.subnet2.lin_2.weight', tensor([[ 0.0543,  0.0197,  0.0327,  0.0818,  0.0794,  0.0712, -0.0308,  0.0381,\n",
      "          0.0944,  0.0121,  0.0759,  0.0519,  0.0507,  0.0359,  0.0568,  0.1509],\n",
      "        [ 0.0683,  0.0254,  0.0769,  0.0936,  0.0652,  0.0877,  0.0569,  0.0742,\n",
      "          0.0797,  0.1021,  0.0877, -0.0638,  0.0576,  0.0375, -0.0803,  0.2740],\n",
      "        [ 0.1147,  0.2131,  0.1461,  0.1685, -0.1276,  0.1512, -0.2506,  0.1522,\n",
      "          0.1123, -0.2099,  0.1309,  0.1372,  0.1452,  0.1025,  0.1122,  0.1391],\n",
      "        [ 0.1334, -0.0297,  0.1092, -0.0543,  0.1589,  0.1333,  0.0094,  0.0925,\n",
      "          0.1137,  0.1760,  0.1259, -0.2141,  0.1125,  0.1392, -0.1682, -0.0873]])), ('cinn.module_list.4.subnet2.lin_2.bias', tensor([ 0.0834,  0.1103, -0.0041, -0.0316])), ('cinn.module_list.4.subnet2.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.4.subnet2.lin_2.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.4.subnet2.lin_2.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.5.perm', tensor([2, 3, 1, 0])), ('cinn.module_list.5.perm_inv', tensor([3, 2, 0, 1])), ('cinn.module_list.6.subnet1.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.6.subnet1.quant.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.6.subnet1.quant.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.6.subnet1.lin_1.0.weight', tensor([[-0.0338,  0.0461,  0.0515, -0.1714,  0.1752,  0.1714],\n",
      "        [ 0.0828,  0.1091, -0.0089, -0.1570,  0.1417,  0.1702],\n",
      "        [-0.0038,  0.0257,  0.1868,  0.1110, -0.1753, -0.1997],\n",
      "        [-0.2475,  0.0749,  0.1004, -0.1636, -0.0466,  0.1582],\n",
      "        [-0.1156,  0.1724, -0.1774, -0.1608, -0.0498,  0.1846],\n",
      "        [ 0.0201,  0.0922, -0.0364, -0.1224,  0.1566,  0.1786],\n",
      "        [-0.1054, -0.0387,  0.2270, -0.1243, -0.1655, -0.0572],\n",
      "        [-0.0186, -0.0031,  0.2189,  0.0591, -0.1910, -0.1901],\n",
      "        [-0.0933, -0.0525,  0.2321, -0.0126, -0.1486, -0.1832],\n",
      "        [ 0.0688,  0.0833, -0.1410, -0.1579,  0.1478,  0.1657],\n",
      "        [-0.0667, -0.0431, -0.1188,  0.1917,  0.0424,  0.0788],\n",
      "        [ 0.0154,  0.0933, -0.0981, -0.1065,  0.0643,  0.0232],\n",
      "        [-0.0120, -0.0046, -0.1692,  0.2091,  0.0364, -0.0509],\n",
      "        [-0.0336, -0.0216, -0.1016,  0.2237,  0.0433,  0.0865],\n",
      "        [-0.0135, -0.0066,  0.2351,  0.2138, -0.1687, -0.1489],\n",
      "        [ 0.0158,  0.0544,  0.0582, -0.1725,  0.1402,  0.1334]])), ('cinn.module_list.6.subnet1.lin_1.0.bias', tensor([ 0.1411,  0.0839,  0.1499,  0.0928,  0.0450,  0.0796,  0.1767,  0.1681,\n",
      "         0.1285,  0.0979,  0.1479, -0.0242,  0.1515,  0.1170,  0.1686,  0.1225])), ('cinn.module_list.6.subnet1.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.6.subnet1.lin_1.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.6.subnet1.lin_1.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.6.subnet1.lin_2.weight', tensor([[ 0.0728,  0.1071, -0.0388,  0.0213,  0.0559,  0.1161,  0.0913,  0.0793,\n",
      "          0.0583,  0.0561, -0.0277,  0.0427, -0.0584, -0.0655,  0.0629,  0.1651],\n",
      "        [ 0.0997,  0.0668,  0.0506,  0.1105,  0.0900,  0.0983, -0.0336, -0.0030,\n",
      "          0.0038,  0.1095,  0.1031,  0.1019,  0.0657,  0.0858, -0.0192,  0.0555],\n",
      "        [ 0.2302,  0.1572, -0.1637,  0.2297,  0.1514,  0.1677,  0.1667, -0.1021,\n",
      "         -0.0127,  0.1388, -0.1728,  0.0345, -0.1851, -0.2084, -0.1656,  0.1916],\n",
      "        [ 0.0369,  0.0445, -0.1890,  0.0117,  0.1000,  0.0921, -0.2234, -0.2259,\n",
      "         -0.1812,  0.1147,  0.2154,  0.0497,  0.1984,  0.2342, -0.1625,  0.0280]])), ('cinn.module_list.6.subnet1.lin_2.bias', tensor([ 0.0753,  0.1228, -0.0412, -0.0383])), ('cinn.module_list.6.subnet1.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.6.subnet1.lin_2.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.6.subnet1.lin_2.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.6.subnet2.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.6.subnet2.quant.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.6.subnet2.quant.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.6.subnet2.lin_1.0.weight', tensor([[-1.1370e-02, -1.2411e-02,  9.3906e-02, -5.2314e-02,  2.3652e-01,\n",
      "         -1.6819e-01],\n",
      "        [ 1.5583e-01,  1.1219e-01,  1.8677e-01,  1.0546e-01, -1.4588e-01,\n",
      "         -9.9503e-02],\n",
      "        [ 1.1803e-01, -3.2268e-02,  6.5844e-02,  1.2002e-01, -1.3671e-01,\n",
      "         -1.0570e-01],\n",
      "        [-9.2983e-02,  3.4768e-02,  1.9754e-01, -6.3044e-02,  2.4240e-01,\n",
      "         -1.5245e-01],\n",
      "        [-7.5303e-02,  7.1414e-03, -1.4892e-01, -5.6691e-02,  1.7702e-01,\n",
      "          1.1966e-01],\n",
      "        [-2.0940e-01, -6.4866e-02,  4.3077e-02,  2.3747e-38, -2.0223e-01,\n",
      "          1.8832e-01],\n",
      "        [-6.7208e-02, -5.7880e-02, -1.3074e-01, -1.0429e-01,  2.5273e-01,\n",
      "         -1.1522e-01],\n",
      "        [ 1.5279e-01,  1.2525e-01,  1.2749e-01,  1.1463e-01, -1.5653e-01,\n",
      "         -9.4257e-02],\n",
      "        [ 8.0452e-03,  6.7920e-04, -6.1626e-38, -1.5922e-02,  1.4604e-38,\n",
      "         -5.8100e-38],\n",
      "        [-1.8219e-01,  4.5181e-02,  1.3948e-01, -3.0269e-38, -8.8155e-02,\n",
      "          7.8654e-02],\n",
      "        [ 1.1377e-01,  1.2519e-01,  1.5665e-01,  1.4789e-01, -1.6014e-01,\n",
      "         -1.1348e-01],\n",
      "        [-2.3834e-02, -1.3608e-02, -1.6087e-01, -1.4588e-01,  2.2328e-01,\n",
      "         -1.3934e-01],\n",
      "        [ 1.2084e-01,  1.2711e-01,  1.5803e-01,  1.5180e-01, -1.2844e-01,\n",
      "         -9.1185e-02],\n",
      "        [ 2.5322e-03, -4.1591e-02, -9.0813e-02, -1.6829e-01,  1.9678e-01,\n",
      "         -1.8517e-01],\n",
      "        [-5.5610e-02, -2.6569e-03, -2.0101e-01, -6.1579e-02,  1.4169e-01,\n",
      "          1.4760e-01],\n",
      "        [ 3.3927e-02,  5.3614e-03, -1.6625e-01, -1.3647e-01,  1.7224e-01,\n",
      "         -1.7797e-01]])), ('cinn.module_list.6.subnet2.lin_1.0.bias', tensor([ 0.1710,  0.0677,  0.0367,  0.1618,  0.1504,  0.1294,  0.1217,  0.0743,\n",
      "        -0.0142,  0.1734,  0.0921,  0.1429,  0.0579,  0.1277,  0.1643,  0.1539])), ('cinn.module_list.6.subnet2.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.6.subnet2.lin_1.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.6.subnet2.lin_1.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.6.subnet2.lin_2.weight', tensor([[ 2.4041e-02,  1.0432e-01,  9.6875e-02,  8.6010e-03,  5.0412e-02,\n",
      "          5.5104e-02, -2.9682e-03,  9.6676e-02, -2.7421e-07,  1.5327e-01,\n",
      "          1.4049e-01, -1.8463e-03,  6.7833e-02,  4.2111e-03,  1.3408e-04,\n",
      "         -1.4253e-02],\n",
      "        [ 8.0605e-02,  6.7563e-02,  1.1716e-01,  5.5737e-02, -3.6072e-02,\n",
      "          7.3284e-02,  1.3604e-01,  3.3853e-02, -1.1758e-06,  1.4756e-01,\n",
      "          6.4645e-02,  8.4517e-02,  7.7260e-02, -5.0886e-03,  2.0182e-02,\n",
      "         -1.5186e-02],\n",
      "        [-1.9002e-01,  1.5184e-01,  1.1365e-01, -1.5669e-01, -1.7010e-01,\n",
      "          2.0575e-01, -2.2434e-01,  1.2419e-01, -4.0433e-06,  1.4717e-01,\n",
      "          1.5960e-01, -2.6802e-01,  1.0451e-01, -2.0862e-01, -1.5824e-01,\n",
      "         -1.9367e-01],\n",
      "        [ 2.0038e-01,  1.6317e-01,  8.4997e-02,  1.9722e-01, -1.5779e-01,\n",
      "         -1.9181e-01,  1.5666e-01,  1.3457e-01,  4.3563e-06,  2.5673e-02,\n",
      "          1.5049e-01,  1.5980e-01,  1.2781e-01,  7.9921e-02, -1.7093e-01,\n",
      "          9.4971e-02]])), ('cinn.module_list.6.subnet2.lin_2.bias', tensor([0.1358, 0.0730, 0.0300, 0.0026])), ('cinn.module_list.6.subnet2.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.6.subnet2.lin_2.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.6.subnet2.lin_2.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.7.perm', tensor([3, 1, 0, 2])), ('cinn.module_list.7.perm_inv', tensor([2, 1, 3, 0])), ('cinn.module_list.8.subnet1.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.8.subnet1.quant.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.8.subnet1.quant.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.8.subnet1.lin_1.0.weight', tensor([[-3.3599e-03, -4.2859e-02, -6.3515e-02,  2.1239e-01, -1.5205e-01,\n",
      "         -1.6964e-01],\n",
      "        [-8.0483e-03, -6.3311e-04, -1.9206e-01,  1.3552e-01,  2.2716e-01,\n",
      "         -2.0760e-01],\n",
      "        [-1.4308e-01,  2.3297e-02, -5.4965e-02, -1.8226e-01,  5.0868e-02,\n",
      "          1.7837e-01],\n",
      "        [-3.6971e-03, -6.7042e-02, -6.1562e-02,  2.5344e-01, -1.3252e-01,\n",
      "         -1.1901e-01],\n",
      "        [-4.7201e-02,  5.0916e-02,  8.0303e-02,  1.9725e-01, -1.8231e-01,\n",
      "          6.8420e-02],\n",
      "        [ 5.0299e-02,  6.5591e-04, -9.1819e-02,  7.7902e-02,  1.8361e-01,\n",
      "         -2.3817e-02],\n",
      "        [ 1.5663e-01, -1.0863e-01,  1.7207e-01, -1.1740e-01, -1.6967e-01,\n",
      "          1.2425e-39],\n",
      "        [-9.0107e-03,  9.2587e-02, -1.0557e-01,  2.1886e-01, -1.2445e-01,\n",
      "         -2.3635e-01],\n",
      "        [-9.6395e-03,  7.5743e-02, -1.6059e-01,  2.2491e-01,  1.9074e-01,\n",
      "         -2.7260e-01],\n",
      "        [ 4.7656e-02,  7.1353e-03,  6.5023e-02, -1.5272e-01,  2.6350e-01,\n",
      "         -9.9072e-02],\n",
      "        [ 1.3561e-02,  1.6686e-02, -2.2993e-01,  2.4157e-01,  1.8473e-01,\n",
      "         -2.3343e-01],\n",
      "        [ 3.0375e-02, -3.7093e-01,  1.5059e-01, -9.5222e-02, -1.9363e-01,\n",
      "          2.6893e-38],\n",
      "        [-7.6319e-02,  1.2992e-02, -2.6060e-02,  2.1516e-01, -1.8300e-01,\n",
      "         -3.7157e-02],\n",
      "        [ 6.1560e-02,  6.3484e-02,  1.9996e-01, -1.4959e-01, -1.4164e-01,\n",
      "          1.8368e-01],\n",
      "        [-2.3505e-01,  5.5208e-02, -8.1731e-02, -8.5339e-02,  1.7685e-02,\n",
      "          9.6486e-02],\n",
      "        [-6.6517e-38,  1.7009e-38,  5.3147e-38, -6.4824e-15, -4.7796e-38,\n",
      "         -4.5204e-38]])), ('cinn.module_list.8.subnet1.lin_1.0.bias', tensor([ 1.5826e-01,  1.8289e-01,  9.5474e-02,  1.4245e-01,  1.6067e-01,\n",
      "         6.2892e-02, -8.1824e-03,  1.0988e-01,  1.6134e-01,  1.3538e-01,\n",
      "         2.0215e-01,  2.8252e-02,  1.6776e-01,  7.5159e-02,  1.5710e-01,\n",
      "        -1.1991e-14])), ('cinn.module_list.8.subnet1.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.8.subnet1.lin_1.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.8.subnet1.lin_1.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.8.subnet1.lin_2.weight', tensor([[ 3.5974e-02,  2.2589e-01,  1.7948e-01,  3.5565e-02,  1.2618e-01,\n",
      "          1.9900e-01,  5.0812e-02,  7.5857e-02,  5.1100e-02,  1.0804e-01,\n",
      "          8.1780e-02,  2.9781e-02,  3.8806e-02,  7.5315e-02,  5.0630e-02,\n",
      "          5.6674e-38],\n",
      "        [-1.6191e-04,  1.8115e-02, -1.9809e-02,  1.5673e-02,  2.8828e-02,\n",
      "          2.3274e-02,  4.7778e-02,  2.3050e-02,  1.2235e-01,  5.0234e-02,\n",
      "          1.0173e-01,  8.9988e-02,  3.8578e-02,  5.4737e-02,  1.3216e-01,\n",
      "          2.1326e-38],\n",
      "        [ 1.0801e-01, -2.3567e-01,  1.3947e-01,  1.2401e-01,  1.6449e-01,\n",
      "         -1.0707e-01,  1.8009e-01,  1.1350e-01, -1.8040e-01, -2.2584e-01,\n",
      "         -1.7490e-01,  1.2950e-01,  1.9203e-01,  1.5474e-01,  1.3145e-01,\n",
      "         -3.0043e-22],\n",
      "        [-2.1148e-01, -1.8101e-01,  1.9517e-01, -2.5295e-01, -1.6529e-01,\n",
      "         -8.1113e-02,  1.5124e-01, -2.5079e-01, -1.7035e-01,  1.7861e-01,\n",
      "         -2.0386e-01,  2.0162e-01, -2.0478e-01,  1.3028e-01,  1.4422e-01,\n",
      "         -1.7846e-20]])), ('cinn.module_list.8.subnet1.lin_2.bias', tensor([ 0.1598,  0.0969, -0.0248, -0.0388])), ('cinn.module_list.8.subnet1.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.8.subnet1.lin_2.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.8.subnet1.lin_2.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.8.subnet2.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.8.subnet2.quant.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.8.subnet2.quant.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.8.subnet2.lin_1.0.weight', tensor([[ 7.6632e-02,  9.3730e-02, -1.6216e-01,  8.2990e-02,  1.1580e-01,\n",
      "         -1.2229e-01],\n",
      "        [-6.4824e-02,  1.6352e-01, -1.0602e-01,  1.3224e-01,  2.5844e-02,\n",
      "         -1.5399e-01],\n",
      "        [-1.1026e-02,  1.1058e-03,  1.1921e-01, -2.0138e-01, -1.8002e-01,\n",
      "          2.0225e-01],\n",
      "        [-5.8759e-02,  1.8067e-01, -1.0800e-01,  8.4074e-02,  3.6916e-02,\n",
      "         -1.6271e-01],\n",
      "        [-8.2623e-02, -7.3119e-02,  2.2738e-01, -3.2751e-02, -1.6763e-01,\n",
      "          5.7244e-02],\n",
      "        [ 1.5281e-01,  2.5406e-03,  6.3112e-38, -2.9963e-02, -1.0502e-02,\n",
      "          3.6249e-38],\n",
      "        [ 1.1549e-01,  1.4297e-01, -1.5492e-01,  1.3433e-01,  1.2356e-01,\n",
      "         -1.4887e-01],\n",
      "        [-5.8262e-02, -8.7179e-02, -1.4223e-01,  5.7118e-02,  2.0477e-02,\n",
      "          2.5656e-01],\n",
      "        [ 1.1754e-01,  1.4422e-01, -1.5158e-01,  1.0424e-01,  1.5216e-01,\n",
      "         -1.3581e-01],\n",
      "        [-9.0040e-03,  3.4413e-02,  2.1613e-01, -1.5219e-01,  3.1528e-02,\n",
      "         -1.7394e-01],\n",
      "        [ 8.8784e-02,  1.4981e-01, -1.0840e-01,  8.2394e-02,  1.4030e-01,\n",
      "         -1.2185e-01],\n",
      "        [-4.1515e-02, -8.7837e-02, -1.3669e-01, -5.3253e-02, -1.4225e-01,\n",
      "          1.8343e-01],\n",
      "        [ 3.4334e-03, -1.5698e-01, -1.2546e-01,  1.1647e-01,  6.4126e-02,\n",
      "          1.8902e-01],\n",
      "        [ 3.2975e-03, -9.5694e-02,  1.6401e-01, -5.7669e-02, -1.6678e-01,\n",
      "          1.8325e-01],\n",
      "        [-6.3866e-02, -1.0855e-01, -1.3783e-01, -1.4331e-01, -1.3665e-02,\n",
      "          1.9291e-01],\n",
      "        [-1.8378e-01,  2.3624e-03, -2.0936e-02,  1.7832e-01,  8.3951e-02,\n",
      "         -9.4652e-02]])), ('cinn.module_list.8.subnet2.lin_1.0.bias', tensor([ 0.1005,  0.0377,  0.1773,  0.0212,  0.1550, -0.0546,  0.1130,  0.1090,\n",
      "         0.1019,  0.1536,  0.0702,  0.1289,  0.1426,  0.1554,  0.1554,  0.0888])), ('cinn.module_list.8.subnet2.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.8.subnet2.lin_1.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.8.subnet2.lin_1.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.8.subnet2.lin_2.weight', tensor([[ 0.1127,  0.1096,  0.0574,  0.0631,  0.1949, -0.2254,  0.1031, -0.0113,\n",
      "          0.1154, -0.0257,  0.0825,  0.0038,  0.1491,  0.0735,  0.0911,  0.1754],\n",
      "        [ 0.0418,  0.0971,  0.0094,  0.0559,  0.1120, -0.1404,  0.0794,  0.1725,\n",
      "          0.0467,  0.0898,  0.0667, -0.0309,  0.0831,  0.0539,  0.0161,  0.1344],\n",
      "        [ 0.1274,  0.1521, -0.1382,  0.1278, -0.0921,  0.0278,  0.1177,  0.0519,\n",
      "          0.1506, -0.2290,  0.1523,  0.1087,  0.1633, -0.1962,  0.1053,  0.1210],\n",
      "        [ 0.0842,  0.1650, -0.1692,  0.1511, -0.0194, -0.0337,  0.1663, -0.1201,\n",
      "          0.1201,  0.2142,  0.1132, -0.2065, -0.1259, -0.2184, -0.1959,  0.0989]])), ('cinn.module_list.8.subnet2.lin_2.bias', tensor([ 0.0816,  0.1270, -0.0995, -0.0374])), ('cinn.module_list.8.subnet2.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.8.subnet2.lin_2.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.8.subnet2.lin_2.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.9.perm', tensor([0, 1, 3, 2])), ('cinn.module_list.9.perm_inv', tensor([0, 1, 3, 2])), ('cinn.module_list.10.subnet1.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.10.subnet1.quant.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.10.subnet1.quant.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.10.subnet1.lin_1.0.weight', tensor([[-0.0729,  0.1923,  0.0154, -0.0097, -0.0895,  0.0738],\n",
      "        [-0.0095, -0.0039, -0.0260, -0.0142, -0.0216, -0.0049],\n",
      "        [-0.1300,  0.0173, -0.0209,  0.1947, -0.1443,  0.0921],\n",
      "        [ 0.0075, -0.0921, -0.0391, -0.1229,  0.2115,  0.0104],\n",
      "        [ 0.0047, -0.1390,  0.0922, -0.1669,  0.2674,  0.0339],\n",
      "        [ 0.0194, -0.1504,  0.0890, -0.1845,  0.1826,  0.0397],\n",
      "        [ 0.0540,  0.0232, -0.2551,  0.2194,  0.1704, -0.2310],\n",
      "        [ 0.0701,  0.0230,  0.1654, -0.1363, -0.1450,  0.1967],\n",
      "        [ 0.0458,  0.0104, -0.2625,  0.2071,  0.2012, -0.2320],\n",
      "        [ 0.0778,  0.0764,  0.1207, -0.1262, -0.2333,  0.1719],\n",
      "        [-0.2159,  0.0119,  0.0314, -0.0743,  0.1409,  0.1446],\n",
      "        [ 0.0058, -0.1375,  0.0629, -0.1380,  0.2170,  0.0603],\n",
      "        [ 0.0449,  0.1249, -0.0160,  0.3167,  0.0610, -0.0252],\n",
      "        [-0.2788,  0.0060,  0.1474, -0.2527, -0.1833,  0.1741],\n",
      "        [-0.0106,  0.1983, -0.1269,  0.2940, -0.1231, -0.0501],\n",
      "        [ 0.0883,  0.0680,  0.1461, -0.2133, -0.2206,  0.1184]])), ('cinn.module_list.10.subnet1.lin_1.0.bias', tensor([-0.0086, -0.0437,  0.1048,  0.1160,  0.1550,  0.1759,  0.1735,  0.0651,\n",
      "         0.1949,  0.1218,  0.1766,  0.1261,  0.1291,  0.0815,  0.0910,  0.1053])), ('cinn.module_list.10.subnet1.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.10.subnet1.lin_1.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.10.subnet1.lin_1.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.10.subnet1.lin_2.weight', tensor([[ 0.0444,  0.0028,  0.0495,  0.0469,  0.0628,  0.1615,  0.0889,  0.0918,\n",
      "          0.1147,  0.0886,  0.1417,  0.0746,  0.2789,  0.0579,  0.2029,  0.1217],\n",
      "        [-0.0744, -0.0223,  0.1268,  0.0160,  0.1112,  0.1877,  0.0979,  0.0479,\n",
      "          0.0917,  0.1122,  0.1888,  0.0578,  0.0795,  0.1292, -0.0274,  0.1533],\n",
      "        [ 0.0103,  0.0087, -0.1242,  0.1888,  0.1844,  0.1753, -0.1732,  0.1625,\n",
      "         -0.1650,  0.1161,  0.2194,  0.2331, -0.1483,  0.2186, -0.2329,  0.1317],\n",
      "        [ 0.1346, -0.0096,  0.2302, -0.1607, -0.1731, -0.1169, -0.1536,  0.1288,\n",
      "         -0.1884,  0.1504,  0.0427, -0.1727, -0.0301,  0.2800,  0.0969,  0.1483]])), ('cinn.module_list.10.subnet1.lin_2.bias', tensor([ 0.1576,  0.1711, -0.0893, -0.0263])), ('cinn.module_list.10.subnet1.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.10.subnet1.lin_2.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.10.subnet1.lin_2.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.10.subnet2.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.10.subnet2.quant.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.10.subnet2.quant.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.10.subnet2.lin_1.0.weight', tensor([[-1.4381e-01,  1.3200e-02, -1.3987e-01, -9.0854e-02, -5.8508e-02,\n",
      "          1.5675e-01],\n",
      "        [-1.7030e-01, -4.5908e-02,  2.7132e-01, -1.4301e-01,  1.5024e-01,\n",
      "         -2.6456e-01],\n",
      "        [ 1.5491e-01, -2.4294e-02, -1.2687e-01,  1.1107e-01,  1.1652e-01,\n",
      "         -1.7432e-01],\n",
      "        [ 2.1550e-02,  1.1800e-02, -1.4577e-01,  8.3024e-02, -1.5829e-01,\n",
      "          2.3674e-01],\n",
      "        [ 2.4336e-02, -1.9642e-02, -7.7176e-39, -1.7909e-02,  2.9127e-38,\n",
      "         -4.8137e-38],\n",
      "        [-1.9031e-01, -6.9779e-03, -1.3053e-01,  9.1068e-02,  1.0999e-01,\n",
      "          2.3335e-01],\n",
      "        [ 6.4440e-02, -1.9513e-01,  1.0139e-02,  1.6130e-01,  5.0223e-02,\n",
      "         -8.4781e-02],\n",
      "        [-2.3902e-02,  1.1198e-02,  1.4780e-01, -1.9008e-01, -2.1463e-01,\n",
      "          1.8535e-01],\n",
      "        [ 5.8532e-03, -2.8313e-01,  3.0262e-01,  8.6012e-02,  1.0580e-01,\n",
      "         -1.2866e-01],\n",
      "        [ 7.7805e-02,  7.5554e-02, -1.4625e-01,  1.8970e-01,  1.7718e-01,\n",
      "         -1.4091e-01],\n",
      "        [ 4.3292e-03, -1.3404e-01,  2.1291e-01, -9.2208e-02, -1.2947e-01,\n",
      "         -1.5210e-01],\n",
      "        [-1.7125e-02, -1.4517e-01,  2.6638e-01, -7.9674e-02, -1.1413e-01,\n",
      "         -1.4518e-01],\n",
      "        [-6.8392e-02, -2.1839e-02,  2.3736e-01, -6.7669e-02,  1.3861e-01,\n",
      "         -1.6711e-01],\n",
      "        [ 6.0337e-02,  5.0841e-02, -1.4531e-01,  1.8711e-01,  2.0011e-01,\n",
      "         -1.3623e-01],\n",
      "        [-8.7785e-03, -4.2699e-02,  3.4708e-01,  8.8710e-02,  7.3117e-02,\n",
      "         -1.9009e-01],\n",
      "        [-1.2363e-01, -3.1828e-03,  1.6262e-01, -1.0429e-01, -1.2327e-01,\n",
      "          1.2688e-01]])), ('cinn.module_list.10.subnet2.lin_1.0.bias', tensor([ 0.1665,  0.1671,  0.0912,  0.1333, -0.0555,  0.1688,  0.1123,  0.1877,\n",
      "         0.1853,  0.0949,  0.1838,  0.1852,  0.1286,  0.1106,  0.1433,  0.1737])), ('cinn.module_list.10.subnet2.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.10.subnet2.lin_1.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.10.subnet2.lin_1.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.10.subnet2.lin_2.weight', tensor([[ 0.0567,  0.2651,  0.0937, -0.0154,  0.0090,  0.1422,  0.0924,  0.0780,\n",
      "          0.2820,  0.0794, -0.0142,  0.0252,  0.1578,  0.0596,  0.2352,  0.1877],\n",
      "        [ 0.0380,  0.1461,  0.0604,  0.0926,  0.0014,  0.1363,  0.1000,  0.1015,\n",
      "          0.1595,  0.1323,  0.1078,  0.1089,  0.1405,  0.1102,  0.1151,  0.0361],\n",
      "        [ 0.1468, -0.2050,  0.1725,  0.1112,  0.0043,  0.2333,  0.1379, -0.1858,\n",
      "         -0.1368,  0.1587, -0.1922, -0.1882, -0.2400,  0.1905, -0.1229, -0.1496],\n",
      "        [-0.2518,  0.1389,  0.1476, -0.2025,  0.0022, -0.2358,  0.1592, -0.1659,\n",
      "          0.2025,  0.1155,  0.1450,  0.1493,  0.1875,  0.1143,  0.1060, -0.1564]])), ('cinn.module_list.10.subnet2.lin_2.bias', tensor([ 0.1879,  0.1130, -0.0470, -0.0971])), ('cinn.module_list.10.subnet2.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.10.subnet2.lin_2.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.10.subnet2.lin_2.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.11.perm', tensor([0, 1, 2, 3])), ('cinn.module_list.11.perm_inv', tensor([0, 1, 2, 3])), ('cinn.module_list.12.subnet1.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.12.subnet1.quant.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.12.subnet1.quant.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.12.subnet1.lin_1.0.weight', tensor([[ 5.3700e-02,  1.8561e-01,  1.4688e-01, -1.3385e-01, -1.6208e-01,\n",
      "          1.2246e-01],\n",
      "        [ 7.6248e-02,  3.4596e-02,  2.0035e-01, -1.5235e-01, -1.6211e-01,\n",
      "          1.9274e-01],\n",
      "        [-3.9024e-03,  5.1824e-03,  5.5558e-38, -4.3536e-38,  2.7636e-02,\n",
      "         -1.0446e-38],\n",
      "        [ 1.3425e-02,  2.0431e-01,  1.6263e-01, -1.0217e-01, -5.3585e-02,\n",
      "          2.1668e-01],\n",
      "        [-1.4973e-02,  2.2703e-01, -1.4301e-01,  2.5619e-01, -1.5377e-01,\n",
      "          3.3493e-02],\n",
      "        [-9.2186e-06, -1.0135e-05,  4.8467e-38,  1.8843e-38,  2.7082e-04,\n",
      "          4.8502e-38],\n",
      "        [ 9.2285e-03,  2.5457e-01,  9.7912e-02,  4.1466e-02, -2.2663e-01,\n",
      "          4.5120e-02],\n",
      "        [ 7.2818e-02,  4.4594e-02,  1.6261e-01, -2.4686e-01, -8.4661e-02,\n",
      "          1.6142e-01],\n",
      "        [-6.0867e-03, -7.6926e-02,  6.5449e-02, -1.3658e-01,  2.1874e-01,\n",
      "         -1.1863e-01],\n",
      "        [-8.2397e-02,  1.3316e-02, -1.0566e-01,  2.0000e-01, -9.8399e-02,\n",
      "          7.3223e-02],\n",
      "        [-5.0754e-02,  2.5100e-01,  3.6289e-02, -9.1111e-02,  1.0588e-02,\n",
      "          1.3627e-01],\n",
      "        [-5.0508e-03,  4.3386e-02, -1.4963e-01,  3.3312e-01,  1.9990e-01,\n",
      "         -2.8893e-01],\n",
      "        [-1.2582e-01, -2.6414e-02,  6.1910e-02, -6.6285e-02,  1.9963e-01,\n",
      "          1.3319e-01],\n",
      "        [ 9.3829e-03, -1.4585e-01,  1.1648e-01, -2.3435e-01,  2.9680e-01,\n",
      "          2.1554e-02],\n",
      "        [ 1.1148e-01,  1.8781e-02,  1.3496e-01, -9.0202e-02,  9.5270e-02,\n",
      "          1.3843e-01],\n",
      "        [ 1.0790e-02, -9.0976e-03, -2.3216e-01,  1.6674e-01,  1.4725e-01,\n",
      "         -2.1933e-01]])), ('cinn.module_list.12.subnet1.lin_1.0.bias', tensor([ 0.1991,  0.0438, -0.0503,  0.1682,  0.0972, -0.0006,  0.0336,  0.1353,\n",
      "         0.1125,  0.1762,  0.1405,  0.2128,  0.1917,  0.1886,  0.2329,  0.1985])), ('cinn.module_list.12.subnet1.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.12.subnet1.lin_1.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.12.subnet1.lin_1.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.12.subnet1.lin_2.weight', tensor([[ 1.1965e-01,  9.8625e-02, -2.9374e-04,  1.0297e-01,  1.1102e-01,\n",
      "         -2.9381e-38,  1.2042e-01,  1.1710e-01,  4.9101e-02,  9.6850e-02,\n",
      "          1.3284e-01,  2.4095e-01,  1.2801e-01,  9.9303e-02,  1.4188e-01,\n",
      "          4.7046e-02],\n",
      "        [ 5.6331e-02,  1.1185e-01, -4.1945e-03,  1.0927e-01,  8.5826e-02,\n",
      "         -2.6999e-38,  2.3715e-02,  1.0077e-01,  1.5714e-01,  8.1104e-02,\n",
      "          1.4789e-01,  1.1803e-01,  2.4013e-01,  3.1307e-01,  1.7432e-01,\n",
      "          1.9937e-01],\n",
      "        [ 8.9813e-02,  1.1656e-01, -1.1512e-02,  1.2755e-01, -2.3832e-01,\n",
      "         -3.0755e-39,  1.3283e-01,  1.6492e-01,  2.0775e-01, -1.6385e-01,\n",
      "          1.5610e-01, -2.1950e-01,  2.0122e-01,  2.4331e-01,  1.2780e-01,\n",
      "         -1.8684e-01],\n",
      "        [ 1.7820e-01,  1.4815e-01,  1.7843e-04,  1.3370e-01,  1.8235e-01,\n",
      "          5.0310e-38,  8.7183e-02,  1.2736e-01, -2.0949e-01,  1.9200e-01,\n",
      "          1.4756e-01, -1.7501e-01, -3.7827e-02, -1.4764e-01,  2.6943e-02,\n",
      "         -1.4152e-01]])), ('cinn.module_list.12.subnet1.lin_2.bias', tensor([ 0.1279,  0.1831, -0.0468, -0.0428])), ('cinn.module_list.12.subnet1.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.12.subnet1.lin_2.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.12.subnet1.lin_2.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.12.subnet2.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.12.subnet2.quant.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.12.subnet2.quant.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.12.subnet2.lin_1.0.weight', tensor([[ 1.1200e-02, -3.2515e-03,  3.1391e-38, -3.5420e-38,  3.5466e-03,\n",
      "          5.0851e-38],\n",
      "        [-1.5921e-01,  1.0567e-03,  1.8098e-01, -9.4842e-02, -2.2334e-01,\n",
      "          2.2832e-01],\n",
      "        [-3.2238e-02, -3.3044e-02, -2.0024e-01,  1.0215e-01, -1.8040e-01,\n",
      "          2.3909e-01],\n",
      "        [ 3.4757e-02,  9.8311e-03, -3.1737e-38, -2.9412e-02, -2.6322e-38,\n",
      "          8.8422e-39],\n",
      "        [-9.1221e-02,  8.4661e-03, -1.0014e-01, -1.2436e-01, -1.9959e-01,\n",
      "          1.6162e-01],\n",
      "        [-1.5275e-01, -1.8554e-03,  1.3813e-01, -1.4091e-01, -2.5903e-01,\n",
      "          2.2525e-01],\n",
      "        [-5.6225e-02, -4.6682e-02,  2.2585e-01, -1.1947e-01,  2.4331e-02,\n",
      "         -1.1573e-01],\n",
      "        [-4.3808e-03, -3.0918e-03, -3.5841e-38,  1.3307e-02, -6.2263e-38,\n",
      "          3.8150e-38],\n",
      "        [-6.2639e-02, -4.2397e-02,  1.6249e-01, -9.1485e-02,  1.0900e-01,\n",
      "         -2.1569e-01],\n",
      "        [ 1.0005e-02, -2.0058e-01, -9.3879e-02,  1.6642e-01, -6.4851e-02,\n",
      "          2.1948e-01],\n",
      "        [ 4.0173e-02,  1.3980e-02, -1.7447e-01, -1.7702e-01, -1.4983e-01,\n",
      "          2.0358e-01],\n",
      "        [-3.9779e-02, -4.9483e-02, -2.4313e-01,  1.1701e-01,  4.5952e-02,\n",
      "          2.6773e-01],\n",
      "        [-9.7285e-03,  1.1459e-01,  1.9668e-01,  6.6538e-02,  1.5973e-01,\n",
      "         -1.1018e-01],\n",
      "        [ 5.9613e-02, -2.6869e-01,  7.6959e-02,  1.5691e-01,  2.9389e-02,\n",
      "         -3.8293e-02],\n",
      "        [-2.3100e-02, -1.6582e-01, -3.2409e-01,  1.5930e-01, -6.7737e-02,\n",
      "          2.5392e-01],\n",
      "        [ 3.0896e-02, -6.6542e-02, -2.5835e-01,  1.1466e-01,  6.2767e-02,\n",
      "          2.4667e-01]])), ('cinn.module_list.12.subnet2.lin_1.0.bias', tensor([-0.0262,  0.1531,  0.1474, -0.0471,  0.1549,  0.1929,  0.1686, -0.0419,\n",
      "         0.1438,  0.2010,  0.1044,  0.1787,  0.1868,  0.1544,  0.1789,  0.1911])), ('cinn.module_list.12.subnet2.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.12.subnet2.lin_1.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.12.subnet2.lin_1.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.12.subnet2.lin_2.weight', tensor([[ 0.0288,  0.0954,  0.0225,  0.0417,  0.1004,  0.0827,  0.0800, -0.0366,\n",
      "          0.0881,  0.0781, -0.0056,  0.0273,  0.2231,  0.1712,  0.0773,  0.0845],\n",
      "        [-0.0087,  0.1552,  0.0753,  0.0182, -0.0342,  0.1376,  0.1046, -0.0153,\n",
      "          0.1067,  0.2591, -0.0278,  0.2669,  0.1144,  0.1469,  0.2775,  0.2641],\n",
      "        [-0.0372, -0.1855,  0.1754, -0.0143,  0.0605, -0.1862, -0.2170,  0.0735,\n",
      "         -0.1736,  0.1903,  0.1683,  0.1609,  0.0078,  0.1518,  0.1853,  0.2145],\n",
      "        [-0.0021, -0.2492, -0.2205, -0.0413, -0.2262, -0.2004,  0.1742, -0.0290,\n",
      "          0.2382, -0.1102, -0.2322, -0.1779,  0.1230,  0.1767, -0.1523, -0.1412]])), ('cinn.module_list.12.subnet2.lin_2.bias', tensor([ 0.1845,  0.1268, -0.0824, -0.0357])), ('cinn.module_list.12.subnet2.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.12.subnet2.lin_2.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.12.subnet2.lin_2.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.13.perm', tensor([0, 3, 1, 2])), ('cinn.module_list.13.perm_inv', tensor([0, 2, 3, 1])), ('cinn.module_list.14.subnet1.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.14.subnet1.quant.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.14.subnet1.quant.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.14.subnet1.lin_1.0.weight', tensor([[-7.6520e-02,  8.5056e-04,  1.0920e-01,  2.2110e-01,  1.3087e-01,\n",
      "         -8.7636e-02],\n",
      "        [ 9.7487e-02, -1.9055e-02, -3.4524e-01,  2.6302e-01, -2.3404e-01,\n",
      "          1.5967e-01],\n",
      "        [ 5.7928e-02, -5.5066e-03,  1.2612e-01, -9.3462e-02,  1.7672e-01,\n",
      "         -2.1745e-01],\n",
      "        [ 2.7425e-04,  5.0225e-03, -2.8215e-38, -3.6032e-38,  6.3432e-03,\n",
      "          8.8069e-03],\n",
      "        [ 4.6986e-02,  1.5020e-01,  3.1123e-02,  1.4847e-01,  7.3224e-03,\n",
      "          2.4240e-01],\n",
      "        [-7.5078e-02, -5.9758e-03,  9.0776e-02,  2.3752e-01,  9.7715e-02,\n",
      "         -1.3453e-01],\n",
      "        [-9.8531e-03,  8.1360e-02, -8.3912e-02,  1.4628e-01, -7.7733e-02,\n",
      "         -2.0777e-01],\n",
      "        [-6.1828e-02, -1.2235e-03, -4.4955e-02,  1.9252e-01,  1.0454e-01,\n",
      "         -5.8296e-02],\n",
      "        [ 1.0441e-01, -1.4044e-02, -3.0179e-01, -7.6034e-02, -2.5839e-01,\n",
      "          1.7452e-01],\n",
      "        [ 4.8146e-03,  1.3761e-01,  1.0934e-01, -7.1305e-02,  1.1284e-01,\n",
      "         -9.8155e-02],\n",
      "        [ 4.2737e-02,  3.1594e-03, -3.1490e-01,  2.1226e-01, -1.8541e-01,\n",
      "          1.8896e-01],\n",
      "        [ 1.6001e-03,  1.0294e-01,  1.4611e-01, -2.4119e-01,  1.1533e-01,\n",
      "         -5.1956e-02],\n",
      "        [-2.8081e-02, -2.5138e-01,  1.8354e-01, -2.7794e-01,  8.1919e-02,\n",
      "         -2.1645e-01],\n",
      "        [ 3.8752e-03,  1.6954e-01,  1.7756e-01, -4.2479e-02,  1.1122e-01,\n",
      "         -7.6043e-02],\n",
      "        [ 6.7753e-02, -5.7260e-03, -2.5636e-01,  3.0112e-01, -1.8796e-01,\n",
      "          2.0632e-01],\n",
      "        [ 1.2086e-02,  3.6715e-02, -1.8901e-01,  2.5848e-01, -1.9845e-01,\n",
      "          2.2478e-01]])), ('cinn.module_list.14.subnet1.lin_1.0.bias', tensor([ 0.1889,  0.1924,  0.1268, -0.0350,  0.1804,  0.2333,  0.0844,  0.1392,\n",
      "         0.2024,  0.1711,  0.2528,  0.1007,  0.0788,  0.1670,  0.1610,  0.2445])), ('cinn.module_list.14.subnet1.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.14.subnet1.lin_1.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.14.subnet1.lin_1.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.14.subnet1.lin_2.weight', tensor([[ 0.1755,  0.0384,  0.0961, -0.0092,  0.3313,  0.0899,  0.0942,  0.1018,\n",
      "          0.0481,  0.1320,  0.2464,  0.1665,  0.2028,  0.1388,  0.1204,  0.3146],\n",
      "        [ 0.1559,  0.2416,  0.1252,  0.0085, -0.0026,  0.2243,  0.0111,  0.0569,\n",
      "          0.1441,  0.1396,  0.1443,  0.0922,  0.1837,  0.1170,  0.1768,  0.2002],\n",
      "        [ 0.1843, -0.1686,  0.1419,  0.0104, -0.1810,  0.1933,  0.1609,  0.1772,\n",
      "         -0.2301,  0.1362, -0.1743,  0.1167,  0.1993,  0.1559, -0.1688, -0.2231],\n",
      "        [-0.2001, -0.1323,  0.0942, -0.0263, -0.1318, -0.1946, -0.1867, -0.1693,\n",
      "          0.1122,  0.1197, -0.1603,  0.1216,  0.2199,  0.1421, -0.1603, -0.1827]])), ('cinn.module_list.14.subnet1.lin_2.bias', tensor([ 0.1384,  0.1694, -0.0891, -0.0344])), ('cinn.module_list.14.subnet1.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.14.subnet1.lin_2.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.14.subnet1.lin_2.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.14.subnet2.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.14.subnet2.quant.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.14.subnet2.quant.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.14.subnet2.lin_1.0.weight', tensor([[-2.2892e-01,  2.6044e-02,  2.0455e-01, -1.5670e-01, -1.3128e-01,\n",
      "         -8.7322e-02],\n",
      "        [-1.7456e-01,  3.0260e-02, -1.2982e-01,  1.0062e-01, -1.2533e-01,\n",
      "          1.3377e-01],\n",
      "        [ 8.4132e-02,  2.8709e-01, -2.0420e-01,  1.1605e-01, -8.8190e-02,\n",
      "         -4.6475e-02],\n",
      "        [-1.2550e-01,  1.2168e-02,  1.9262e-01, -1.0858e-01, -9.7747e-02,\n",
      "          1.7242e-01],\n",
      "        [ 1.0219e-01,  5.8954e-02, -2.1240e-01,  1.5872e-01,  1.2264e-02,\n",
      "          9.3757e-02],\n",
      "        [ 1.0611e-01,  1.8875e-01,  1.6702e-02,  1.0499e-01, -5.3055e-02,\n",
      "          1.4485e-01],\n",
      "        [-7.8906e-02,  1.0297e-01, -2.0049e-01,  1.1439e-01, -1.0439e-01,\n",
      "          6.1740e-02],\n",
      "        [-1.4737e-03,  1.8533e-02,  1.8820e-01, -1.8313e-01,  2.5173e-01,\n",
      "         -2.2527e-01],\n",
      "        [-1.1293e-01,  9.1709e-02,  1.8796e-01, -1.7430e-01, -1.0469e-01,\n",
      "         -7.8496e-02],\n",
      "        [-6.1417e-03,  5.0759e-03,  2.1495e-02,  2.5384e-38,  1.5171e-02,\n",
      "          6.2646e-38],\n",
      "        [-2.6091e-01,  4.1031e-02,  3.0566e-01,  7.2481e-02, -6.0109e-02,\n",
      "          3.2389e-02],\n",
      "        [ 1.3147e-01,  2.4512e-02, -1.8836e-01,  1.5025e-01, -1.2090e-01,\n",
      "          9.9405e-02],\n",
      "        [ 1.1623e-03, -4.4939e-02, -1.3335e-01,  1.5409e-01,  2.7099e-01,\n",
      "          2.2724e-02],\n",
      "        [ 8.3872e-02, -1.2515e-01, -2.5803e-01,  9.9961e-02,  2.1808e-02,\n",
      "          1.1885e-01],\n",
      "        [-6.4070e-03,  8.4651e-02, -1.3554e-01,  1.2813e-01, -1.4519e-01,\n",
      "          6.0149e-02],\n",
      "        [-1.0114e-02, -2.1170e-02, -1.1407e-01,  1.6322e-01,  2.2539e-01,\n",
      "         -3.7344e-02]])), ('cinn.module_list.14.subnet2.lin_1.0.bias', tensor([ 0.2669, -0.0227, -0.0511,  0.1724,  0.0969,  0.1811,  0.0643,  0.2240,\n",
      "         0.1817, -0.0399,  0.1630,  0.0814,  0.1963,  0.1563,  0.0460,  0.2089])), ('cinn.module_list.14.subnet2.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.14.subnet2.lin_1.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.14.subnet2.lin_1.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.14.subnet2.lin_2.weight', tensor([[ 9.9393e-02,  1.2225e-01, -1.6856e-01,  7.0698e-02,  8.7448e-02,\n",
      "          1.4950e-01,  1.2777e-01,  1.5742e-01,  1.3640e-01, -1.0908e-04,\n",
      "          2.2240e-01,  9.3010e-02,  5.1110e-02,  7.8536e-02,  1.1707e-01,\n",
      "          1.6625e-01],\n",
      "        [ 7.9812e-02,  1.4294e-01, -3.5679e-01,  9.1015e-02,  1.6431e-01,\n",
      "          1.5644e-01,  6.7695e-02,  2.2524e-01,  7.3855e-02, -1.5979e-02,\n",
      "          1.1994e-01,  9.4934e-02,  1.3942e-01,  1.9374e-01,  8.4430e-02,\n",
      "          1.7472e-01],\n",
      "        [-2.1679e-01,  1.2197e-01,  9.3360e-02, -1.7752e-01,  1.3405e-01,\n",
      "          4.8992e-02,  1.2002e-01, -1.5166e-01, -2.1349e-01,  2.0156e-03,\n",
      "         -1.2433e-01,  1.9057e-01,  2.2460e-01,  1.5446e-01,  7.0570e-02,\n",
      "          1.8110e-01],\n",
      "        [ 2.2728e-01,  1.2361e-01, -6.1766e-02,  2.1419e-01,  6.6124e-02,\n",
      "          1.4158e-01,  1.1235e-01, -1.9817e-01,  1.9960e-01,  2.8299e-02,\n",
      "          2.3474e-01,  1.9331e-01, -1.2222e-01,  1.5202e-01,  1.0885e-01,\n",
      "         -2.0315e-01]])), ('cinn.module_list.14.subnet2.lin_2.bias', tensor([ 0.1437,  0.2096, -0.1401, -0.0961])), ('cinn.module_list.14.subnet2.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.14.subnet2.lin_2.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.14.subnet2.lin_2.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.15.perm', tensor([2, 1, 0, 3])), ('cinn.module_list.15.perm_inv', tensor([2, 1, 0, 3])), ('cinn.module_list.16.subnet1.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.16.subnet1.quant.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.16.subnet1.quant.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.16.subnet1.lin_1.0.weight', tensor([[-7.3431e-03,  3.3844e-02,  2.0773e-01,  7.2191e-02, -2.6550e-01,\n",
      "         -1.6397e-01],\n",
      "        [-2.5637e-14, -2.7640e-26, -4.7710e-16, -1.5957e-20, -7.1638e-39,\n",
      "         -3.8180e-40],\n",
      "        [ 1.1088e-02, -9.7724e-02,  2.1451e-01, -2.2385e-02,  1.1575e-02,\n",
      "          5.8329e-02],\n",
      "        [-1.0867e-02, -3.3281e-02,  1.6578e-01, -8.1562e-02, -9.0909e-02,\n",
      "         -9.6748e-02],\n",
      "        [-1.7416e-01, -2.7366e-02,  1.1694e-01,  1.2429e-01,  2.1075e-01,\n",
      "         -4.9216e-03],\n",
      "        [ 3.5230e-02, -1.0151e-01, -8.7839e-02,  2.8768e-01,  4.2191e-02,\n",
      "          2.5754e-02],\n",
      "        [ 6.1002e-02,  9.4007e-02, -1.9994e-02,  1.1301e-01,  1.6905e-01,\n",
      "          8.7755e-02],\n",
      "        [-2.3450e-01, -1.4558e-04, -7.2522e-02,  1.4533e-01,  7.6191e-02,\n",
      "          3.4314e-02],\n",
      "        [ 8.2039e-02,  1.1210e-01,  2.8799e-01,  2.7050e-01, -4.6496e-02,\n",
      "         -8.2235e-02],\n",
      "        [-1.0627e-02, -1.6877e-02,  2.0947e-01, -1.4430e-01, -2.1175e-02,\n",
      "         -9.2784e-02],\n",
      "        [ 1.7652e-02, -1.2395e-02,  2.0971e-01,  1.2523e-01, -1.4528e-01,\n",
      "         -2.4277e-01],\n",
      "        [-1.6385e-01, -1.8576e-02, -2.0577e-01, -2.1158e-01,  1.7743e-01,\n",
      "          1.8231e-01],\n",
      "        [ 1.8054e-01,  1.4894e-01,  2.8427e-02,  3.0544e-02,  8.2265e-02,\n",
      "          1.0924e-01],\n",
      "        [-1.4449e-01, -2.0678e-02,  1.5102e-01, -2.7492e-01,  2.0139e-01,\n",
      "          2.3184e-02],\n",
      "        [ 3.0605e-01,  4.7574e-02,  2.1310e-01,  2.8649e-02,  8.5440e-02,\n",
      "          3.1452e-03],\n",
      "        [-1.4897e-01,  4.5279e-02,  4.5913e-02,  8.0140e-02,  1.3519e-01,\n",
      "          3.7640e-02]])), ('cinn.module_list.16.subnet1.lin_1.0.bias', tensor([ 1.7829e-01, -4.9596e-12,  2.1654e-01,  1.7174e-01,  2.1714e-01,\n",
      "         2.5635e-01,  2.2796e-01,  1.6915e-01,  2.0613e-01,  1.8851e-01,\n",
      "         1.9506e-01,  6.6227e-02,  2.2926e-01,  1.3370e-01,  1.5785e-01,\n",
      "         2.5650e-01])), ('cinn.module_list.16.subnet1.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.16.subnet1.lin_1.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.16.subnet1.lin_1.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.16.subnet1.lin_2.weight', tensor([[ 1.0481e-01,  4.2743e-38,  1.5560e-01,  1.7056e-02,  1.3694e-01,\n",
      "          1.2781e-01,  1.6049e-01,  1.0831e-01,  3.4764e-01,  6.6730e-02,\n",
      "          1.8543e-01,  1.2553e-01,  2.0080e-01,  1.3742e-01,  2.6882e-01,\n",
      "          1.0676e-01],\n",
      "        [ 8.7061e-02, -6.2457e-38,  2.2529e-01,  1.7460e-01,  2.6136e-01,\n",
      "          2.5556e-01,  9.3873e-02,  2.4201e-01,  2.4038e-01,  1.0149e-01,\n",
      "          1.0940e-01,  1.5811e-01,  2.1660e-02,  1.3624e-01,  1.5160e-01,\n",
      "          1.9779e-01],\n",
      "        [-1.5533e-01, -1.3978e-38, -1.7277e-01, -1.8308e-01,  1.6277e-01,\n",
      "          1.1332e-01,  7.7671e-02,  1.7580e-01, -1.4186e-01, -1.6321e-01,\n",
      "         -1.5863e-01,  1.4220e-01,  4.6535e-02,  1.3213e-01, -7.0141e-02,\n",
      "          1.2661e-01],\n",
      "        [-1.1789e-01,  2.3601e-38,  1.5857e-01,  1.6107e-01,  9.6322e-02,\n",
      "         -1.3786e-01, -2.9582e-03,  5.6276e-02, -1.4818e-01,  1.7742e-01,\n",
      "         -1.7231e-01,  1.8145e-01,  5.9300e-02,  1.6129e-01,  1.9040e-01,\n",
      "          7.4647e-02]])), ('cinn.module_list.16.subnet1.lin_2.bias', tensor([ 0.1877,  0.2017, -0.0792, -0.1783])), ('cinn.module_list.16.subnet1.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.16.subnet1.lin_2.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.16.subnet1.lin_2.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.16.subnet2.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.16.subnet2.quant.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.16.subnet2.quant.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.16.subnet2.lin_1.0.weight', tensor([[ 0.1882, -0.0019,  0.1398,  0.1046, -0.1066, -0.0915],\n",
      "        [ 0.0245,  0.0742,  0.1380,  0.1240,  0.2036, -0.0574],\n",
      "        [-0.0676,  0.0057,  0.0047,  0.1639, -0.1171,  0.1974],\n",
      "        [ 0.1620, -0.2029,  0.1627, -0.0050,  0.0762,  0.0782],\n",
      "        [-0.1157,  0.0937, -0.0626,  0.1158, -0.1074,  0.2567],\n",
      "        [ 0.0215,  0.1532, -0.1771, -0.2209,  0.2103,  0.2259],\n",
      "        [-0.0755, -0.0028,  0.0862, -0.0725,  0.1946, -0.0937],\n",
      "        [-0.0383,  0.0120, -0.0779, -0.1817,  0.2234, -0.0898],\n",
      "        [ 0.0298,  0.3433, -0.3262,  0.3342, -0.3212, -0.1422],\n",
      "        [-0.0945,  0.0254,  0.0467, -0.1505,  0.1940, -0.0105],\n",
      "        [ 0.1862,  0.0303,  0.1229,  0.1195, -0.0494, -0.0242],\n",
      "        [ 0.0326, -0.1454,  0.1906,  0.0238,  0.0567, -0.2495],\n",
      "        [ 0.1029,  0.0190,  0.1741,  0.0913,  0.0704, -0.0723],\n",
      "        [-0.0893, -0.0841,  0.0824,  0.0248,  0.0915,  0.0373],\n",
      "        [-0.0633,  0.0012,  0.0840, -0.0606,  0.1825, -0.0830],\n",
      "        [ 0.0287,  0.1996, -0.0727, -0.1125,  0.1708,  0.1401]])), ('cinn.module_list.16.subnet2.lin_1.0.bias', tensor([ 0.2174,  0.2079,  0.2203,  0.2020,  0.2175,  0.2507,  0.2002,  0.1526,\n",
      "        -0.0312,  0.1494,  0.1590,  0.0725,  0.1540,  0.1955,  0.1720,  0.1601])), ('cinn.module_list.16.subnet2.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.16.subnet2.lin_1.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.16.subnet2.lin_1.activation_post_process.max_val', tensor(-inf)), ('cinn.module_list.16.subnet2.lin_2.weight', tensor([[ 0.0676,  0.1381,  0.2477,  0.1985,  0.2987,  0.1819,  0.1164,  0.0593,\n",
      "         -0.4878,  0.1606,  0.1130,  0.1125,  0.0242,  0.1542,  0.1124,  0.1176],\n",
      "        [ 0.1615,  0.2287,  0.0998,  0.1939,  0.1360,  0.1179,  0.0807,  0.1127,\n",
      "         -0.1498,  0.0630,  0.1583,  0.1598,  0.1914,  0.1479,  0.1355,  0.1526],\n",
      "        [ 0.1268,  0.1549, -0.1262,  0.0831, -0.1714, -0.2095,  0.2021,  0.1538,\n",
      "         -0.0296,  0.1655,  0.0346,  0.1675,  0.1005,  0.1312,  0.2045, -0.1412],\n",
      "        [ 0.1159, -0.0751,  0.1582,  0.0819,  0.1437, -0.1571, -0.1647, -0.2114,\n",
      "         -0.0502, -0.1588,  0.0872,  0.1157,  0.0404,  0.1105, -0.1748, -0.1654]])), ('cinn.module_list.16.subnet2.lin_2.bias', tensor([ 0.1931,  0.1800, -0.1385, -0.0489])), ('cinn.module_list.16.subnet2.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.16.subnet2.lin_2.activation_post_process.min_val', tensor(inf)), ('cinn.module_list.16.subnet2.lin_2.activation_post_process.max_val', tensor(-inf))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/spack_views/visionary-dls/lib/python3.8/site-packages/torch/quantization/observer.py:121: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_floating.eval()\n",
    "model_floating.fuse_model()\n",
    "model_floating.qconfig = torch.quantization.default_qconfig\n",
    "\n",
    "for m in model_floating.modules():\n",
    "    if type(m) == nn.Sequential:\n",
    "        m.qconfig = torch.quantization.default_qconfig\n",
    "        print(m, model_floating.qconfig)\n",
    "\n",
    "torch.quantization.prepare(model_floating, inplace=True)\n",
    "\n",
    "print(\"Pre-Calibrated state dict with Observer\")\n",
    "print(model_floating.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration run - floating model\n",
      "1.0\t0.0\t0.0\t0.0\n",
      "0.0\t1.0\t0.0\t0.0\n",
      "0.0\t0.0\t1.0\t0.0\n",
      "0.0\t0.0\t0.0\t1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Calibration run - floating model\")\n",
    "for k in range(4):\n",
    "    show_samples(model_floating, data, config, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrated state dict with Observer\n",
      "OrderedDict([('cinn.module_list.1.perm', tensor([2, 3, 1, 0])), ('cinn.module_list.1.perm_inv', tensor([3, 2, 0, 1])), ('cinn.module_list.2.subnet1.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.2.subnet1.quant.activation_post_process.min_val', tensor(-1.0603)), ('cinn.module_list.2.subnet1.quant.activation_post_process.max_val', tensor(1.9254)), ('cinn.module_list.2.subnet1.lin_1.0.weight', tensor([[-6.3718e-02,  2.2704e-02,  1.5997e-02, -9.9484e-02, -4.8681e-40,\n",
      "          8.9261e-02],\n",
      "        [ 1.2351e-01, -7.3390e-02, -1.3032e-01, -1.1414e-01,  1.5680e-01,\n",
      "          1.6682e-39],\n",
      "        [ 9.0425e-03,  3.9725e-03,  2.2071e-32, -1.9854e-38,  1.7462e-05,\n",
      "          9.9035e-03],\n",
      "        [ 1.1287e-01,  1.0318e-01, -6.9996e-02, -9.0046e-02,  1.1976e-01,\n",
      "          1.6756e-01],\n",
      "        [ 1.0469e-01,  7.9483e-02, -9.0949e-02, -1.0548e-01,  1.3954e-01,\n",
      "          1.9798e-01],\n",
      "        [-7.5446e-02,  1.2797e-01, -7.1518e-02, -7.6847e-02,  1.8507e-38,\n",
      "          1.6983e-01],\n",
      "        [ 8.4478e-02, -1.4780e-01,  2.1776e-01, -2.3118e-01,  1.2755e-01,\n",
      "          3.2281e-02],\n",
      "        [ 5.2725e-02, -2.1961e-01, -6.3929e-02, -1.0089e-01,  3.2166e-02,\n",
      "          2.0766e-38],\n",
      "        [-8.9426e-02, -1.1587e-01, -1.5234e-01,  2.3180e-01, -9.5839e-02,\n",
      "         -7.0867e-02],\n",
      "        [-4.5741e-02,  1.0398e-02,  1.6892e-01,  1.9478e-01, -1.3361e-01,\n",
      "         -2.3566e-01],\n",
      "        [ 1.7593e-03,  2.1866e-03, -1.3687e-03,  6.7889e-39, -8.3514e-08,\n",
      "          4.1697e-04],\n",
      "        [-4.9310e-02, -1.2655e-01,  2.7561e-01, -1.5909e-01,  5.5200e-02,\n",
      "          4.8816e-02],\n",
      "        [-1.3342e-01, -1.2408e-01,  2.3926e-01, -1.9257e-01, -1.0131e-01,\n",
      "         -1.5783e-01],\n",
      "        [-1.4271e-01, -1.4846e-01,  1.9418e-01, -1.7250e-01,  6.1550e-02,\n",
      "          7.6993e-02],\n",
      "        [-2.4360e-02, -5.0244e-02, -1.5711e-01,  2.0950e-01, -2.8397e-03,\n",
      "         -1.1578e-01],\n",
      "        [-1.9798e-01, -3.3995e-02, -1.7687e-01,  2.1523e-01,  2.2162e-38,\n",
      "          9.9054e-02]])), ('cinn.module_list.2.subnet1.lin_1.0.bias', tensor([ 0.0044,  0.0433, -0.0320,  0.1170,  0.1164,  0.0322,  0.1263,  0.0925,\n",
      "         0.0981,  0.1856, -0.0047,  0.1293,  0.1568,  0.1274,  0.1370,  0.1260])), ('cinn.module_list.2.subnet1.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.2.subnet1.lin_1.activation_post_process.min_val', tensor(0.)), ('cinn.module_list.2.subnet1.lin_1.activation_post_process.max_val', tensor(0.6346)), ('cinn.module_list.2.subnet1.lin_2.weight', tensor([[ 1.7042e-01,  1.0280e-01, -4.1664e-03,  8.4079e-02,  6.1928e-02,\n",
      "          3.6950e-02,  4.9250e-02,  9.6221e-02, -5.9871e-02, -1.2794e-03,\n",
      "          1.6340e-10,  8.3309e-02,  1.0954e-01,  1.5614e-01, -9.5581e-02,\n",
      "         -3.6528e-02],\n",
      "        [ 4.6724e-02,  6.8902e-02,  1.9120e-02,  5.7261e-02,  1.0294e-01,\n",
      "          7.5369e-02,  3.0319e-02,  5.8504e-02,  1.2393e-01, -1.1065e-01,\n",
      "         -4.8163e-09, -4.0231e-02, -1.4908e-02, -1.0915e-01,  5.0379e-02,\n",
      "          1.2185e-01],\n",
      "        [ 6.8445e-02,  1.4451e-01,  3.0307e-03,  1.4453e-01,  1.2112e-01,\n",
      "          1.3399e-01,  2.0955e-01,  1.4736e-01, -2.2887e-01, -1.6428e-01,\n",
      "          1.1175e-09,  1.8594e-01,  1.1091e-01,  2.1010e-01, -2.0547e-01,\n",
      "         -1.2220e-01],\n",
      "        [ 9.5804e-03,  2.0005e-01, -1.2366e-02,  1.4348e-01,  1.4211e-01,\n",
      "          1.5041e-01, -1.2007e-01,  6.1561e-02,  1.6726e-01, -1.3492e-01,\n",
      "         -4.9227e-09, -1.8739e-01, -2.5404e-01, -1.8849e-01,  1.5063e-01,\n",
      "          1.8574e-01]])), ('cinn.module_list.2.subnet1.lin_2.bias', tensor([0.0466, 0.0555, 0.0238, 0.0282])), ('cinn.module_list.2.subnet1.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.2.subnet1.lin_2.activation_post_process.min_val', tensor(-0.3820)), ('cinn.module_list.2.subnet1.lin_2.activation_post_process.max_val', tensor(0.3789)), ('cinn.module_list.2.subnet2.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.2.subnet2.quant.activation_post_process.min_val', tensor(-1.1102)), ('cinn.module_list.2.subnet2.quant.activation_post_process.max_val', tensor(2.1152)), ('cinn.module_list.2.subnet2.lin_1.0.weight', tensor([[-1.7315e-01, -1.0738e-01, -1.0674e-01, -1.1952e-38, -1.9613e-01,\n",
      "          1.9768e-01],\n",
      "        [-1.3333e-01, -7.8222e-02, -1.3455e-01, -1.6781e-02, -1.9426e-01,\n",
      "          2.4632e-01],\n",
      "        [-1.0701e-01, -1.1280e-01, -1.0828e-02, -2.6257e-02,  1.9461e-01,\n",
      "         -1.4867e-01],\n",
      "        [ 1.9222e-02,  2.2558e-03,  5.1502e-38, -3.3565e-02,  1.6159e-16,\n",
      "         -1.0697e-38],\n",
      "        [-1.9254e-01, -1.5399e-01, -3.6427e-02, -3.4836e-38, -1.9415e-01,\n",
      "          2.0557e-01],\n",
      "        [-6.6881e-02, -5.1754e-02, -1.0850e-01, -7.3560e-02,  1.4847e-01,\n",
      "          1.4773e-01],\n",
      "        [-1.3434e-01, -1.7858e-01, -1.9441e-38, -5.9823e-02,  2.1260e-01,\n",
      "         -2.2426e-01],\n",
      "        [-8.8198e-02, -1.2222e-01,  5.5693e-04, -7.0622e-02,  2.0466e-01,\n",
      "         -1.6069e-01],\n",
      "        [-6.2820e-16,  1.7744e-25,  1.9362e-38,  6.2844e-38, -2.2778e-13,\n",
      "          2.5168e-38],\n",
      "        [ 7.4629e-02,  9.0458e-02,  1.6015e-01,  9.2684e-02, -8.5881e-02,\n",
      "          2.3848e-02],\n",
      "        [-5.8425e-02, -3.4366e-02, -1.9281e-01, -1.3979e-01, -2.6889e-02,\n",
      "          2.2646e-01],\n",
      "        [ 1.3728e-01, -7.3751e-02, -2.2668e-38,  8.3395e-02, -1.2385e-01,\n",
      "         -1.2362e-01],\n",
      "        [-1.3133e-01, -1.1015e-01, -6.3018e-02, -2.4378e-02, -1.7900e-01,\n",
      "          2.2910e-01],\n",
      "        [ 1.0448e-01, -3.1433e-02, -2.1835e-02,  9.4880e-02, -6.5993e-02,\n",
      "         -5.7926e-02],\n",
      "        [ 5.2025e-02, -2.0624e-01,  4.8537e-38,  1.1180e-01, -9.5572e-02,\n",
      "         -1.0091e-01],\n",
      "        [ 9.7226e-03, -7.1584e-03, -1.2087e-02, -3.6312e-03, -5.3518e-06,\n",
      "         -1.3028e-14]])), ('cinn.module_list.2.subnet2.lin_1.0.bias', tensor([ 1.0832e-01,  1.2581e-01,  7.9915e-02, -3.1265e-02,  8.2558e-02,\n",
      "         1.1347e-01,  1.2553e-01,  9.4819e-02, -5.8261e-13,  1.3163e-01,\n",
      "         1.8253e-01,  6.9647e-02,  1.0059e-01,  2.1179e-02,  7.6320e-02,\n",
      "        -2.6854e-02])), ('cinn.module_list.2.subnet2.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.2.subnet2.lin_1.activation_post_process.min_val', tensor(0.)), ('cinn.module_list.2.subnet2.lin_1.activation_post_process.max_val', tensor(0.6337)), ('cinn.module_list.2.subnet2.lin_2.weight', tensor([[ 1.9358e-01,  1.2141e-01, -7.4102e-02, -3.2118e-03,  1.6749e-01,\n",
      "         -3.1822e-02, -1.1204e-02,  2.7908e-03,  1.1073e-38,  1.0711e-01,\n",
      "         -3.7921e-02,  7.4352e-02,  1.3092e-01,  9.2867e-02,  9.9356e-02,\n",
      "          6.0947e-03],\n",
      "        [-4.2537e-02, -5.4692e-02,  1.4670e-01,  3.1573e-02, -1.5069e-02,\n",
      "         -3.5292e-02,  1.4677e-01,  1.3348e-01, -2.2444e-38,  4.0336e-02,\n",
      "         -5.4831e-02,  8.6481e-02, -7.4145e-02,  4.7290e-03,  1.3402e-01,\n",
      "         -3.6415e-03],\n",
      "        [ 1.6613e-01,  1.5877e-01, -2.4389e-01, -5.5170e-03,  2.4339e-01,\n",
      "         -1.7409e-01, -2.1551e-01, -2.3239e-01, -2.3019e-38,  1.4690e-01,\n",
      "         -5.3303e-02,  1.4269e-01,  1.6527e-01,  1.1441e-01,  1.0984e-01,\n",
      "         -6.8214e-04],\n",
      "        [-2.3357e-01, -2.4047e-01,  2.1016e-01, -2.8818e-02, -2.2629e-01,\n",
      "         -1.3549e-01,  2.0468e-01,  1.6411e-01, -3.8820e-39,  5.7137e-02,\n",
      "         -2.0118e-01,  9.7636e-02, -2.2969e-01,  5.7923e-02,  8.4984e-02,\n",
      "          2.3359e-03]])), ('cinn.module_list.2.subnet2.lin_2.bias', tensor([0.0316, 0.0321, 0.0390, 0.0349])), ('cinn.module_list.2.subnet2.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.2.subnet2.lin_2.activation_post_process.min_val', tensor(-0.5612)), ('cinn.module_list.2.subnet2.lin_2.activation_post_process.max_val', tensor(0.3432)), ('cinn.module_list.3.perm', tensor([3, 2, 0, 1])), ('cinn.module_list.3.perm_inv', tensor([2, 3, 1, 0])), ('cinn.module_list.4.subnet1.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.4.subnet1.quant.activation_post_process.min_val', tensor(-1.1212)), ('cinn.module_list.4.subnet1.quant.activation_post_process.max_val', tensor(1.9748)), ('cinn.module_list.4.subnet1.lin_1.0.weight', tensor([[-7.4000e-02, -1.0740e-01, -3.2874e-02, -4.5923e-02,  2.1407e-01,\n",
      "         -1.0263e-01],\n",
      "        [-1.0640e-01,  1.8263e-02, -7.5568e-03,  1.3001e-01, -1.8716e-01,\n",
      "          1.9735e-01],\n",
      "        [ 8.2141e-02, -1.8764e-01,  1.4368e-01, -6.8110e-38, -1.8023e-01,\n",
      "         -5.6967e-02],\n",
      "        [-2.1414e-02, -1.8354e-02,  4.2434e-40,  2.1649e-02, -4.0020e-38,\n",
      "          6.8457e-03],\n",
      "        [-3.3533e-04, -4.8876e-02, -2.2840e-01, -1.8414e-01,  1.6397e-01,\n",
      "          1.4493e-01],\n",
      "        [ 6.0188e-02, -2.1310e-01,  1.7891e-01,  3.3711e-38, -8.3268e-02,\n",
      "         -1.6092e-01],\n",
      "        [-6.6887e-02, -6.4118e-02, -1.4349e-01, -1.5453e-01,  2.0367e-01,\n",
      "         -1.4788e-01],\n",
      "        [ 1.2953e-02, -7.8155e-02, -1.7404e-01, -6.9951e-02,  2.0858e-01,\n",
      "          2.0711e-01],\n",
      "        [ 1.2469e-01, -6.5800e-02,  1.5871e-01, -2.8567e-02, -1.5636e-01,\n",
      "         -1.7365e-01],\n",
      "        [-1.2865e-01,  1.2592e-01, -4.7869e-39,  1.2110e-01,  8.2756e-02,\n",
      "         -1.5202e-01],\n",
      "        [-6.3771e-02, -5.0830e-02, -7.4978e-02, -1.1790e-01,  2.3907e-01,\n",
      "         -1.2274e-01],\n",
      "        [ 2.5867e-02, -3.4493e-03, -2.3046e-01, -1.8265e-01,  1.9421e-01,\n",
      "         -1.0708e-01],\n",
      "        [-2.5348e-01,  6.2143e-02, -6.2250e-39,  1.1553e-01,  2.9613e-02,\n",
      "         -1.4039e-01],\n",
      "        [-5.4309e-02,  1.6056e-01,  6.4375e-02,  1.5458e-01, -1.7331e-01,\n",
      "         -1.4629e-01],\n",
      "        [-3.8031e-02,  1.3287e-01, -4.0173e-38,  1.0020e-01, -1.0388e-01,\n",
      "         -6.6041e-02],\n",
      "        [-1.2925e-01, -6.8421e-02, -5.4380e-02,  1.6329e-01, -2.1905e-01,\n",
      "          1.7974e-01]])), ('cinn.module_list.4.subnet1.lin_1.0.bias', tensor([ 0.1058,  0.1139,  0.0787, -0.0447,  0.2013,  0.1766,  0.1565,  0.1693,\n",
      "         0.0804,  0.0739,  0.1302,  0.1833,  0.0570,  0.0848, -0.0007,  0.1442])), ('cinn.module_list.4.subnet1.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.4.subnet1.lin_1.activation_post_process.min_val', tensor(0.)), ('cinn.module_list.4.subnet1.lin_1.activation_post_process.max_val', tensor(0.5995)), ('cinn.module_list.4.subnet1.lin_2.weight', tensor([[-1.7383e-02,  1.3179e-01,  6.6573e-02, -3.3248e-02,  3.1977e-03,\n",
      "          8.3517e-02, -4.8819e-02, -6.9899e-03,  7.4097e-02,  6.5504e-02,\n",
      "         -7.3560e-02, -2.7354e-02,  8.8424e-02,  6.2392e-02,  8.5751e-02,\n",
      "          6.5268e-02],\n",
      "        [ 1.1998e-01,  9.1656e-02,  1.4420e-01, -3.2759e-02,  2.7082e-02,\n",
      "          1.0187e-01,  1.7794e-01, -1.5059e-02,  9.6756e-02,  5.3518e-02,\n",
      "          7.5322e-02, -1.8611e-02,  7.6486e-02,  9.3861e-02, -1.4598e-02,\n",
      "         -5.2994e-05],\n",
      "        [-1.9622e-01,  1.5062e-01,  1.6810e-01, -3.9774e-02, -1.7533e-01,\n",
      "          1.4446e-01, -2.2439e-01, -1.8592e-01,  1.8559e-01,  3.9384e-02,\n",
      "         -2.2194e-01, -2.2457e-01,  7.4890e-02,  1.4892e-01,  1.1609e-01,\n",
      "          2.2291e-01],\n",
      "        [ 1.6496e-01, -9.2654e-02,  1.1993e-01, -2.3512e-03, -1.7327e-01,\n",
      "          1.5480e-01,  1.3705e-01, -1.7403e-01,  1.8593e-01,  2.1610e-01,\n",
      "          1.5898e-01,  5.6097e-03,  1.5618e-01,  1.6559e-01,  7.4089e-02,\n",
      "         -2.1173e-01]])), ('cinn.module_list.4.subnet1.lin_2.bias', tensor([0.0465, 0.1263, 0.0181, 0.0521])), ('cinn.module_list.4.subnet1.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.4.subnet1.lin_2.activation_post_process.min_val', tensor(-0.4353)), ('cinn.module_list.4.subnet1.lin_2.activation_post_process.max_val', tensor(0.3312)), ('cinn.module_list.4.subnet2.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.4.subnet2.quant.activation_post_process.min_val', tensor(-1.0603)), ('cinn.module_list.4.subnet2.quant.activation_post_process.max_val', tensor(1.9254)), ('cinn.module_list.4.subnet2.lin_1.0.weight', tensor([[ 1.4506e-01, -7.9618e-02, -1.1082e-01, -1.0888e-01,  9.3376e-02,\n",
      "          1.4648e-38],\n",
      "        [ 7.2653e-02, -1.3579e-01, -1.1494e-01,  1.2505e-01,  1.5833e-01,\n",
      "         -3.7069e-02],\n",
      "        [-1.0066e-01,  1.1099e-01, -1.1496e-01, -1.1716e-01, -6.5617e-38,\n",
      "          1.6204e-01],\n",
      "        [ 3.9160e-02,  6.3537e-02, -1.2869e-01,  2.1009e-01,  1.1019e-01,\n",
      "          1.4007e-01],\n",
      "        [-1.9626e-02, -1.9578e-01,  2.1671e-01, -1.8792e-01,  1.0739e-01,\n",
      "          3.3844e-02],\n",
      "        [ 4.6281e-02, -2.1231e-01, -1.3436e-01, -1.1813e-01,  1.2834e-01,\n",
      "         -4.2072e-38],\n",
      "        [-4.7815e-02, -6.6039e-02,  2.1999e-01, -1.0689e-01, -1.6990e-01,\n",
      "         -1.5520e-01],\n",
      "        [ 1.7004e-01,  1.6136e-01, -7.7334e-02, -9.0977e-02,  1.4858e-01,\n",
      "          1.0232e-01],\n",
      "        [-1.3014e-01,  1.3992e-01, -1.7991e-01, -1.7229e-01,  1.6200e-38,\n",
      "          1.1457e-01],\n",
      "        [-8.1062e-02, -1.9262e-01,  2.1998e-01, -2.0350e-01,  1.3269e-02,\n",
      "          9.8050e-03],\n",
      "        [ 1.0729e-01, -5.2312e-02, -9.8134e-02, -9.8954e-02,  1.7388e-01,\n",
      "         -7.0331e-39],\n",
      "        [-3.5135e-02, -7.0855e-02, -1.2966e-01,  3.0879e-01, -2.3056e-02,\n",
      "         -6.6920e-02],\n",
      "        [ 1.2380e-01,  1.2546e-01, -2.5985e-02, -4.7200e-02,  1.2043e-01,\n",
      "          1.2755e-01],\n",
      "        [ 1.4680e-01, -1.0981e-01, -1.3407e-01, -1.5346e-01,  1.5628e-01,\n",
      "          3.7172e-38],\n",
      "        [ 7.8048e-03,  9.9662e-03, -1.0659e-01,  2.3456e-01, -2.1512e-02,\n",
      "         -1.8067e-02],\n",
      "        [-2.1232e-01, -2.3168e-01, -1.2065e-01,  1.2044e-01,  5.4862e-38,\n",
      "          3.5762e-38]])), ('cinn.module_list.4.subnet2.lin_1.0.bias', tensor([0.0319, 0.1339, 0.0577, 0.1505, 0.1533, 0.1127, 0.1691, 0.1313, 0.0997,\n",
      "        0.1595, 0.0307, 0.0997, 0.0789, 0.0555, 0.0969, 0.0152])), ('cinn.module_list.4.subnet2.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.4.subnet2.lin_1.activation_post_process.min_val', tensor(0.)), ('cinn.module_list.4.subnet2.lin_1.activation_post_process.max_val', tensor(0.6413)), ('cinn.module_list.4.subnet2.lin_2.weight', tensor([[ 0.0543,  0.0197,  0.0327,  0.0818,  0.0794,  0.0712, -0.0308,  0.0381,\n",
      "          0.0944,  0.0121,  0.0759,  0.0519,  0.0507,  0.0359,  0.0568,  0.1509],\n",
      "        [ 0.0683,  0.0254,  0.0769,  0.0936,  0.0652,  0.0877,  0.0569,  0.0742,\n",
      "          0.0797,  0.1021,  0.0877, -0.0638,  0.0576,  0.0375, -0.0803,  0.2740],\n",
      "        [ 0.1147,  0.2131,  0.1461,  0.1685, -0.1276,  0.1512, -0.2506,  0.1522,\n",
      "          0.1123, -0.2099,  0.1309,  0.1372,  0.1452,  0.1025,  0.1122,  0.1391],\n",
      "        [ 0.1334, -0.0297,  0.1092, -0.0543,  0.1589,  0.1333,  0.0094,  0.0925,\n",
      "          0.1137,  0.1760,  0.1259, -0.2141,  0.1125,  0.1392, -0.1682, -0.0873]])), ('cinn.module_list.4.subnet2.lin_2.bias', tensor([ 0.0834,  0.1103, -0.0041, -0.0316])), ('cinn.module_list.4.subnet2.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.4.subnet2.lin_2.activation_post_process.min_val', tensor(-0.2545)), ('cinn.module_list.4.subnet2.lin_2.activation_post_process.max_val', tensor(0.4655)), ('cinn.module_list.5.perm', tensor([2, 3, 1, 0])), ('cinn.module_list.5.perm_inv', tensor([3, 2, 0, 1])), ('cinn.module_list.6.subnet1.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.6.subnet1.quant.activation_post_process.min_val', tensor(-1.0150)), ('cinn.module_list.6.subnet1.quant.activation_post_process.max_val', tensor(1.5360)), ('cinn.module_list.6.subnet1.lin_1.0.weight', tensor([[-0.0338,  0.0461,  0.0515, -0.1714,  0.1752,  0.1714],\n",
      "        [ 0.0828,  0.1091, -0.0089, -0.1570,  0.1417,  0.1702],\n",
      "        [-0.0038,  0.0257,  0.1868,  0.1110, -0.1753, -0.1997],\n",
      "        [-0.2475,  0.0749,  0.1004, -0.1636, -0.0466,  0.1582],\n",
      "        [-0.1156,  0.1724, -0.1774, -0.1608, -0.0498,  0.1846],\n",
      "        [ 0.0201,  0.0922, -0.0364, -0.1224,  0.1566,  0.1786],\n",
      "        [-0.1054, -0.0387,  0.2270, -0.1243, -0.1655, -0.0572],\n",
      "        [-0.0186, -0.0031,  0.2189,  0.0591, -0.1910, -0.1901],\n",
      "        [-0.0933, -0.0525,  0.2321, -0.0126, -0.1486, -0.1832],\n",
      "        [ 0.0688,  0.0833, -0.1410, -0.1579,  0.1478,  0.1657],\n",
      "        [-0.0667, -0.0431, -0.1188,  0.1917,  0.0424,  0.0788],\n",
      "        [ 0.0154,  0.0933, -0.0981, -0.1065,  0.0643,  0.0232],\n",
      "        [-0.0120, -0.0046, -0.1692,  0.2091,  0.0364, -0.0509],\n",
      "        [-0.0336, -0.0216, -0.1016,  0.2237,  0.0433,  0.0865],\n",
      "        [-0.0135, -0.0066,  0.2351,  0.2138, -0.1687, -0.1489],\n",
      "        [ 0.0158,  0.0544,  0.0582, -0.1725,  0.1402,  0.1334]])), ('cinn.module_list.6.subnet1.lin_1.0.bias', tensor([ 0.1411,  0.0839,  0.1499,  0.0928,  0.0450,  0.0796,  0.1767,  0.1681,\n",
      "         0.1285,  0.0979,  0.1479, -0.0242,  0.1515,  0.1170,  0.1686,  0.1225])), ('cinn.module_list.6.subnet1.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.6.subnet1.lin_1.activation_post_process.min_val', tensor(0.)), ('cinn.module_list.6.subnet1.lin_1.activation_post_process.max_val', tensor(0.5912)), ('cinn.module_list.6.subnet1.lin_2.weight', tensor([[ 0.0728,  0.1071, -0.0388,  0.0213,  0.0559,  0.1161,  0.0913,  0.0793,\n",
      "          0.0583,  0.0561, -0.0277,  0.0427, -0.0584, -0.0655,  0.0629,  0.1651],\n",
      "        [ 0.0997,  0.0668,  0.0506,  0.1105,  0.0900,  0.0983, -0.0336, -0.0030,\n",
      "          0.0038,  0.1095,  0.1031,  0.1019,  0.0657,  0.0858, -0.0192,  0.0555],\n",
      "        [ 0.2302,  0.1572, -0.1637,  0.2297,  0.1514,  0.1677,  0.1667, -0.1021,\n",
      "         -0.0127,  0.1388, -0.1728,  0.0345, -0.1851, -0.2084, -0.1656,  0.1916],\n",
      "        [ 0.0369,  0.0445, -0.1890,  0.0117,  0.1000,  0.0921, -0.2234, -0.2259,\n",
      "         -0.1812,  0.1147,  0.2154,  0.0497,  0.1984,  0.2342, -0.1625,  0.0280]])), ('cinn.module_list.6.subnet1.lin_2.bias', tensor([ 0.0753,  0.1228, -0.0412, -0.0383])), ('cinn.module_list.6.subnet1.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.6.subnet1.lin_2.activation_post_process.min_val', tensor(-0.4099)), ('cinn.module_list.6.subnet1.lin_2.activation_post_process.max_val', tensor(0.4482)), ('cinn.module_list.6.subnet2.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.6.subnet2.quant.activation_post_process.min_val', tensor(-1.1212)), ('cinn.module_list.6.subnet2.quant.activation_post_process.max_val', tensor(1.9748)), ('cinn.module_list.6.subnet2.lin_1.0.weight', tensor([[-1.1370e-02, -1.2411e-02,  9.3906e-02, -5.2314e-02,  2.3652e-01,\n",
      "         -1.6819e-01],\n",
      "        [ 1.5583e-01,  1.1219e-01,  1.8677e-01,  1.0546e-01, -1.4588e-01,\n",
      "         -9.9503e-02],\n",
      "        [ 1.1803e-01, -3.2268e-02,  6.5844e-02,  1.2002e-01, -1.3671e-01,\n",
      "         -1.0570e-01],\n",
      "        [-9.2983e-02,  3.4768e-02,  1.9754e-01, -6.3044e-02,  2.4240e-01,\n",
      "         -1.5245e-01],\n",
      "        [-7.5303e-02,  7.1414e-03, -1.4892e-01, -5.6691e-02,  1.7702e-01,\n",
      "          1.1966e-01],\n",
      "        [-2.0940e-01, -6.4866e-02,  4.3077e-02,  2.3747e-38, -2.0223e-01,\n",
      "          1.8832e-01],\n",
      "        [-6.7208e-02, -5.7880e-02, -1.3074e-01, -1.0429e-01,  2.5273e-01,\n",
      "         -1.1522e-01],\n",
      "        [ 1.5279e-01,  1.2525e-01,  1.2749e-01,  1.1463e-01, -1.5653e-01,\n",
      "         -9.4257e-02],\n",
      "        [ 8.0452e-03,  6.7920e-04, -6.1626e-38, -1.5922e-02,  1.4604e-38,\n",
      "         -5.8100e-38],\n",
      "        [-1.8219e-01,  4.5181e-02,  1.3948e-01, -3.0269e-38, -8.8155e-02,\n",
      "          7.8654e-02],\n",
      "        [ 1.1377e-01,  1.2519e-01,  1.5665e-01,  1.4789e-01, -1.6014e-01,\n",
      "         -1.1348e-01],\n",
      "        [-2.3834e-02, -1.3608e-02, -1.6087e-01, -1.4588e-01,  2.2328e-01,\n",
      "         -1.3934e-01],\n",
      "        [ 1.2084e-01,  1.2711e-01,  1.5803e-01,  1.5180e-01, -1.2844e-01,\n",
      "         -9.1185e-02],\n",
      "        [ 2.5322e-03, -4.1591e-02, -9.0813e-02, -1.6829e-01,  1.9678e-01,\n",
      "         -1.8517e-01],\n",
      "        [-5.5610e-02, -2.6569e-03, -2.0101e-01, -6.1579e-02,  1.4169e-01,\n",
      "          1.4760e-01],\n",
      "        [ 3.3927e-02,  5.3614e-03, -1.6625e-01, -1.3647e-01,  1.7224e-01,\n",
      "         -1.7797e-01]])), ('cinn.module_list.6.subnet2.lin_1.0.bias', tensor([ 0.1710,  0.0677,  0.0367,  0.1618,  0.1504,  0.1294,  0.1217,  0.0743,\n",
      "        -0.0142,  0.1734,  0.0921,  0.1429,  0.0579,  0.1277,  0.1643,  0.1539])), ('cinn.module_list.6.subnet2.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.6.subnet2.lin_1.activation_post_process.min_val', tensor(0.)), ('cinn.module_list.6.subnet2.lin_1.activation_post_process.max_val', tensor(0.5661)), ('cinn.module_list.6.subnet2.lin_2.weight', tensor([[ 2.4041e-02,  1.0432e-01,  9.6875e-02,  8.6010e-03,  5.0412e-02,\n",
      "          5.5104e-02, -2.9682e-03,  9.6676e-02, -2.7421e-07,  1.5327e-01,\n",
      "          1.4049e-01, -1.8463e-03,  6.7833e-02,  4.2111e-03,  1.3408e-04,\n",
      "         -1.4253e-02],\n",
      "        [ 8.0605e-02,  6.7563e-02,  1.1716e-01,  5.5737e-02, -3.6072e-02,\n",
      "          7.3284e-02,  1.3604e-01,  3.3853e-02, -1.1758e-06,  1.4756e-01,\n",
      "          6.4645e-02,  8.4517e-02,  7.7260e-02, -5.0886e-03,  2.0182e-02,\n",
      "         -1.5186e-02],\n",
      "        [-1.9002e-01,  1.5184e-01,  1.1365e-01, -1.5669e-01, -1.7010e-01,\n",
      "          2.0575e-01, -2.2434e-01,  1.2419e-01, -4.0433e-06,  1.4717e-01,\n",
      "          1.5960e-01, -2.6802e-01,  1.0451e-01, -2.0862e-01, -1.5824e-01,\n",
      "         -1.9367e-01],\n",
      "        [ 2.0038e-01,  1.6317e-01,  8.4997e-02,  1.9722e-01, -1.5779e-01,\n",
      "         -1.9181e-01,  1.5666e-01,  1.3457e-01,  4.3563e-06,  2.5673e-02,\n",
      "          1.5049e-01,  1.5980e-01,  1.2781e-01,  7.9921e-02, -1.7093e-01,\n",
      "          9.4971e-02]])), ('cinn.module_list.6.subnet2.lin_2.bias', tensor([0.1358, 0.0730, 0.0300, 0.0026])), ('cinn.module_list.6.subnet2.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.6.subnet2.lin_2.activation_post_process.min_val', tensor(-0.5365)), ('cinn.module_list.6.subnet2.lin_2.activation_post_process.max_val', tensor(0.3829)), ('cinn.module_list.7.perm', tensor([3, 1, 0, 2])), ('cinn.module_list.7.perm_inv', tensor([2, 1, 3, 0])), ('cinn.module_list.8.subnet1.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.8.subnet1.quant.activation_post_process.min_val', tensor(-0.9472)), ('cinn.module_list.8.subnet1.quant.activation_post_process.max_val', tensor(1.4112)), ('cinn.module_list.8.subnet1.lin_1.0.weight', tensor([[-3.3599e-03, -4.2859e-02, -6.3515e-02,  2.1239e-01, -1.5205e-01,\n",
      "         -1.6964e-01],\n",
      "        [-8.0483e-03, -6.3311e-04, -1.9206e-01,  1.3552e-01,  2.2716e-01,\n",
      "         -2.0760e-01],\n",
      "        [-1.4308e-01,  2.3297e-02, -5.4965e-02, -1.8226e-01,  5.0868e-02,\n",
      "          1.7837e-01],\n",
      "        [-3.6971e-03, -6.7042e-02, -6.1562e-02,  2.5344e-01, -1.3252e-01,\n",
      "         -1.1901e-01],\n",
      "        [-4.7201e-02,  5.0916e-02,  8.0303e-02,  1.9725e-01, -1.8231e-01,\n",
      "          6.8420e-02],\n",
      "        [ 5.0299e-02,  6.5591e-04, -9.1819e-02,  7.7902e-02,  1.8361e-01,\n",
      "         -2.3817e-02],\n",
      "        [ 1.5663e-01, -1.0863e-01,  1.7207e-01, -1.1740e-01, -1.6967e-01,\n",
      "          1.2425e-39],\n",
      "        [-9.0107e-03,  9.2587e-02, -1.0557e-01,  2.1886e-01, -1.2445e-01,\n",
      "         -2.3635e-01],\n",
      "        [-9.6395e-03,  7.5743e-02, -1.6059e-01,  2.2491e-01,  1.9074e-01,\n",
      "         -2.7260e-01],\n",
      "        [ 4.7656e-02,  7.1353e-03,  6.5023e-02, -1.5272e-01,  2.6350e-01,\n",
      "         -9.9072e-02],\n",
      "        [ 1.3561e-02,  1.6686e-02, -2.2993e-01,  2.4157e-01,  1.8473e-01,\n",
      "         -2.3343e-01],\n",
      "        [ 3.0375e-02, -3.7093e-01,  1.5059e-01, -9.5222e-02, -1.9363e-01,\n",
      "          2.6893e-38],\n",
      "        [-7.6319e-02,  1.2992e-02, -2.6060e-02,  2.1516e-01, -1.8300e-01,\n",
      "         -3.7157e-02],\n",
      "        [ 6.1560e-02,  6.3484e-02,  1.9996e-01, -1.4959e-01, -1.4164e-01,\n",
      "          1.8368e-01],\n",
      "        [-2.3505e-01,  5.5208e-02, -8.1731e-02, -8.5339e-02,  1.7685e-02,\n",
      "          9.6486e-02],\n",
      "        [-6.6517e-38,  1.7009e-38,  5.3147e-38, -6.4824e-15, -4.7796e-38,\n",
      "         -4.5204e-38]])), ('cinn.module_list.8.subnet1.lin_1.0.bias', tensor([ 1.5826e-01,  1.8289e-01,  9.5474e-02,  1.4245e-01,  1.6067e-01,\n",
      "         6.2892e-02, -8.1824e-03,  1.0988e-01,  1.6134e-01,  1.3538e-01,\n",
      "         2.0215e-01,  2.8252e-02,  1.6776e-01,  7.5159e-02,  1.5710e-01,\n",
      "        -1.1991e-14])), ('cinn.module_list.8.subnet1.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.8.subnet1.lin_1.activation_post_process.min_val', tensor(0.)), ('cinn.module_list.8.subnet1.lin_1.activation_post_process.max_val', tensor(0.5489)), ('cinn.module_list.8.subnet1.lin_2.weight', tensor([[ 3.5974e-02,  2.2589e-01,  1.7948e-01,  3.5565e-02,  1.2618e-01,\n",
      "          1.9900e-01,  5.0812e-02,  7.5857e-02,  5.1100e-02,  1.0804e-01,\n",
      "          8.1780e-02,  2.9781e-02,  3.8806e-02,  7.5315e-02,  5.0630e-02,\n",
      "          5.6674e-38],\n",
      "        [-1.6191e-04,  1.8115e-02, -1.9809e-02,  1.5673e-02,  2.8828e-02,\n",
      "          2.3274e-02,  4.7778e-02,  2.3050e-02,  1.2235e-01,  5.0234e-02,\n",
      "          1.0173e-01,  8.9988e-02,  3.8578e-02,  5.4737e-02,  1.3216e-01,\n",
      "          2.1326e-38],\n",
      "        [ 1.0801e-01, -2.3567e-01,  1.3947e-01,  1.2401e-01,  1.6449e-01,\n",
      "         -1.0707e-01,  1.8009e-01,  1.1350e-01, -1.8040e-01, -2.2584e-01,\n",
      "         -1.7490e-01,  1.2950e-01,  1.9203e-01,  1.5474e-01,  1.3145e-01,\n",
      "         -3.0043e-22],\n",
      "        [-2.1148e-01, -1.8101e-01,  1.9517e-01, -2.5295e-01, -1.6529e-01,\n",
      "         -8.1113e-02,  1.5124e-01, -2.5079e-01, -1.7035e-01,  1.7861e-01,\n",
      "         -2.0386e-01,  2.0162e-01, -2.0478e-01,  1.3028e-01,  1.4422e-01,\n",
      "         -1.7846e-20]])), ('cinn.module_list.8.subnet1.lin_2.bias', tensor([ 0.1598,  0.0969, -0.0248, -0.0388])), ('cinn.module_list.8.subnet1.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.8.subnet1.lin_2.activation_post_process.min_val', tensor(-0.6689)), ('cinn.module_list.8.subnet1.lin_2.activation_post_process.max_val', tensor(0.4602)), ('cinn.module_list.8.subnet2.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.8.subnet2.quant.activation_post_process.min_val', tensor(-1.0150)), ('cinn.module_list.8.subnet2.quant.activation_post_process.max_val', tensor(1.6994)), ('cinn.module_list.8.subnet2.lin_1.0.weight', tensor([[ 7.6632e-02,  9.3730e-02, -1.6216e-01,  8.2990e-02,  1.1580e-01,\n",
      "         -1.2229e-01],\n",
      "        [-6.4824e-02,  1.6352e-01, -1.0602e-01,  1.3224e-01,  2.5844e-02,\n",
      "         -1.5399e-01],\n",
      "        [-1.1026e-02,  1.1058e-03,  1.1921e-01, -2.0138e-01, -1.8002e-01,\n",
      "          2.0225e-01],\n",
      "        [-5.8759e-02,  1.8067e-01, -1.0800e-01,  8.4074e-02,  3.6916e-02,\n",
      "         -1.6271e-01],\n",
      "        [-8.2623e-02, -7.3119e-02,  2.2738e-01, -3.2751e-02, -1.6763e-01,\n",
      "          5.7244e-02],\n",
      "        [ 1.5281e-01,  2.5406e-03,  6.3112e-38, -2.9963e-02, -1.0502e-02,\n",
      "          3.6249e-38],\n",
      "        [ 1.1549e-01,  1.4297e-01, -1.5492e-01,  1.3433e-01,  1.2356e-01,\n",
      "         -1.4887e-01],\n",
      "        [-5.8262e-02, -8.7179e-02, -1.4223e-01,  5.7118e-02,  2.0477e-02,\n",
      "          2.5656e-01],\n",
      "        [ 1.1754e-01,  1.4422e-01, -1.5158e-01,  1.0424e-01,  1.5216e-01,\n",
      "         -1.3581e-01],\n",
      "        [-9.0040e-03,  3.4413e-02,  2.1613e-01, -1.5219e-01,  3.1528e-02,\n",
      "         -1.7394e-01],\n",
      "        [ 8.8784e-02,  1.4981e-01, -1.0840e-01,  8.2394e-02,  1.4030e-01,\n",
      "         -1.2185e-01],\n",
      "        [-4.1515e-02, -8.7837e-02, -1.3669e-01, -5.3253e-02, -1.4225e-01,\n",
      "          1.8343e-01],\n",
      "        [ 3.4334e-03, -1.5698e-01, -1.2546e-01,  1.1647e-01,  6.4126e-02,\n",
      "          1.8902e-01],\n",
      "        [ 3.2975e-03, -9.5694e-02,  1.6401e-01, -5.7669e-02, -1.6678e-01,\n",
      "          1.8325e-01],\n",
      "        [-6.3866e-02, -1.0855e-01, -1.3783e-01, -1.4331e-01, -1.3665e-02,\n",
      "          1.9291e-01],\n",
      "        [-1.8378e-01,  2.3624e-03, -2.0936e-02,  1.7832e-01,  8.3951e-02,\n",
      "         -9.4652e-02]])), ('cinn.module_list.8.subnet2.lin_1.0.bias', tensor([ 0.1005,  0.0377,  0.1773,  0.0212,  0.1550, -0.0546,  0.1130,  0.1090,\n",
      "         0.1019,  0.1536,  0.0702,  0.1289,  0.1426,  0.1554,  0.1554,  0.0888])), ('cinn.module_list.8.subnet2.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.8.subnet2.lin_1.activation_post_process.min_val', tensor(0.)), ('cinn.module_list.8.subnet2.lin_1.activation_post_process.max_val', tensor(0.5142)), ('cinn.module_list.8.subnet2.lin_2.weight', tensor([[ 0.1127,  0.1096,  0.0574,  0.0631,  0.1949, -0.2254,  0.1031, -0.0113,\n",
      "          0.1154, -0.0257,  0.0825,  0.0038,  0.1491,  0.0735,  0.0911,  0.1754],\n",
      "        [ 0.0418,  0.0971,  0.0094,  0.0559,  0.1120, -0.1404,  0.0794,  0.1725,\n",
      "          0.0467,  0.0898,  0.0667, -0.0309,  0.0831,  0.0539,  0.0161,  0.1344],\n",
      "        [ 0.1274,  0.1521, -0.1382,  0.1278, -0.0921,  0.0278,  0.1177,  0.0519,\n",
      "          0.1506, -0.2290,  0.1523,  0.1087,  0.1633, -0.1962,  0.1053,  0.1210],\n",
      "        [ 0.0842,  0.1650, -0.1692,  0.1511, -0.0194, -0.0337,  0.1663, -0.1201,\n",
      "          0.1201,  0.2142,  0.1132, -0.2065, -0.1259, -0.2184, -0.1959,  0.0989]])), ('cinn.module_list.8.subnet2.lin_2.bias', tensor([ 0.0816,  0.1270, -0.0995, -0.0374])), ('cinn.module_list.8.subnet2.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.8.subnet2.lin_2.activation_post_process.min_val', tensor(-0.4944)), ('cinn.module_list.8.subnet2.lin_2.activation_post_process.max_val', tensor(0.3779)), ('cinn.module_list.9.perm', tensor([0, 1, 3, 2])), ('cinn.module_list.9.perm_inv', tensor([0, 1, 3, 2])), ('cinn.module_list.10.subnet1.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.10.subnet1.quant.activation_post_process.min_val', tensor(-1.2146)), ('cinn.module_list.10.subnet1.quant.activation_post_process.max_val', tensor(1.4718)), ('cinn.module_list.10.subnet1.lin_1.0.weight', tensor([[-0.0729,  0.1923,  0.0154, -0.0097, -0.0895,  0.0738],\n",
      "        [-0.0095, -0.0039, -0.0260, -0.0142, -0.0216, -0.0049],\n",
      "        [-0.1300,  0.0173, -0.0209,  0.1947, -0.1443,  0.0921],\n",
      "        [ 0.0075, -0.0921, -0.0391, -0.1229,  0.2115,  0.0104],\n",
      "        [ 0.0047, -0.1390,  0.0922, -0.1669,  0.2674,  0.0339],\n",
      "        [ 0.0194, -0.1504,  0.0890, -0.1845,  0.1826,  0.0397],\n",
      "        [ 0.0540,  0.0232, -0.2551,  0.2194,  0.1704, -0.2310],\n",
      "        [ 0.0701,  0.0230,  0.1654, -0.1363, -0.1450,  0.1967],\n",
      "        [ 0.0458,  0.0104, -0.2625,  0.2071,  0.2012, -0.2320],\n",
      "        [ 0.0778,  0.0764,  0.1207, -0.1262, -0.2333,  0.1719],\n",
      "        [-0.2159,  0.0119,  0.0314, -0.0743,  0.1409,  0.1446],\n",
      "        [ 0.0058, -0.1375,  0.0629, -0.1380,  0.2170,  0.0603],\n",
      "        [ 0.0449,  0.1249, -0.0160,  0.3167,  0.0610, -0.0252],\n",
      "        [-0.2788,  0.0060,  0.1474, -0.2527, -0.1833,  0.1741],\n",
      "        [-0.0106,  0.1983, -0.1269,  0.2940, -0.1231, -0.0501],\n",
      "        [ 0.0883,  0.0680,  0.1461, -0.2133, -0.2206,  0.1184]])), ('cinn.module_list.10.subnet1.lin_1.0.bias', tensor([-0.0086, -0.0437,  0.1048,  0.1160,  0.1550,  0.1759,  0.1735,  0.0651,\n",
      "         0.1949,  0.1218,  0.1766,  0.1261,  0.1291,  0.0815,  0.0910,  0.1053])), ('cinn.module_list.10.subnet1.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.10.subnet1.lin_1.activation_post_process.min_val', tensor(0.)), ('cinn.module_list.10.subnet1.lin_1.activation_post_process.max_val', tensor(0.6663)), ('cinn.module_list.10.subnet1.lin_2.weight', tensor([[ 0.0444,  0.0028,  0.0495,  0.0469,  0.0628,  0.1615,  0.0889,  0.0918,\n",
      "          0.1147,  0.0886,  0.1417,  0.0746,  0.2789,  0.0579,  0.2029,  0.1217],\n",
      "        [-0.0744, -0.0223,  0.1268,  0.0160,  0.1112,  0.1877,  0.0979,  0.0479,\n",
      "          0.0917,  0.1122,  0.1888,  0.0578,  0.0795,  0.1292, -0.0274,  0.1533],\n",
      "        [ 0.0103,  0.0087, -0.1242,  0.1888,  0.1844,  0.1753, -0.1732,  0.1625,\n",
      "         -0.1650,  0.1161,  0.2194,  0.2331, -0.1483,  0.2186, -0.2329,  0.1317],\n",
      "        [ 0.1346, -0.0096,  0.2302, -0.1607, -0.1731, -0.1169, -0.1536,  0.1288,\n",
      "         -0.1884,  0.1504,  0.0427, -0.1727, -0.0301,  0.2800,  0.0969,  0.1483]])), ('cinn.module_list.10.subnet1.lin_2.bias', tensor([ 0.1576,  0.1711, -0.0893, -0.0263])), ('cinn.module_list.10.subnet1.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.10.subnet1.lin_2.activation_post_process.min_val', tensor(-0.4857)), ('cinn.module_list.10.subnet1.lin_2.activation_post_process.max_val', tensor(0.6047)), ('cinn.module_list.10.subnet2.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.10.subnet2.quant.activation_post_process.min_val', tensor(-1.0767)), ('cinn.module_list.10.subnet2.quant.activation_post_process.max_val', tensor(1.3603)), ('cinn.module_list.10.subnet2.lin_1.0.weight', tensor([[-1.4381e-01,  1.3200e-02, -1.3987e-01, -9.0854e-02, -5.8508e-02,\n",
      "          1.5675e-01],\n",
      "        [-1.7030e-01, -4.5908e-02,  2.7132e-01, -1.4301e-01,  1.5024e-01,\n",
      "         -2.6456e-01],\n",
      "        [ 1.5491e-01, -2.4294e-02, -1.2687e-01,  1.1107e-01,  1.1652e-01,\n",
      "         -1.7432e-01],\n",
      "        [ 2.1550e-02,  1.1800e-02, -1.4577e-01,  8.3024e-02, -1.5829e-01,\n",
      "          2.3674e-01],\n",
      "        [ 2.4336e-02, -1.9642e-02, -7.7176e-39, -1.7909e-02,  2.9127e-38,\n",
      "         -4.8137e-38],\n",
      "        [-1.9031e-01, -6.9779e-03, -1.3053e-01,  9.1068e-02,  1.0999e-01,\n",
      "          2.3335e-01],\n",
      "        [ 6.4440e-02, -1.9513e-01,  1.0139e-02,  1.6130e-01,  5.0223e-02,\n",
      "         -8.4781e-02],\n",
      "        [-2.3902e-02,  1.1198e-02,  1.4780e-01, -1.9008e-01, -2.1463e-01,\n",
      "          1.8535e-01],\n",
      "        [ 5.8532e-03, -2.8313e-01,  3.0262e-01,  8.6012e-02,  1.0580e-01,\n",
      "         -1.2866e-01],\n",
      "        [ 7.7805e-02,  7.5554e-02, -1.4625e-01,  1.8970e-01,  1.7718e-01,\n",
      "         -1.4091e-01],\n",
      "        [ 4.3292e-03, -1.3404e-01,  2.1291e-01, -9.2208e-02, -1.2947e-01,\n",
      "         -1.5210e-01],\n",
      "        [-1.7125e-02, -1.4517e-01,  2.6638e-01, -7.9674e-02, -1.1413e-01,\n",
      "         -1.4518e-01],\n",
      "        [-6.8392e-02, -2.1839e-02,  2.3736e-01, -6.7669e-02,  1.3861e-01,\n",
      "         -1.6711e-01],\n",
      "        [ 6.0337e-02,  5.0841e-02, -1.4531e-01,  1.8711e-01,  2.0011e-01,\n",
      "         -1.3623e-01],\n",
      "        [-8.7785e-03, -4.2699e-02,  3.4708e-01,  8.8710e-02,  7.3117e-02,\n",
      "         -1.9009e-01],\n",
      "        [-1.2363e-01, -3.1828e-03,  1.6262e-01, -1.0429e-01, -1.2327e-01,\n",
      "          1.2688e-01]])), ('cinn.module_list.10.subnet2.lin_1.0.bias', tensor([ 0.1665,  0.1671,  0.0912,  0.1333, -0.0555,  0.1688,  0.1123,  0.1877,\n",
      "         0.1853,  0.0949,  0.1838,  0.1852,  0.1286,  0.1106,  0.1433,  0.1737])), ('cinn.module_list.10.subnet2.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.10.subnet2.lin_1.activation_post_process.min_val', tensor(0.)), ('cinn.module_list.10.subnet2.lin_1.activation_post_process.max_val', tensor(0.7738)), ('cinn.module_list.10.subnet2.lin_2.weight', tensor([[ 0.0567,  0.2651,  0.0937, -0.0154,  0.0090,  0.1422,  0.0924,  0.0780,\n",
      "          0.2820,  0.0794, -0.0142,  0.0252,  0.1578,  0.0596,  0.2352,  0.1877],\n",
      "        [ 0.0380,  0.1461,  0.0604,  0.0926,  0.0014,  0.1363,  0.1000,  0.1015,\n",
      "          0.1595,  0.1323,  0.1078,  0.1089,  0.1405,  0.1102,  0.1151,  0.0361],\n",
      "        [ 0.1468, -0.2050,  0.1725,  0.1112,  0.0043,  0.2333,  0.1379, -0.1858,\n",
      "         -0.1368,  0.1587, -0.1922, -0.1882, -0.2400,  0.1905, -0.1229, -0.1496],\n",
      "        [-0.2518,  0.1389,  0.1476, -0.2025,  0.0022, -0.2358,  0.1592, -0.1659,\n",
      "          0.2025,  0.1155,  0.1450,  0.1493,  0.1875,  0.1143,  0.1060, -0.1564]])), ('cinn.module_list.10.subnet2.lin_2.bias', tensor([ 0.1879,  0.1130, -0.0470, -0.0971])), ('cinn.module_list.10.subnet2.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.10.subnet2.lin_2.activation_post_process.min_val', tensor(-0.6918)), ('cinn.module_list.10.subnet2.lin_2.activation_post_process.max_val', tensor(0.9412)), ('cinn.module_list.11.perm', tensor([0, 1, 2, 3])), ('cinn.module_list.11.perm_inv', tensor([0, 1, 2, 3])), ('cinn.module_list.12.subnet1.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.12.subnet1.quant.activation_post_process.min_val', tensor(-1.5067)), ('cinn.module_list.12.subnet1.quant.activation_post_process.max_val', tensor(1.8901)), ('cinn.module_list.12.subnet1.lin_1.0.weight', tensor([[ 5.3700e-02,  1.8561e-01,  1.4688e-01, -1.3385e-01, -1.6208e-01,\n",
      "          1.2246e-01],\n",
      "        [ 7.6248e-02,  3.4596e-02,  2.0035e-01, -1.5235e-01, -1.6211e-01,\n",
      "          1.9274e-01],\n",
      "        [-3.9024e-03,  5.1824e-03,  5.5558e-38, -4.3536e-38,  2.7636e-02,\n",
      "         -1.0446e-38],\n",
      "        [ 1.3425e-02,  2.0431e-01,  1.6263e-01, -1.0217e-01, -5.3585e-02,\n",
      "          2.1668e-01],\n",
      "        [-1.4973e-02,  2.2703e-01, -1.4301e-01,  2.5619e-01, -1.5377e-01,\n",
      "          3.3493e-02],\n",
      "        [-9.2186e-06, -1.0135e-05,  4.8467e-38,  1.8843e-38,  2.7082e-04,\n",
      "          4.8502e-38],\n",
      "        [ 9.2285e-03,  2.5457e-01,  9.7912e-02,  4.1466e-02, -2.2663e-01,\n",
      "          4.5120e-02],\n",
      "        [ 7.2818e-02,  4.4594e-02,  1.6261e-01, -2.4686e-01, -8.4661e-02,\n",
      "          1.6142e-01],\n",
      "        [-6.0867e-03, -7.6926e-02,  6.5449e-02, -1.3658e-01,  2.1874e-01,\n",
      "         -1.1863e-01],\n",
      "        [-8.2397e-02,  1.3316e-02, -1.0566e-01,  2.0000e-01, -9.8399e-02,\n",
      "          7.3223e-02],\n",
      "        [-5.0754e-02,  2.5100e-01,  3.6289e-02, -9.1111e-02,  1.0588e-02,\n",
      "          1.3627e-01],\n",
      "        [-5.0508e-03,  4.3386e-02, -1.4963e-01,  3.3312e-01,  1.9990e-01,\n",
      "         -2.8893e-01],\n",
      "        [-1.2582e-01, -2.6414e-02,  6.1910e-02, -6.6285e-02,  1.9963e-01,\n",
      "          1.3319e-01],\n",
      "        [ 9.3829e-03, -1.4585e-01,  1.1648e-01, -2.3435e-01,  2.9680e-01,\n",
      "          2.1554e-02],\n",
      "        [ 1.1148e-01,  1.8781e-02,  1.3496e-01, -9.0202e-02,  9.5270e-02,\n",
      "          1.3843e-01],\n",
      "        [ 1.0790e-02, -9.0976e-03, -2.3216e-01,  1.6674e-01,  1.4725e-01,\n",
      "         -2.1933e-01]])), ('cinn.module_list.12.subnet1.lin_1.0.bias', tensor([ 0.1991,  0.0438, -0.0503,  0.1682,  0.0972, -0.0006,  0.0336,  0.1353,\n",
      "         0.1125,  0.1762,  0.1405,  0.2128,  0.1917,  0.1886,  0.2329,  0.1985])), ('cinn.module_list.12.subnet1.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.12.subnet1.lin_1.activation_post_process.min_val', tensor(0.)), ('cinn.module_list.12.subnet1.lin_1.activation_post_process.max_val', tensor(0.7747)), ('cinn.module_list.12.subnet1.lin_2.weight', tensor([[ 1.1965e-01,  9.8625e-02, -2.9374e-04,  1.0297e-01,  1.1102e-01,\n",
      "         -2.9381e-38,  1.2042e-01,  1.1710e-01,  4.9101e-02,  9.6850e-02,\n",
      "          1.3284e-01,  2.4095e-01,  1.2801e-01,  9.9303e-02,  1.4188e-01,\n",
      "          4.7046e-02],\n",
      "        [ 5.6331e-02,  1.1185e-01, -4.1945e-03,  1.0927e-01,  8.5826e-02,\n",
      "         -2.6999e-38,  2.3715e-02,  1.0077e-01,  1.5714e-01,  8.1104e-02,\n",
      "          1.4789e-01,  1.1803e-01,  2.4013e-01,  3.1307e-01,  1.7432e-01,\n",
      "          1.9937e-01],\n",
      "        [ 8.9813e-02,  1.1656e-01, -1.1512e-02,  1.2755e-01, -2.3832e-01,\n",
      "         -3.0755e-39,  1.3283e-01,  1.6492e-01,  2.0775e-01, -1.6385e-01,\n",
      "          1.5610e-01, -2.1950e-01,  2.0122e-01,  2.4331e-01,  1.2780e-01,\n",
      "         -1.8684e-01],\n",
      "        [ 1.7820e-01,  1.4815e-01,  1.7843e-04,  1.3370e-01,  1.8235e-01,\n",
      "          5.0310e-38,  8.7183e-02,  1.2736e-01, -2.0949e-01,  1.9200e-01,\n",
      "          1.4756e-01, -1.7501e-01, -3.7827e-02, -1.4764e-01,  2.6943e-02,\n",
      "         -1.4152e-01]])), ('cinn.module_list.12.subnet1.lin_2.bias', tensor([ 0.1279,  0.1831, -0.0468, -0.0428])), ('cinn.module_list.12.subnet1.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.12.subnet1.lin_2.activation_post_process.min_val', tensor(-0.3513)), ('cinn.module_list.12.subnet1.lin_2.activation_post_process.max_val', tensor(0.7509)), ('cinn.module_list.12.subnet2.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.12.subnet2.quant.activation_post_process.min_val', tensor(-1.3709)), ('cinn.module_list.12.subnet2.quant.activation_post_process.max_val', tensor(1.4515)), ('cinn.module_list.12.subnet2.lin_1.0.weight', tensor([[ 1.1200e-02, -3.2515e-03,  3.1391e-38, -3.5420e-38,  3.5466e-03,\n",
      "          5.0851e-38],\n",
      "        [-1.5921e-01,  1.0567e-03,  1.8098e-01, -9.4842e-02, -2.2334e-01,\n",
      "          2.2832e-01],\n",
      "        [-3.2238e-02, -3.3044e-02, -2.0024e-01,  1.0215e-01, -1.8040e-01,\n",
      "          2.3909e-01],\n",
      "        [ 3.4757e-02,  9.8311e-03, -3.1737e-38, -2.9412e-02, -2.6322e-38,\n",
      "          8.8422e-39],\n",
      "        [-9.1221e-02,  8.4661e-03, -1.0014e-01, -1.2436e-01, -1.9959e-01,\n",
      "          1.6162e-01],\n",
      "        [-1.5275e-01, -1.8554e-03,  1.3813e-01, -1.4091e-01, -2.5903e-01,\n",
      "          2.2525e-01],\n",
      "        [-5.6225e-02, -4.6682e-02,  2.2585e-01, -1.1947e-01,  2.4331e-02,\n",
      "         -1.1573e-01],\n",
      "        [-4.3808e-03, -3.0918e-03, -3.5841e-38,  1.3307e-02, -6.2263e-38,\n",
      "          3.8150e-38],\n",
      "        [-6.2639e-02, -4.2397e-02,  1.6249e-01, -9.1485e-02,  1.0900e-01,\n",
      "         -2.1569e-01],\n",
      "        [ 1.0005e-02, -2.0058e-01, -9.3879e-02,  1.6642e-01, -6.4851e-02,\n",
      "          2.1948e-01],\n",
      "        [ 4.0173e-02,  1.3980e-02, -1.7447e-01, -1.7702e-01, -1.4983e-01,\n",
      "          2.0358e-01],\n",
      "        [-3.9779e-02, -4.9483e-02, -2.4313e-01,  1.1701e-01,  4.5952e-02,\n",
      "          2.6773e-01],\n",
      "        [-9.7285e-03,  1.1459e-01,  1.9668e-01,  6.6538e-02,  1.5973e-01,\n",
      "         -1.1018e-01],\n",
      "        [ 5.9613e-02, -2.6869e-01,  7.6959e-02,  1.5691e-01,  2.9389e-02,\n",
      "         -3.8293e-02],\n",
      "        [-2.3100e-02, -1.6582e-01, -3.2409e-01,  1.5930e-01, -6.7737e-02,\n",
      "          2.5392e-01],\n",
      "        [ 3.0896e-02, -6.6542e-02, -2.5835e-01,  1.1466e-01,  6.2767e-02,\n",
      "          2.4667e-01]])), ('cinn.module_list.12.subnet2.lin_1.0.bias', tensor([-0.0262,  0.1531,  0.1474, -0.0471,  0.1549,  0.1929,  0.1686, -0.0419,\n",
      "         0.1438,  0.2010,  0.1044,  0.1787,  0.1868,  0.1544,  0.1789,  0.1911])), ('cinn.module_list.12.subnet2.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.12.subnet2.lin_1.activation_post_process.min_val', tensor(0.)), ('cinn.module_list.12.subnet2.lin_1.activation_post_process.max_val', tensor(0.6597)), ('cinn.module_list.12.subnet2.lin_2.weight', tensor([[ 0.0288,  0.0954,  0.0225,  0.0417,  0.1004,  0.0827,  0.0800, -0.0366,\n",
      "          0.0881,  0.0781, -0.0056,  0.0273,  0.2231,  0.1712,  0.0773,  0.0845],\n",
      "        [-0.0087,  0.1552,  0.0753,  0.0182, -0.0342,  0.1376,  0.1046, -0.0153,\n",
      "          0.1067,  0.2591, -0.0278,  0.2669,  0.1144,  0.1469,  0.2775,  0.2641],\n",
      "        [-0.0372, -0.1855,  0.1754, -0.0143,  0.0605, -0.1862, -0.2170,  0.0735,\n",
      "         -0.1736,  0.1903,  0.1683,  0.1609,  0.0078,  0.1518,  0.1853,  0.2145],\n",
      "        [-0.0021, -0.2492, -0.2205, -0.0413, -0.2262, -0.2004,  0.1742, -0.0290,\n",
      "          0.2382, -0.1102, -0.2322, -0.1779,  0.1230,  0.1767, -0.1523, -0.1412]])), ('cinn.module_list.12.subnet2.lin_2.bias', tensor([ 0.1845,  0.1268, -0.0824, -0.0357])), ('cinn.module_list.12.subnet2.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.12.subnet2.lin_2.activation_post_process.min_val', tensor(-0.7816)), ('cinn.module_list.12.subnet2.lin_2.activation_post_process.max_val', tensor(0.9558)), ('cinn.module_list.13.perm', tensor([0, 3, 1, 2])), ('cinn.module_list.13.perm_inv', tensor([0, 2, 3, 1])), ('cinn.module_list.14.subnet1.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.14.subnet1.quant.activation_post_process.min_val', tensor(-2.3626)), ('cinn.module_list.14.subnet1.quant.activation_post_process.max_val', tensor(2.2772)), ('cinn.module_list.14.subnet1.lin_1.0.weight', tensor([[-7.6520e-02,  8.5056e-04,  1.0920e-01,  2.2110e-01,  1.3087e-01,\n",
      "         -8.7636e-02],\n",
      "        [ 9.7487e-02, -1.9055e-02, -3.4524e-01,  2.6302e-01, -2.3404e-01,\n",
      "          1.5967e-01],\n",
      "        [ 5.7928e-02, -5.5066e-03,  1.2612e-01, -9.3462e-02,  1.7672e-01,\n",
      "         -2.1745e-01],\n",
      "        [ 2.7425e-04,  5.0225e-03, -2.8215e-38, -3.6032e-38,  6.3432e-03,\n",
      "          8.8069e-03],\n",
      "        [ 4.6986e-02,  1.5020e-01,  3.1123e-02,  1.4847e-01,  7.3224e-03,\n",
      "          2.4240e-01],\n",
      "        [-7.5078e-02, -5.9758e-03,  9.0776e-02,  2.3752e-01,  9.7715e-02,\n",
      "         -1.3453e-01],\n",
      "        [-9.8531e-03,  8.1360e-02, -8.3912e-02,  1.4628e-01, -7.7733e-02,\n",
      "         -2.0777e-01],\n",
      "        [-6.1828e-02, -1.2235e-03, -4.4955e-02,  1.9252e-01,  1.0454e-01,\n",
      "         -5.8296e-02],\n",
      "        [ 1.0441e-01, -1.4044e-02, -3.0179e-01, -7.6034e-02, -2.5839e-01,\n",
      "          1.7452e-01],\n",
      "        [ 4.8146e-03,  1.3761e-01,  1.0934e-01, -7.1305e-02,  1.1284e-01,\n",
      "         -9.8155e-02],\n",
      "        [ 4.2737e-02,  3.1594e-03, -3.1490e-01,  2.1226e-01, -1.8541e-01,\n",
      "          1.8896e-01],\n",
      "        [ 1.6001e-03,  1.0294e-01,  1.4611e-01, -2.4119e-01,  1.1533e-01,\n",
      "         -5.1956e-02],\n",
      "        [-2.8081e-02, -2.5138e-01,  1.8354e-01, -2.7794e-01,  8.1919e-02,\n",
      "         -2.1645e-01],\n",
      "        [ 3.8752e-03,  1.6954e-01,  1.7756e-01, -4.2479e-02,  1.1122e-01,\n",
      "         -7.6043e-02],\n",
      "        [ 6.7753e-02, -5.7260e-03, -2.5636e-01,  3.0112e-01, -1.8796e-01,\n",
      "          2.0632e-01],\n",
      "        [ 1.2086e-02,  3.6715e-02, -1.8901e-01,  2.5848e-01, -1.9845e-01,\n",
      "          2.2478e-01]])), ('cinn.module_list.14.subnet1.lin_1.0.bias', tensor([ 0.1889,  0.1924,  0.1268, -0.0350,  0.1804,  0.2333,  0.0844,  0.1392,\n",
      "         0.2024,  0.1711,  0.2528,  0.1007,  0.0788,  0.1670,  0.1610,  0.2445])), ('cinn.module_list.14.subnet1.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.14.subnet1.lin_1.activation_post_process.min_val', tensor(0.)), ('cinn.module_list.14.subnet1.lin_1.activation_post_process.max_val', tensor(0.8589)), ('cinn.module_list.14.subnet1.lin_2.weight', tensor([[ 0.1755,  0.0384,  0.0961, -0.0092,  0.3313,  0.0899,  0.0942,  0.1018,\n",
      "          0.0481,  0.1320,  0.2464,  0.1665,  0.2028,  0.1388,  0.1204,  0.3146],\n",
      "        [ 0.1559,  0.2416,  0.1252,  0.0085, -0.0026,  0.2243,  0.0111,  0.0569,\n",
      "          0.1441,  0.1396,  0.1443,  0.0922,  0.1837,  0.1170,  0.1768,  0.2002],\n",
      "        [ 0.1843, -0.1686,  0.1419,  0.0104, -0.1810,  0.1933,  0.1609,  0.1772,\n",
      "         -0.2301,  0.1362, -0.1743,  0.1167,  0.1993,  0.1559, -0.1688, -0.2231],\n",
      "        [-0.2001, -0.1323,  0.0942, -0.0263, -0.1318, -0.1946, -0.1867, -0.1693,\n",
      "          0.1122,  0.1197, -0.1603,  0.1216,  0.2199,  0.1421, -0.1603, -0.1827]])), ('cinn.module_list.14.subnet1.lin_2.bias', tensor([ 0.1384,  0.1694, -0.0891, -0.0344])), ('cinn.module_list.14.subnet1.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.14.subnet1.lin_2.activation_post_process.min_val', tensor(-0.6305)), ('cinn.module_list.14.subnet1.lin_2.activation_post_process.max_val', tensor(1.0532)), ('cinn.module_list.14.subnet2.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.14.subnet2.quant.activation_post_process.min_val', tensor(-1.5067)), ('cinn.module_list.14.subnet2.quant.activation_post_process.max_val', tensor(1.8901)), ('cinn.module_list.14.subnet2.lin_1.0.weight', tensor([[-2.2892e-01,  2.6044e-02,  2.0455e-01, -1.5670e-01, -1.3128e-01,\n",
      "         -8.7322e-02],\n",
      "        [-1.7456e-01,  3.0260e-02, -1.2982e-01,  1.0062e-01, -1.2533e-01,\n",
      "          1.3377e-01],\n",
      "        [ 8.4132e-02,  2.8709e-01, -2.0420e-01,  1.1605e-01, -8.8190e-02,\n",
      "         -4.6475e-02],\n",
      "        [-1.2550e-01,  1.2168e-02,  1.9262e-01, -1.0858e-01, -9.7747e-02,\n",
      "          1.7242e-01],\n",
      "        [ 1.0219e-01,  5.8954e-02, -2.1240e-01,  1.5872e-01,  1.2264e-02,\n",
      "          9.3757e-02],\n",
      "        [ 1.0611e-01,  1.8875e-01,  1.6702e-02,  1.0499e-01, -5.3055e-02,\n",
      "          1.4485e-01],\n",
      "        [-7.8906e-02,  1.0297e-01, -2.0049e-01,  1.1439e-01, -1.0439e-01,\n",
      "          6.1740e-02],\n",
      "        [-1.4737e-03,  1.8533e-02,  1.8820e-01, -1.8313e-01,  2.5173e-01,\n",
      "         -2.2527e-01],\n",
      "        [-1.1293e-01,  9.1709e-02,  1.8796e-01, -1.7430e-01, -1.0469e-01,\n",
      "         -7.8496e-02],\n",
      "        [-6.1417e-03,  5.0759e-03,  2.1495e-02,  2.5384e-38,  1.5171e-02,\n",
      "          6.2646e-38],\n",
      "        [-2.6091e-01,  4.1031e-02,  3.0566e-01,  7.2481e-02, -6.0109e-02,\n",
      "          3.2389e-02],\n",
      "        [ 1.3147e-01,  2.4512e-02, -1.8836e-01,  1.5025e-01, -1.2090e-01,\n",
      "          9.9405e-02],\n",
      "        [ 1.1623e-03, -4.4939e-02, -1.3335e-01,  1.5409e-01,  2.7099e-01,\n",
      "          2.2724e-02],\n",
      "        [ 8.3872e-02, -1.2515e-01, -2.5803e-01,  9.9961e-02,  2.1808e-02,\n",
      "          1.1885e-01],\n",
      "        [-6.4070e-03,  8.4651e-02, -1.3554e-01,  1.2813e-01, -1.4519e-01,\n",
      "          6.0149e-02],\n",
      "        [-1.0114e-02, -2.1170e-02, -1.1407e-01,  1.6322e-01,  2.2539e-01,\n",
      "         -3.7344e-02]])), ('cinn.module_list.14.subnet2.lin_1.0.bias', tensor([ 0.2669, -0.0227, -0.0511,  0.1724,  0.0969,  0.1811,  0.0643,  0.2240,\n",
      "         0.1817, -0.0399,  0.1630,  0.0814,  0.1963,  0.1563,  0.0460,  0.2089])), ('cinn.module_list.14.subnet2.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.14.subnet2.lin_1.activation_post_process.min_val', tensor(0.)), ('cinn.module_list.14.subnet2.lin_1.activation_post_process.max_val', tensor(0.8246)), ('cinn.module_list.14.subnet2.lin_2.weight', tensor([[ 9.9393e-02,  1.2225e-01, -1.6856e-01,  7.0698e-02,  8.7448e-02,\n",
      "          1.4950e-01,  1.2777e-01,  1.5742e-01,  1.3640e-01, -1.0908e-04,\n",
      "          2.2240e-01,  9.3010e-02,  5.1110e-02,  7.8536e-02,  1.1707e-01,\n",
      "          1.6625e-01],\n",
      "        [ 7.9812e-02,  1.4294e-01, -3.5679e-01,  9.1015e-02,  1.6431e-01,\n",
      "          1.5644e-01,  6.7695e-02,  2.2524e-01,  7.3855e-02, -1.5979e-02,\n",
      "          1.1994e-01,  9.4934e-02,  1.3942e-01,  1.9374e-01,  8.4430e-02,\n",
      "          1.7472e-01],\n",
      "        [-2.1679e-01,  1.2197e-01,  9.3360e-02, -1.7752e-01,  1.3405e-01,\n",
      "          4.8992e-02,  1.2002e-01, -1.5166e-01, -2.1349e-01,  2.0156e-03,\n",
      "         -1.2433e-01,  1.9057e-01,  2.2460e-01,  1.5446e-01,  7.0570e-02,\n",
      "          1.8110e-01],\n",
      "        [ 2.2728e-01,  1.2361e-01, -6.1766e-02,  2.1419e-01,  6.6124e-02,\n",
      "          1.4158e-01,  1.1235e-01, -1.9817e-01,  1.9960e-01,  2.8299e-02,\n",
      "          2.3474e-01,  1.9331e-01, -1.2222e-01,  1.5202e-01,  1.0885e-01,\n",
      "         -2.0315e-01]])), ('cinn.module_list.14.subnet2.lin_2.bias', tensor([ 0.1437,  0.2096, -0.1401, -0.0961])), ('cinn.module_list.14.subnet2.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.14.subnet2.lin_2.activation_post_process.min_val', tensor(-0.6469)), ('cinn.module_list.14.subnet2.lin_2.activation_post_process.max_val', tensor(0.6774)), ('cinn.module_list.15.perm', tensor([2, 1, 0, 3])), ('cinn.module_list.15.perm_inv', tensor([2, 1, 0, 3])), ('cinn.module_list.16.subnet1.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.16.subnet1.quant.activation_post_process.min_val', tensor(-3.4994)), ('cinn.module_list.16.subnet1.quant.activation_post_process.max_val', tensor(3.1154)), ('cinn.module_list.16.subnet1.lin_1.0.weight', tensor([[-7.3431e-03,  3.3844e-02,  2.0773e-01,  7.2191e-02, -2.6550e-01,\n",
      "         -1.6397e-01],\n",
      "        [-2.5637e-14, -2.7640e-26, -4.7710e-16, -1.5957e-20, -7.1638e-39,\n",
      "         -3.8180e-40],\n",
      "        [ 1.1088e-02, -9.7724e-02,  2.1451e-01, -2.2385e-02,  1.1575e-02,\n",
      "          5.8329e-02],\n",
      "        [-1.0867e-02, -3.3281e-02,  1.6578e-01, -8.1562e-02, -9.0909e-02,\n",
      "         -9.6748e-02],\n",
      "        [-1.7416e-01, -2.7366e-02,  1.1694e-01,  1.2429e-01,  2.1075e-01,\n",
      "         -4.9216e-03],\n",
      "        [ 3.5230e-02, -1.0151e-01, -8.7839e-02,  2.8768e-01,  4.2191e-02,\n",
      "          2.5754e-02],\n",
      "        [ 6.1002e-02,  9.4007e-02, -1.9994e-02,  1.1301e-01,  1.6905e-01,\n",
      "          8.7755e-02],\n",
      "        [-2.3450e-01, -1.4558e-04, -7.2522e-02,  1.4533e-01,  7.6191e-02,\n",
      "          3.4314e-02],\n",
      "        [ 8.2039e-02,  1.1210e-01,  2.8799e-01,  2.7050e-01, -4.6496e-02,\n",
      "         -8.2235e-02],\n",
      "        [-1.0627e-02, -1.6877e-02,  2.0947e-01, -1.4430e-01, -2.1175e-02,\n",
      "         -9.2784e-02],\n",
      "        [ 1.7652e-02, -1.2395e-02,  2.0971e-01,  1.2523e-01, -1.4528e-01,\n",
      "         -2.4277e-01],\n",
      "        [-1.6385e-01, -1.8576e-02, -2.0577e-01, -2.1158e-01,  1.7743e-01,\n",
      "          1.8231e-01],\n",
      "        [ 1.8054e-01,  1.4894e-01,  2.8427e-02,  3.0544e-02,  8.2265e-02,\n",
      "          1.0924e-01],\n",
      "        [-1.4449e-01, -2.0678e-02,  1.5102e-01, -2.7492e-01,  2.0139e-01,\n",
      "          2.3184e-02],\n",
      "        [ 3.0605e-01,  4.7574e-02,  2.1310e-01,  2.8649e-02,  8.5440e-02,\n",
      "          3.1452e-03],\n",
      "        [-1.4897e-01,  4.5279e-02,  4.5913e-02,  8.0140e-02,  1.3519e-01,\n",
      "          3.7640e-02]])), ('cinn.module_list.16.subnet1.lin_1.0.bias', tensor([ 1.7829e-01, -4.9596e-12,  2.1654e-01,  1.7174e-01,  2.1714e-01,\n",
      "         2.5635e-01,  2.2796e-01,  1.6915e-01,  2.0613e-01,  1.8851e-01,\n",
      "         1.9506e-01,  6.6227e-02,  2.2926e-01,  1.3370e-01,  1.5785e-01,\n",
      "         2.5650e-01])), ('cinn.module_list.16.subnet1.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.16.subnet1.lin_1.activation_post_process.min_val', tensor(0.)), ('cinn.module_list.16.subnet1.lin_1.activation_post_process.max_val', tensor(1.2662)), ('cinn.module_list.16.subnet1.lin_2.weight', tensor([[ 1.0481e-01,  4.2743e-38,  1.5560e-01,  1.7056e-02,  1.3694e-01,\n",
      "          1.2781e-01,  1.6049e-01,  1.0831e-01,  3.4764e-01,  6.6730e-02,\n",
      "          1.8543e-01,  1.2553e-01,  2.0080e-01,  1.3742e-01,  2.6882e-01,\n",
      "          1.0676e-01],\n",
      "        [ 8.7061e-02, -6.2457e-38,  2.2529e-01,  1.7460e-01,  2.6136e-01,\n",
      "          2.5556e-01,  9.3873e-02,  2.4201e-01,  2.4038e-01,  1.0149e-01,\n",
      "          1.0940e-01,  1.5811e-01,  2.1660e-02,  1.3624e-01,  1.5160e-01,\n",
      "          1.9779e-01],\n",
      "        [-1.5533e-01, -1.3978e-38, -1.7277e-01, -1.8308e-01,  1.6277e-01,\n",
      "          1.1332e-01,  7.7671e-02,  1.7580e-01, -1.4186e-01, -1.6321e-01,\n",
      "         -1.5863e-01,  1.4220e-01,  4.6535e-02,  1.3213e-01, -7.0141e-02,\n",
      "          1.2661e-01],\n",
      "        [-1.1789e-01,  2.3601e-38,  1.5857e-01,  1.6107e-01,  9.6322e-02,\n",
      "         -1.3786e-01, -2.9582e-03,  5.6276e-02, -1.4818e-01,  1.7742e-01,\n",
      "         -1.7231e-01,  1.8145e-01,  5.9300e-02,  1.6129e-01,  1.9040e-01,\n",
      "          7.4647e-02]])), ('cinn.module_list.16.subnet1.lin_2.bias', tensor([ 0.1877,  0.2017, -0.0792, -0.1783])), ('cinn.module_list.16.subnet1.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.16.subnet1.lin_2.activation_post_process.min_val', tensor(-0.4884)), ('cinn.module_list.16.subnet1.lin_2.activation_post_process.max_val', tensor(1.3249)), ('cinn.module_list.16.subnet2.quant.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.16.subnet2.quant.activation_post_process.min_val', tensor(-2.3353)), ('cinn.module_list.16.subnet2.quant.activation_post_process.max_val', tensor(1.8866)), ('cinn.module_list.16.subnet2.lin_1.0.weight', tensor([[ 0.1882, -0.0019,  0.1398,  0.1046, -0.1066, -0.0915],\n",
      "        [ 0.0245,  0.0742,  0.1380,  0.1240,  0.2036, -0.0574],\n",
      "        [-0.0676,  0.0057,  0.0047,  0.1639, -0.1171,  0.1974],\n",
      "        [ 0.1620, -0.2029,  0.1627, -0.0050,  0.0762,  0.0782],\n",
      "        [-0.1157,  0.0937, -0.0626,  0.1158, -0.1074,  0.2567],\n",
      "        [ 0.0215,  0.1532, -0.1771, -0.2209,  0.2103,  0.2259],\n",
      "        [-0.0755, -0.0028,  0.0862, -0.0725,  0.1946, -0.0937],\n",
      "        [-0.0383,  0.0120, -0.0779, -0.1817,  0.2234, -0.0898],\n",
      "        [ 0.0298,  0.3433, -0.3262,  0.3342, -0.3212, -0.1422],\n",
      "        [-0.0945,  0.0254,  0.0467, -0.1505,  0.1940, -0.0105],\n",
      "        [ 0.1862,  0.0303,  0.1229,  0.1195, -0.0494, -0.0242],\n",
      "        [ 0.0326, -0.1454,  0.1906,  0.0238,  0.0567, -0.2495],\n",
      "        [ 0.1029,  0.0190,  0.1741,  0.0913,  0.0704, -0.0723],\n",
      "        [-0.0893, -0.0841,  0.0824,  0.0248,  0.0915,  0.0373],\n",
      "        [-0.0633,  0.0012,  0.0840, -0.0606,  0.1825, -0.0830],\n",
      "        [ 0.0287,  0.1996, -0.0727, -0.1125,  0.1708,  0.1401]])), ('cinn.module_list.16.subnet2.lin_1.0.bias', tensor([ 0.2174,  0.2079,  0.2203,  0.2020,  0.2175,  0.2507,  0.2002,  0.1526,\n",
      "        -0.0312,  0.1494,  0.1590,  0.0725,  0.1540,  0.1955,  0.1720,  0.1601])), ('cinn.module_list.16.subnet2.lin_1.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.16.subnet2.lin_1.activation_post_process.min_val', tensor(0.)), ('cinn.module_list.16.subnet2.lin_1.activation_post_process.max_val', tensor(0.9372)), ('cinn.module_list.16.subnet2.lin_2.weight', tensor([[ 0.0676,  0.1381,  0.2477,  0.1985,  0.2987,  0.1819,  0.1164,  0.0593,\n",
      "         -0.4878,  0.1606,  0.1130,  0.1125,  0.0242,  0.1542,  0.1124,  0.1176],\n",
      "        [ 0.1615,  0.2287,  0.0998,  0.1939,  0.1360,  0.1179,  0.0807,  0.1127,\n",
      "         -0.1498,  0.0630,  0.1583,  0.1598,  0.1914,  0.1479,  0.1355,  0.1526],\n",
      "        [ 0.1268,  0.1549, -0.1262,  0.0831, -0.1714, -0.2095,  0.2021,  0.1538,\n",
      "         -0.0296,  0.1655,  0.0346,  0.1675,  0.1005,  0.1312,  0.2045, -0.1412],\n",
      "        [ 0.1159, -0.0751,  0.1582,  0.0819,  0.1437, -0.1571, -0.1647, -0.2114,\n",
      "         -0.0502, -0.1588,  0.0872,  0.1157,  0.0404,  0.1105, -0.1748, -0.1654]])), ('cinn.module_list.16.subnet2.lin_2.bias', tensor([ 0.1931,  0.1800, -0.1385, -0.0489])), ('cinn.module_list.16.subnet2.lin_2.activation_post_process.eps', tensor([1.1921e-07])), ('cinn.module_list.16.subnet2.lin_2.activation_post_process.min_val', tensor(-0.5190)), ('cinn.module_list.16.subnet2.lin_2.activation_post_process.max_val', tensor(0.8640))])\n"
     ]
    }
   ],
   "source": [
    "print(\"Calibrated state dict with Observer\")\n",
    "print(model_floating.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted state dict\n",
      "OrderedDict([('cinn.module_list.1.perm', tensor([2, 3, 1, 0])), ('cinn.module_list.1.perm_inv', tensor([3, 2, 0, 1])), ('cinn.module_list.2.subnet1.quant.scale', tensor([0.0235])), ('cinn.module_list.2.subnet1.quant.zero_point', tensor([45])), ('cinn.module_list.2.subnet1.lin_1.scale', tensor(0.0050)), ('cinn.module_list.2.subnet1.lin_1.zero_point', tensor(0)), ('cinn.module_list.2.subnet1.lin_1._packed_params.dtype', torch.qint8), ('cinn.module_list.2.subnet1.lin_1._packed_params._packed_params', (tensor([[-0.0627,  0.0238,  0.0151, -0.0994,  0.0000,  0.0886],\n",
      "        [ 0.1232, -0.0735, -0.1297, -0.1146,  0.1578,  0.0000],\n",
      "        [ 0.0086,  0.0043,  0.0000,  0.0000,  0.0000,  0.0108],\n",
      "        [ 0.1124,  0.1038, -0.0692, -0.0908,  0.1189,  0.1686],\n",
      "        [ 0.1038,  0.0800, -0.0908, -0.1059,  0.1405,  0.1989],\n",
      "        [-0.0757,  0.1275, -0.0713, -0.0778,  0.0000,  0.1708],\n",
      "        [ 0.0843, -0.1470,  0.2183, -0.2313,  0.1275,  0.0324],\n",
      "        [ 0.0519, -0.2205, -0.0648, -0.1016,  0.0324,  0.0000],\n",
      "        [-0.0886, -0.1167, -0.1513,  0.2313, -0.0951, -0.0713],\n",
      "        [-0.0454,  0.0108,  0.1686,  0.1945, -0.1340, -0.2356],\n",
      "        [ 0.0022,  0.0022, -0.0022,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0497, -0.1275,  0.2745, -0.1600,  0.0562,  0.0497],\n",
      "        [-0.1340, -0.1232,  0.2399, -0.1924, -0.1016, -0.1578],\n",
      "        [-0.1427, -0.1492,  0.1945, -0.1729,  0.0605,  0.0778],\n",
      "        [-0.0238, -0.0497, -0.1578,  0.2097, -0.0022, -0.1167],\n",
      "        [-0.1989, -0.0346, -0.1773,  0.2162,  0.0000,  0.0994]], size=(16, 6),\n",
      "       dtype=torch.qint8, quantization_scheme=torch.per_tensor_affine,\n",
      "       scale=0.0021616348531097174, zero_point=0), Parameter containing:\n",
      "tensor([ 0.0044,  0.0433, -0.0320,  0.1170,  0.1164,  0.0322,  0.1263,  0.0925,\n",
      "         0.0981,  0.1856, -0.0047,  0.1293,  0.1568,  0.1274,  0.1370,  0.1260],\n",
      "       requires_grad=True))), ('cinn.module_list.2.subnet1.lin_2.scale', tensor(0.0060)), ('cinn.module_list.2.subnet1.lin_2.zero_point', tensor(64)), ('cinn.module_list.2.subnet1.lin_2._packed_params.dtype', torch.qint8), ('cinn.module_list.2.subnet1.lin_2._packed_params._packed_params', (tensor([[ 0.1714,  0.1036, -0.0040,  0.0837,  0.0618,  0.0379,  0.0498,  0.0956,\n",
      "         -0.0598, -0.0020,  0.0000,  0.0837,  0.1096,  0.1554, -0.0956, -0.0359],\n",
      "        [ 0.0458,  0.0697,  0.0199,  0.0578,  0.1036,  0.0757,  0.0299,  0.0578,\n",
      "          0.1235, -0.1116,  0.0000, -0.0398, -0.0139, -0.1096,  0.0498,  0.1215],\n",
      "        [ 0.0677,  0.1454,  0.0040,  0.1454,  0.1215,  0.1335,  0.2092,  0.1474,\n",
      "         -0.2291, -0.1634,  0.0000,  0.1853,  0.1116,  0.2092, -0.2052, -0.1215],\n",
      "        [ 0.0100,  0.1992, -0.0120,  0.1435,  0.1415,  0.1494, -0.1195,  0.0618,\n",
      "          0.1674, -0.1355,  0.0000, -0.1873, -0.2550, -0.1893,  0.1514,  0.1853]],\n",
      "       size=(4, 16), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.0019924461375921965,\n",
      "       zero_point=0), Parameter containing:\n",
      "tensor([0.0466, 0.0555, 0.0238, 0.0282], requires_grad=True))), ('cinn.module_list.2.subnet2.quant.scale', tensor([0.0254])), ('cinn.module_list.2.subnet2.quant.zero_point', tensor([44])), ('cinn.module_list.2.subnet2.lin_1.scale', tensor(0.0050)), ('cinn.module_list.2.subnet2.lin_1.zero_point', tensor(0)), ('cinn.module_list.2.subnet2.lin_1._packed_params.dtype', torch.qint8), ('cinn.module_list.2.subnet2.lin_1._packed_params._packed_params', (tensor([[-0.1739, -0.1082, -0.1063,  0.0000, -0.1971,  0.1971],\n",
      "        [-0.1333, -0.0773, -0.1352, -0.0174, -0.1951,  0.2454],\n",
      "        [-0.1063, -0.1121, -0.0116, -0.0270,  0.1951, -0.1488],\n",
      "        [ 0.0193,  0.0019,  0.0000, -0.0328,  0.0000,  0.0000],\n",
      "        [-0.1932, -0.1546, -0.0367,  0.0000, -0.1932,  0.2048],\n",
      "        [-0.0676, -0.0522, -0.1082, -0.0734,  0.1488,  0.1468],\n",
      "        [-0.1352, -0.1777,  0.0000, -0.0599,  0.2125, -0.2241],\n",
      "        [-0.0889, -0.1217,  0.0000, -0.0715,  0.2048, -0.1604],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0753,  0.0908,  0.1604,  0.0927, -0.0850,  0.0232],\n",
      "        [-0.0580, -0.0348, -0.1932, -0.1391, -0.0270,  0.2260],\n",
      "        [ 0.1372, -0.0734,  0.0000,  0.0831, -0.1236, -0.1236],\n",
      "        [-0.1314, -0.1101, -0.0638, -0.0251, -0.1797,  0.2299],\n",
      "        [ 0.1043, -0.0309, -0.0213,  0.0947, -0.0657, -0.0580],\n",
      "        [ 0.0522, -0.2067,  0.0000,  0.1121, -0.0947, -0.1005],\n",
      "        [ 0.0097, -0.0077, -0.0116, -0.0039,  0.0000,  0.0000]], size=(16, 6),\n",
      "       dtype=torch.qint8, quantization_scheme=torch.per_tensor_affine,\n",
      "       scale=0.0019319291459396482, zero_point=0), Parameter containing:\n",
      "tensor([ 1.0832e-01,  1.2581e-01,  7.9915e-02, -3.1265e-02,  8.2558e-02,\n",
      "         1.1347e-01,  1.2553e-01,  9.4819e-02, -5.8261e-13,  1.3163e-01,\n",
      "         1.8253e-01,  6.9647e-02,  1.0059e-01,  2.1179e-02,  7.6320e-02,\n",
      "        -2.6854e-02], requires_grad=True))), ('cinn.module_list.2.subnet2.lin_2.scale', tensor(0.0071)), ('cinn.module_list.2.subnet2.lin_2.zero_point', tensor(79)), ('cinn.module_list.2.subnet2.lin_2._packed_params.dtype', torch.qint8), ('cinn.module_list.2.subnet2.lin_2._packed_params._packed_params', (tensor([[ 0.1932,  0.1205, -0.0746, -0.0038,  0.1683, -0.0325, -0.0115,  0.0019,\n",
      "          0.0000,  0.1071, -0.0383,  0.0746,  0.1301,  0.0937,  0.0995,  0.0057],\n",
      "        [-0.0421, -0.0555,  0.1473,  0.0325, -0.0153, -0.0344,  0.1473,  0.1339,\n",
      "          0.0000,  0.0402, -0.0555,  0.0861, -0.0746,  0.0038,  0.1339, -0.0038],\n",
      "        [ 0.1664,  0.1588, -0.2429, -0.0057,  0.2429, -0.1741, -0.2162, -0.2315,\n",
      "          0.0000,  0.1473, -0.0536,  0.1435,  0.1645,  0.1148,  0.1090,  0.0000],\n",
      "        [-0.2334, -0.2410,  0.2104, -0.0287, -0.2257, -0.1358,  0.2047,  0.1645,\n",
      "          0.0000,  0.0574, -0.2009,  0.0976, -0.2295,  0.0574,  0.0842,  0.0019]],\n",
      "       size=(4, 16), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.001912884064950049,\n",
      "       zero_point=0), Parameter containing:\n",
      "tensor([0.0316, 0.0321, 0.0390, 0.0349], requires_grad=True))), ('cinn.module_list.3.perm', tensor([3, 2, 0, 1])), ('cinn.module_list.3.perm_inv', tensor([2, 3, 1, 0])), ('cinn.module_list.4.subnet1.quant.scale', tensor([0.0244])), ('cinn.module_list.4.subnet1.quant.zero_point', tensor([46])), ('cinn.module_list.4.subnet1.lin_1.scale', tensor(0.0047)), ('cinn.module_list.4.subnet1.lin_1.zero_point', tensor(0)), ('cinn.module_list.4.subnet1.lin_1._packed_params.dtype', torch.qint8), ('cinn.module_list.4.subnet1.lin_1._packed_params._packed_params', (tensor([[-0.0736, -0.1074, -0.0338, -0.0457,  0.2147, -0.1034],\n",
      "        [-0.1074,  0.0179, -0.0080,  0.1292, -0.1869,  0.1968],\n",
      "        [ 0.0815, -0.1869,  0.1431,  0.0000, -0.1809, -0.0577],\n",
      "        [-0.0219, -0.0179,  0.0000,  0.0219,  0.0000,  0.0060],\n",
      "        [ 0.0000, -0.0497, -0.2286, -0.1849,  0.1630,  0.1451],\n",
      "        [ 0.0596, -0.2127,  0.1789,  0.0000, -0.0835, -0.1610],\n",
      "        [-0.0676, -0.0636, -0.1431, -0.1551,  0.2028, -0.1471],\n",
      "        [ 0.0139, -0.0775, -0.1749, -0.0696,  0.2087,  0.2068],\n",
      "        [ 0.1252, -0.0656,  0.1590, -0.0278, -0.1571, -0.1730],\n",
      "        [-0.1292,  0.1252,  0.0000,  0.1213,  0.0835, -0.1511],\n",
      "        [-0.0636, -0.0517, -0.0755, -0.1173,  0.2386, -0.1233],\n",
      "        [ 0.0258, -0.0040, -0.2306, -0.1829,  0.1948, -0.1074],\n",
      "        [-0.2545,  0.0616,  0.0000,  0.1153,  0.0298, -0.1412],\n",
      "        [-0.0537,  0.1610,  0.0636,  0.1551, -0.1730, -0.1471],\n",
      "        [-0.0378,  0.1332,  0.0000,  0.0994, -0.1034, -0.0656],\n",
      "        [-0.1292, -0.0676, -0.0537,  0.1630, -0.2187,  0.1789]], size=(16, 6),\n",
      "       dtype=torch.qint8, quantization_scheme=torch.per_tensor_affine,\n",
      "       scale=0.001988051226362586, zero_point=0), Parameter containing:\n",
      "tensor([ 0.1058,  0.1139,  0.0787, -0.0447,  0.2013,  0.1766,  0.1565,  0.1693,\n",
      "         0.0804,  0.0739,  0.1302,  0.1833,  0.0570,  0.0848, -0.0007,  0.1442],\n",
      "       requires_grad=True))), ('cinn.module_list.4.subnet1.lin_2.scale', tensor(0.0060)), ('cinn.module_list.4.subnet1.lin_2.zero_point', tensor(72)), ('cinn.module_list.4.subnet1.lin_2._packed_params.dtype', torch.qint8), ('cinn.module_list.4.subnet1.lin_2._packed_params._packed_params', (tensor([[-0.0176,  0.1321,  0.0669, -0.0335,  0.0035,  0.0828, -0.0493, -0.0070,\n",
      "          0.0740,  0.0652, -0.0740, -0.0282,  0.0881,  0.0616,  0.0863,  0.0652],\n",
      "        [ 0.1198,  0.0916,  0.1444, -0.0335,  0.0264,  0.1022,  0.1779, -0.0159,\n",
      "          0.0969,  0.0528,  0.0757, -0.0194,  0.0757,  0.0934, -0.0141,  0.0000],\n",
      "        [-0.1955,  0.1515,  0.1673, -0.0405, -0.1761,  0.1444, -0.2237, -0.1867,\n",
      "          0.1849,  0.0387, -0.2219, -0.2255,  0.0757,  0.1497,  0.1162,  0.2237],\n",
      "        [ 0.1656, -0.0934,  0.1198, -0.0018, -0.1726,  0.1550,  0.1374, -0.1744,\n",
      "          0.1867,  0.2166,  0.1585,  0.0053,  0.1568,  0.1656,  0.0740, -0.2114]],\n",
      "       size=(4, 16), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.0017613284289836884,\n",
      "       zero_point=0), Parameter containing:\n",
      "tensor([0.0465, 0.1263, 0.0181, 0.0521], requires_grad=True))), ('cinn.module_list.4.subnet2.quant.scale', tensor([0.0235])), ('cinn.module_list.4.subnet2.quant.zero_point', tensor([45])), ('cinn.module_list.4.subnet2.lin_1.scale', tensor(0.0050)), ('cinn.module_list.4.subnet2.lin_1.zero_point', tensor(0)), ('cinn.module_list.4.subnet2.lin_1._packed_params.dtype', torch.qint8), ('cinn.module_list.4.subnet2.lin_1._packed_params._packed_params', (tensor([[ 0.1453, -0.0799, -0.1114, -0.1090,  0.0945,  0.0000],\n",
      "        [ 0.0727, -0.1356, -0.1138,  0.1259,  0.1574, -0.0363],\n",
      "        [-0.1017,  0.1114, -0.1138, -0.1162,  0.0000,  0.1623],\n",
      "        [ 0.0387,  0.0630, -0.1284,  0.2107,  0.1090,  0.1405],\n",
      "        [-0.0194, -0.1962,  0.2155, -0.1889,  0.1066,  0.0339],\n",
      "        [ 0.0460, -0.2131, -0.1332, -0.1187,  0.1284,  0.0000],\n",
      "        [-0.0484, -0.0654,  0.2204, -0.1066, -0.1695, -0.1550],\n",
      "        [ 0.1695,  0.1623, -0.0775, -0.0920,  0.1477,  0.1017],\n",
      "        [-0.1308,  0.1405, -0.1792, -0.1720,  0.0000,  0.1138],\n",
      "        [-0.0799, -0.1937,  0.2204, -0.2034,  0.0121,  0.0097],\n",
      "        [ 0.1066, -0.0533, -0.0993, -0.0993,  0.1744,  0.0000],\n",
      "        [-0.0363, -0.0702, -0.1308,  0.3076, -0.0242, -0.0678],\n",
      "        [ 0.1235,  0.1259, -0.0266, -0.0460,  0.1211,  0.1284],\n",
      "        [ 0.1477, -0.1090, -0.1332, -0.1526,  0.1574,  0.0000],\n",
      "        [ 0.0073,  0.0097, -0.1066,  0.2349, -0.0218, -0.0170],\n",
      "        [-0.2131, -0.2325, -0.1211,  0.1211,  0.0000,  0.0000]], size=(16, 6),\n",
      "       dtype=torch.qint8, quantization_scheme=torch.per_tensor_affine,\n",
      "       scale=0.0024218487087637186, zero_point=0), Parameter containing:\n",
      "tensor([0.0319, 0.1339, 0.0577, 0.1505, 0.1533, 0.1127, 0.1691, 0.1313, 0.0997,\n",
      "        0.1595, 0.0307, 0.0997, 0.0789, 0.0555, 0.0969, 0.0152],\n",
      "       requires_grad=True))), ('cinn.module_list.4.subnet2.lin_2.scale', tensor(0.0057)), ('cinn.module_list.4.subnet2.lin_2.zero_point', tensor(45)), ('cinn.module_list.4.subnet2.lin_2._packed_params.dtype', torch.qint8), ('cinn.module_list.4.subnet2.lin_2._packed_params._packed_params', (tensor([[ 0.0537,  0.0193,  0.0322,  0.0817,  0.0795,  0.0709, -0.0301,  0.0387,\n",
      "          0.0946,  0.0129,  0.0752,  0.0516,  0.0516,  0.0365,  0.0559,  0.1505],\n",
      "        [ 0.0688,  0.0258,  0.0774,  0.0946,  0.0645,  0.0881,  0.0559,  0.0752,\n",
      "          0.0795,  0.1010,  0.0881, -0.0645,  0.0580,  0.0365, -0.0795,  0.2730],\n",
      "        [ 0.1139,  0.2128,  0.1462,  0.1676, -0.1268,  0.1505, -0.2515,  0.1526,\n",
      "          0.1118, -0.2106,  0.1311,  0.1376,  0.1462,  0.1032,  0.1118,  0.1397],\n",
      "        [ 0.1333, -0.0301,  0.1096, -0.0537,  0.1590,  0.1333,  0.0086,  0.0924,\n",
      "          0.1139,  0.1762,  0.1268, -0.2149,  0.1118,  0.1397, -0.1676, -0.0881]],\n",
      "       size=(4, 16), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.00214930297806859,\n",
      "       zero_point=0), Parameter containing:\n",
      "tensor([ 0.0834,  0.1103, -0.0041, -0.0316], requires_grad=True))), ('cinn.module_list.5.perm', tensor([2, 3, 1, 0])), ('cinn.module_list.5.perm_inv', tensor([3, 2, 0, 1])), ('cinn.module_list.6.subnet1.quant.scale', tensor([0.0201])), ('cinn.module_list.6.subnet1.quant.zero_point', tensor([51])), ('cinn.module_list.6.subnet1.lin_1.scale', tensor(0.0047)), ('cinn.module_list.6.subnet1.lin_1.zero_point', tensor(0)), ('cinn.module_list.6.subnet1.lin_1._packed_params.dtype', torch.qint8), ('cinn.module_list.6.subnet1.lin_1._packed_params._packed_params', (tensor([[-0.0330,  0.0466,  0.0524, -0.1708,  0.1747,  0.1708],\n",
      "        [ 0.0835,  0.1087, -0.0097, -0.1572,  0.1417,  0.1708],\n",
      "        [-0.0039,  0.0252,  0.1863,  0.1106, -0.1747, -0.1999],\n",
      "        [-0.2485,  0.0757,  0.1009, -0.1630, -0.0466,  0.1572],\n",
      "        [-0.1165,  0.1728, -0.1766, -0.1611, -0.0505,  0.1844],\n",
      "        [ 0.0194,  0.0932, -0.0369, -0.1223,  0.1572,  0.1786],\n",
      "        [-0.1048, -0.0388,  0.2271, -0.1242, -0.1650, -0.0563],\n",
      "        [-0.0194, -0.0039,  0.2193,  0.0582, -0.1902, -0.1902],\n",
      "        [-0.0932, -0.0524,  0.2329, -0.0116, -0.1495, -0.1825],\n",
      "        [ 0.0679,  0.0835, -0.1417, -0.1572,  0.1475,  0.1650],\n",
      "        [-0.0660, -0.0427, -0.1184,  0.1922,  0.0427,  0.0796],\n",
      "        [ 0.0155,  0.0932, -0.0990, -0.1068,  0.0641,  0.0233],\n",
      "        [-0.0116, -0.0039, -0.1689,  0.2096,  0.0369, -0.0505],\n",
      "        [-0.0330, -0.0214, -0.1009,  0.2232,  0.0427,  0.0873],\n",
      "        [-0.0136, -0.0058,  0.2349,  0.2135, -0.1689, -0.1495],\n",
      "        [ 0.0155,  0.0543,  0.0582, -0.1728,  0.1398,  0.1339]], size=(16, 6),\n",
      "       dtype=torch.qint8, quantization_scheme=torch.per_tensor_affine,\n",
      "       scale=0.001941054710187018, zero_point=0), Parameter containing:\n",
      "tensor([ 0.1411,  0.0839,  0.1499,  0.0928,  0.0450,  0.0796,  0.1767,  0.1681,\n",
      "         0.1285,  0.0979,  0.1479, -0.0242,  0.1515,  0.1170,  0.1686,  0.1225],\n",
      "       requires_grad=True))), ('cinn.module_list.6.subnet1.lin_2.scale', tensor(0.0068)), ('cinn.module_list.6.subnet1.lin_2.zero_point', tensor(61)), ('cinn.module_list.6.subnet1.lin_2._packed_params.dtype', torch.qint8), ('cinn.module_list.6.subnet1.lin_2._packed_params._packed_params', (tensor([[ 0.0735,  0.1065, -0.0386,  0.0220,  0.0551,  0.1157,  0.0918,  0.0790,\n",
      "          0.0588,  0.0569, -0.0276,  0.0422, -0.0588, -0.0661,  0.0624,  0.1653],\n",
      "        [ 0.0992,  0.0661,  0.0514,  0.1102,  0.0900,  0.0973, -0.0331, -0.0037,\n",
      "          0.0037,  0.1102,  0.1029,  0.1010,  0.0661,  0.0863, -0.0184,  0.0551],\n",
      "        [ 0.2296,  0.1580, -0.1635,  0.2296,  0.1506,  0.1671,  0.1671, -0.1029,\n",
      "         -0.0129,  0.1396, -0.1727,  0.0349, -0.1855, -0.2076, -0.1653,  0.1910],\n",
      "        [ 0.0367,  0.0441, -0.1892,  0.0110,  0.0992,  0.0918, -0.2241, -0.2259,\n",
      "         -0.1818,  0.1139,  0.2149,  0.0496,  0.1984,  0.2333, -0.1616,  0.0276]],\n",
      "       size=(4, 16), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.0018367371521890163,\n",
      "       zero_point=0), Parameter containing:\n",
      "tensor([ 0.0753,  0.1228, -0.0412, -0.0383], requires_grad=True))), ('cinn.module_list.6.subnet2.quant.scale', tensor([0.0244])), ('cinn.module_list.6.subnet2.quant.zero_point', tensor([46])), ('cinn.module_list.6.subnet2.lin_1.scale', tensor(0.0045)), ('cinn.module_list.6.subnet2.lin_1.zero_point', tensor(0)), ('cinn.module_list.6.subnet2.lin_1._packed_params.dtype', torch.qint8), ('cinn.module_list.6.subnet2.lin_1._packed_params._packed_params', (tensor([[-0.0119, -0.0119,  0.0932, -0.0515,  0.2359, -0.1685],\n",
      "        [ 0.1566,  0.1130,  0.1863,  0.1051, -0.1467, -0.0991],\n",
      "        [ 0.1189, -0.0317,  0.0654,  0.1209, -0.1368, -0.1051],\n",
      "        [-0.0932,  0.0357,  0.1982, -0.0634,  0.2418, -0.1526],\n",
      "        [-0.0753,  0.0079, -0.1487, -0.0575,  0.1764,  0.1189],\n",
      "        [-0.2101, -0.0654,  0.0436,  0.0000, -0.2022,  0.1883],\n",
      "        [-0.0674, -0.0575, -0.1308, -0.1051,  0.2517, -0.1150],\n",
      "        [ 0.1526,  0.1249,  0.1269,  0.1150, -0.1566, -0.0951],\n",
      "        [ 0.0079,  0.0000,  0.0000, -0.0159,  0.0000,  0.0000],\n",
      "        [-0.1824,  0.0456,  0.1388,  0.0000, -0.0872,  0.0793],\n",
      "        [ 0.1130,  0.1249,  0.1566,  0.1487, -0.1606, -0.1130],\n",
      "        [-0.0238, -0.0139, -0.1606, -0.1467,  0.2240, -0.1388],\n",
      "        [ 0.1209,  0.1269,  0.1586,  0.1526, -0.1288, -0.0912],\n",
      "        [ 0.0020, -0.0416, -0.0912, -0.1685,  0.1962, -0.1843],\n",
      "        [-0.0555, -0.0020, -0.2002, -0.0614,  0.1407,  0.1467],\n",
      "        [ 0.0337,  0.0059, -0.1665, -0.1368,  0.1725, -0.1784]], size=(16, 6),\n",
      "       dtype=torch.qint8, quantization_scheme=torch.per_tensor_affine,\n",
      "       scale=0.001982186222448945, zero_point=0), Parameter containing:\n",
      "tensor([ 0.1710,  0.0677,  0.0367,  0.1618,  0.1504,  0.1294,  0.1217,  0.0743,\n",
      "        -0.0142,  0.1734,  0.0921,  0.1429,  0.0579,  0.1277,  0.1643,  0.1539],\n",
      "       requires_grad=True))), ('cinn.module_list.6.subnet2.lin_2.scale', tensor(0.0072)), ('cinn.module_list.6.subnet2.lin_2.zero_point', tensor(74)), ('cinn.module_list.6.subnet2.lin_2._packed_params.dtype', torch.qint8), ('cinn.module_list.6.subnet2.lin_2._packed_params._packed_params', (tensor([[ 0.0231,  0.1051,  0.0967,  0.0084,  0.0505,  0.0547, -0.0021,  0.0967,\n",
      "          0.0000,  0.1535,  0.1408, -0.0021,  0.0673,  0.0042,  0.0000, -0.0147],\n",
      "        [ 0.0799,  0.0673,  0.1177,  0.0568, -0.0357,  0.0736,  0.1366,  0.0336,\n",
      "          0.0000,  0.1471,  0.0652,  0.0841,  0.0778, -0.0042,  0.0210, -0.0147],\n",
      "        [-0.1892,  0.1514,  0.1135, -0.1577, -0.1703,  0.2060, -0.2249,  0.1240,\n",
      "          0.0000,  0.1471,  0.1598, -0.2691,  0.1051, -0.2081, -0.1577, -0.1934],\n",
      "        [ 0.1997,  0.1640,  0.0841,  0.1976, -0.1577, -0.1913,  0.1577,  0.1345,\n",
      "          0.0000,  0.0252,  0.1514,  0.1598,  0.1282,  0.0799, -0.1703,  0.0946]],\n",
      "       size=(4, 16), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.002102094702422619,\n",
      "       zero_point=0), Parameter containing:\n",
      "tensor([0.1358, 0.0730, 0.0300, 0.0026], requires_grad=True))), ('cinn.module_list.7.perm', tensor([3, 1, 0, 2])), ('cinn.module_list.7.perm_inv', tensor([2, 1, 3, 0])), ('cinn.module_list.8.subnet1.quant.scale', tensor([0.0186])), ('cinn.module_list.8.subnet1.quant.zero_point', tensor([51])), ('cinn.module_list.8.subnet1.lin_1.scale', tensor(0.0043)), ('cinn.module_list.8.subnet1.lin_1.zero_point', tensor(0)), ('cinn.module_list.8.subnet1.lin_1._packed_params.dtype', torch.qint8), ('cinn.module_list.8.subnet1.lin_1._packed_params._packed_params', (tensor([[-0.0029, -0.0436, -0.0640,  0.2124, -0.1513, -0.1687],\n",
      "        [-0.0087,  0.0000, -0.1920,  0.1367,  0.2269, -0.2066],\n",
      "        [-0.1426,  0.0233, -0.0553, -0.1833,  0.0495,  0.1775],\n",
      "        [-0.0029, -0.0669, -0.0611,  0.2531, -0.1338, -0.1193],\n",
      "        [-0.0465,  0.0524,  0.0815,  0.1978, -0.1833,  0.0698],\n",
      "        [ 0.0495,  0.0000, -0.0931,  0.0785,  0.1833, -0.0233],\n",
      "        [ 0.1571, -0.1076,  0.1716, -0.1164, -0.1687,  0.0000],\n",
      "        [-0.0087,  0.0931, -0.1047,  0.2182, -0.1251, -0.2356],\n",
      "        [-0.0087,  0.0756, -0.1600,  0.2240,  0.1920, -0.2735],\n",
      "        [ 0.0465,  0.0058,  0.0640, -0.1513,  0.2647, -0.0989],\n",
      "        [ 0.0145,  0.0175, -0.2298,  0.2415,  0.1833, -0.2327],\n",
      "        [ 0.0291, -0.3695,  0.1513, -0.0960, -0.1949,  0.0000],\n",
      "        [-0.0756,  0.0116, -0.0262,  0.2153, -0.1833, -0.0378],\n",
      "        [ 0.0611,  0.0640,  0.2007, -0.1484, -0.1426,  0.1833],\n",
      "        [-0.2356,  0.0553, -0.0815, -0.0844,  0.0175,  0.0960],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]], size=(16, 6),\n",
      "       dtype=torch.qint8, quantization_scheme=torch.per_tensor_affine,\n",
      "       scale=0.0029092177283018827, zero_point=0), Parameter containing:\n",
      "tensor([ 1.5826e-01,  1.8289e-01,  9.5474e-02,  1.4245e-01,  1.6067e-01,\n",
      "         6.2892e-02, -8.1824e-03,  1.0988e-01,  1.6134e-01,  1.3538e-01,\n",
      "         2.0215e-01,  2.8252e-02,  1.6776e-01,  7.5159e-02,  1.5710e-01,\n",
      "        -1.1991e-14], requires_grad=True))), ('cinn.module_list.8.subnet1.lin_2.scale', tensor(0.0089)), ('cinn.module_list.8.subnet1.lin_2.zero_point', tensor(75)), ('cinn.module_list.8.subnet1.lin_2._packed_params.dtype', torch.qint8), ('cinn.module_list.8.subnet1.lin_2._packed_params._packed_params', (tensor([[ 0.0357,  0.2262,  0.1786,  0.0357,  0.1270,  0.1984,  0.0516,  0.0754,\n",
      "          0.0516,  0.1071,  0.0813,  0.0298,  0.0397,  0.0754,  0.0516,  0.0000],\n",
      "        [ 0.0000,  0.0179, -0.0198,  0.0159,  0.0298,  0.0238,  0.0476,  0.0238,\n",
      "          0.1230,  0.0496,  0.1012,  0.0893,  0.0377,  0.0556,  0.1329,  0.0000],\n",
      "        [ 0.1071, -0.2361,  0.1389,  0.1250,  0.1647, -0.1071,  0.1805,  0.1131,\n",
      "         -0.1805, -0.2262, -0.1746,  0.1290,  0.1924,  0.1547,  0.1309,  0.0000],\n",
      "        [-0.2123, -0.1805,  0.1944, -0.2539, -0.1647, -0.0813,  0.1508, -0.2500,\n",
      "         -0.1706,  0.1786, -0.2043,  0.2024, -0.2043,  0.1309,  0.1448,  0.0000]],\n",
      "       size=(4, 16), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.0019839478190988302,\n",
      "       zero_point=0), Parameter containing:\n",
      "tensor([ 0.1598,  0.0969, -0.0248, -0.0388], requires_grad=True))), ('cinn.module_list.8.subnet2.quant.scale', tensor([0.0214])), ('cinn.module_list.8.subnet2.quant.zero_point', tensor([47])), ('cinn.module_list.8.subnet2.lin_1.scale', tensor(0.0040)), ('cinn.module_list.8.subnet2.lin_1.zero_point', tensor(0)), ('cinn.module_list.8.subnet2.lin_1._packed_params.dtype', torch.qint8), ('cinn.module_list.8.subnet2.lin_1._packed_params._packed_params', (tensor([[ 0.0765,  0.0946, -0.1630,  0.0825,  0.1167, -0.1227],\n",
      "        [-0.0644,  0.1630, -0.1066,  0.1328,  0.0262, -0.1549],\n",
      "        [-0.0101,  0.0020,  0.1187, -0.2012, -0.1791,  0.2032],\n",
      "        [-0.0584,  0.1811, -0.1087,  0.0845,  0.0362, -0.1630],\n",
      "        [-0.0825, -0.0724,  0.2274, -0.0322, -0.1670,  0.0563],\n",
      "        [ 0.1529,  0.0020,  0.0000, -0.0302, -0.0101,  0.0000],\n",
      "        [ 0.1147,  0.1429, -0.1549,  0.1348,  0.1227, -0.1489],\n",
      "        [-0.0584, -0.0865, -0.1429,  0.0563,  0.0201,  0.2556],\n",
      "        [ 0.1167,  0.1449, -0.1509,  0.1046,  0.1529, -0.1348],\n",
      "        [-0.0080,  0.0342,  0.2153, -0.1529,  0.0322, -0.1731],\n",
      "        [ 0.0885,  0.1489, -0.1087,  0.0825,  0.1409, -0.1227],\n",
      "        [-0.0423, -0.0885, -0.1368, -0.0523, -0.1429,  0.1831],\n",
      "        [ 0.0040, -0.1570, -0.1248,  0.1167,  0.0644,  0.1891],\n",
      "        [ 0.0040, -0.0966,  0.1650, -0.0584, -0.1670,  0.1831],\n",
      "        [-0.0644, -0.1087, -0.1368, -0.1429, -0.0141,  0.1932],\n",
      "        [-0.1831,  0.0020, -0.0201,  0.1791,  0.0845, -0.0946]], size=(16, 6),\n",
      "       dtype=torch.qint8, quantization_scheme=torch.per_tensor_affine,\n",
      "       scale=0.002012218814343214, zero_point=0), Parameter containing:\n",
      "tensor([ 0.1005,  0.0377,  0.1773,  0.0212,  0.1550, -0.0546,  0.1130,  0.1090,\n",
      "         0.1019,  0.1536,  0.0702,  0.1289,  0.1426,  0.1554,  0.1554,  0.0888],\n",
      "       requires_grad=True))), ('cinn.module_list.8.subnet2.lin_2.scale', tensor(0.0069)), ('cinn.module_list.8.subnet2.lin_2.zero_point', tensor(72)), ('cinn.module_list.8.subnet2.lin_2._packed_params.dtype', torch.qint8), ('cinn.module_list.8.subnet2.lin_2._packed_params._packed_params', (tensor([[ 0.1132,  0.1096,  0.0575,  0.0629,  0.1940, -0.2263,  0.1024, -0.0108,\n",
      "          0.1150, -0.0251,  0.0826,  0.0036,  0.1491,  0.0736,  0.0916,  0.1760],\n",
      "        [ 0.0413,  0.0970,  0.0090,  0.0557,  0.1114, -0.1401,  0.0790,  0.1724,\n",
      "          0.0467,  0.0898,  0.0665, -0.0305,  0.0826,  0.0539,  0.0162,  0.1347],\n",
      "        [ 0.1275,  0.1527, -0.1383,  0.1275, -0.0916,  0.0269,  0.1185,  0.0521,\n",
      "          0.1509, -0.2299,  0.1527,  0.1096,  0.1634, -0.1958,  0.1060,  0.1203],\n",
      "        [ 0.0844,  0.1652, -0.1688,  0.1509, -0.0198, -0.0341,  0.1670, -0.1203,\n",
      "          0.1203,  0.2137,  0.1132, -0.2066, -0.1257, -0.2191, -0.1958,  0.0988]],\n",
      "       size=(4, 16), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.0017961018020287156,\n",
      "       zero_point=0), Parameter containing:\n",
      "tensor([ 0.0816,  0.1270, -0.0995, -0.0374], requires_grad=True))), ('cinn.module_list.9.perm', tensor([0, 1, 3, 2])), ('cinn.module_list.9.perm_inv', tensor([0, 1, 3, 2])), ('cinn.module_list.10.subnet1.quant.scale', tensor([0.0212])), ('cinn.module_list.10.subnet1.quant.zero_point', tensor([57])), ('cinn.module_list.10.subnet1.lin_1.scale', tensor(0.0052)), ('cinn.module_list.10.subnet1.lin_1.zero_point', tensor(0)), ('cinn.module_list.10.subnet1.lin_1._packed_params.dtype', torch.qint8), ('cinn.module_list.10.subnet1.lin_1._packed_params._packed_params', (tensor([[-0.0720,  0.1912,  0.0149, -0.0099, -0.0894,  0.0745],\n",
      "        [-0.0099, -0.0050, -0.0248, -0.0149, -0.0224, -0.0050],\n",
      "        [-0.1291,  0.0174, -0.0199,  0.1937, -0.1440,  0.0919],\n",
      "        [ 0.0075, -0.0919, -0.0397, -0.1217,  0.2111,  0.0099],\n",
      "        [ 0.0050, -0.1391,  0.0919, -0.1664,  0.2682,  0.0348],\n",
      "        [ 0.0199, -0.1515,  0.0894, -0.1838,  0.1838,  0.0397],\n",
      "        [ 0.0546,  0.0224, -0.2558,  0.2186,  0.1714, -0.2310],\n",
      "        [ 0.0695,  0.0224,  0.1664, -0.1366, -0.1440,  0.1962],\n",
      "        [ 0.0447,  0.0099, -0.2633,  0.2061,  0.2012, -0.2310],\n",
      "        [ 0.0770,  0.0770,  0.1217, -0.1267, -0.2335,  0.1714],\n",
      "        [-0.2161,  0.0124,  0.0323, -0.0745,  0.1416,  0.1440],\n",
      "        [ 0.0050, -0.1366,  0.0621, -0.1391,  0.2161,  0.0596],\n",
      "        [ 0.0447,  0.1242, -0.0149,  0.3154,  0.0621, -0.0248],\n",
      "        [-0.2782,  0.0050,  0.1465, -0.2533, -0.1838,  0.1739],\n",
      "        [-0.0099,  0.1987, -0.1267,  0.2931, -0.1242, -0.0497],\n",
      "        [ 0.0894,  0.0671,  0.1465, -0.2136, -0.2210,  0.1192]], size=(16, 6),\n",
      "       dtype=torch.qint8, quantization_scheme=torch.per_tensor_affine,\n",
      "       scale=0.0024836023803800344, zero_point=0), Parameter containing:\n",
      "tensor([-0.0086, -0.0437,  0.1048,  0.1160,  0.1550,  0.1759,  0.1735,  0.0651,\n",
      "         0.1949,  0.1218,  0.1766,  0.1261,  0.1291,  0.0815,  0.0910,  0.1053],\n",
      "       requires_grad=True))), ('cinn.module_list.10.subnet1.lin_2.scale', tensor(0.0086)), ('cinn.module_list.10.subnet1.lin_2.zero_point', tensor(57)), ('cinn.module_list.10.subnet1.lin_2._packed_params.dtype', torch.qint8), ('cinn.module_list.10.subnet1.lin_2._packed_params._packed_params', (tensor([[ 0.0439,  0.0022,  0.0505,  0.0461,  0.0637,  0.1625,  0.0879,  0.0922,\n",
      "          0.1142,  0.0879,  0.1428,  0.0747,  0.2789,  0.0571,  0.2021,  0.1208],\n",
      "        [-0.0747, -0.0220,  0.1274,  0.0154,  0.1120,  0.1867,  0.0988,  0.0483,\n",
      "          0.0922,  0.1120,  0.1889,  0.0571,  0.0791,  0.1296, -0.0264,  0.1537],\n",
      "        [ 0.0110,  0.0088, -0.1252,  0.1889,  0.1845,  0.1757, -0.1735,  0.1625,\n",
      "         -0.1647,  0.1164,  0.2196,  0.2328, -0.1494,  0.2196, -0.2328,  0.1318],\n",
      "        [ 0.1340, -0.0088,  0.2306, -0.1603, -0.1735, -0.1164, -0.1537,  0.1296,\n",
      "         -0.1889,  0.1494,  0.0417, -0.1735, -0.0307,  0.2789,  0.0966,  0.1494]],\n",
      "       size=(4, 16), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.0021964265033602715,\n",
      "       zero_point=0), Parameter containing:\n",
      "tensor([ 0.1576,  0.1711, -0.0893, -0.0263], requires_grad=True))), ('cinn.module_list.10.subnet2.quant.scale', tensor([0.0192])), ('cinn.module_list.10.subnet2.quant.zero_point', tensor([56])), ('cinn.module_list.10.subnet2.lin_1.scale', tensor(0.0061)), ('cinn.module_list.10.subnet2.lin_1.zero_point', tensor(0)), ('cinn.module_list.10.subnet2.lin_1._packed_params.dtype', torch.qint8), ('cinn.module_list.10.subnet2.lin_1._packed_params._packed_params', (tensor([[-0.1443,  0.0136, -0.1388, -0.0898, -0.0572,  0.1579],\n",
      "        [-0.1715, -0.0463,  0.2722, -0.1443,  0.1497, -0.2641],\n",
      "        [ 0.1552, -0.0245, -0.1279,  0.1116,  0.1171, -0.1742],\n",
      "        [ 0.0218,  0.0109, -0.1470,  0.0817, -0.1579,  0.2368],\n",
      "        [ 0.0245, -0.0191,  0.0000, -0.0191,  0.0000,  0.0000],\n",
      "        [-0.1906, -0.0082, -0.1307,  0.0898,  0.1089,  0.2341],\n",
      "        [ 0.0653, -0.1960,  0.0109,  0.1606,  0.0490, -0.0844],\n",
      "        [-0.0245,  0.0109,  0.1470, -0.1906, -0.2151,  0.1851],\n",
      "        [ 0.0054, -0.2831,  0.3022,  0.0871,  0.1062, -0.1279],\n",
      "        [ 0.0789,  0.0762, -0.1470,  0.1906,  0.1769, -0.1416],\n",
      "        [ 0.0054, -0.1334,  0.2123, -0.0926, -0.1307, -0.1524],\n",
      "        [-0.0163, -0.1443,  0.2668, -0.0789, -0.1143, -0.1443],\n",
      "        [-0.0681, -0.0218,  0.2368, -0.0681,  0.1388, -0.1661],\n",
      "        [ 0.0599,  0.0517, -0.1443,  0.1878,  0.2014, -0.1361],\n",
      "        [-0.0082, -0.0436,  0.3457,  0.0898,  0.0735, -0.1906],\n",
      "        [-0.1225, -0.0027,  0.1633, -0.1034, -0.1225,  0.1279]], size=(16, 6),\n",
      "       dtype=torch.qint8, quantization_scheme=torch.per_tensor_affine,\n",
      "       scale=0.0027222323697060347, zero_point=0), Parameter containing:\n",
      "tensor([ 0.1665,  0.1671,  0.0912,  0.1333, -0.0555,  0.1688,  0.1123,  0.1877,\n",
      "         0.1853,  0.0949,  0.1838,  0.1852,  0.1286,  0.1106,  0.1433,  0.1737],\n",
      "       requires_grad=True))), ('cinn.module_list.10.subnet2.lin_2.scale', tensor(0.0129)), ('cinn.module_list.10.subnet2.lin_2.zero_point', tensor(54)), ('cinn.module_list.10.subnet2.lin_2._packed_params.dtype', torch.qint8), ('cinn.module_list.10.subnet2.lin_2._packed_params._packed_params', (tensor([[ 0.0575,  0.2654,  0.0929, -0.0155,  0.0088,  0.1415,  0.0929,  0.0774,\n",
      "          0.2809,  0.0796, -0.0133,  0.0243,  0.1570,  0.0597,  0.2344,  0.1880],\n",
      "        [ 0.0376,  0.1460,  0.0597,  0.0929,  0.0022,  0.1371,  0.0995,  0.1017,\n",
      "          0.1592,  0.1327,  0.1084,  0.1084,  0.1415,  0.1106,  0.1150,  0.0354],\n",
      "        [ 0.1460, -0.2057,  0.1725,  0.1106,  0.0044,  0.2322,  0.1371, -0.1858,\n",
      "         -0.1371,  0.1592, -0.1924, -0.1880, -0.2410,  0.1902, -0.1238, -0.1504],\n",
      "        [-0.2521,  0.1393,  0.1482, -0.2035,  0.0022, -0.2366,  0.1592, -0.1659,\n",
      "          0.2035,  0.1150,  0.1460,  0.1504,  0.1880,  0.1150,  0.1061, -0.1570]],\n",
      "       size=(4, 16), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.0022114519961178303,\n",
      "       zero_point=0), Parameter containing:\n",
      "tensor([ 0.1879,  0.1130, -0.0470, -0.0971], requires_grad=True))), ('cinn.module_list.11.perm', tensor([0, 1, 2, 3])), ('cinn.module_list.11.perm_inv', tensor([0, 1, 2, 3])), ('cinn.module_list.12.subnet1.quant.scale', tensor([0.0267])), ('cinn.module_list.12.subnet1.quant.zero_point', tensor([56])), ('cinn.module_list.12.subnet1.lin_1.scale', tensor(0.0061)), ('cinn.module_list.12.subnet1.lin_1.zero_point', tensor(0)), ('cinn.module_list.12.subnet1.lin_1._packed_params.dtype', torch.qint8), ('cinn.module_list.12.subnet1.lin_1._packed_params._packed_params', (tensor([[ 0.0549,  0.1855,  0.1463, -0.1332, -0.1620,  0.1228],\n",
      "        [ 0.0758,  0.0340,  0.2012, -0.1515, -0.1620,  0.1933],\n",
      "        [-0.0026,  0.0052,  0.0000,  0.0000,  0.0287,  0.0000],\n",
      "        [ 0.0131,  0.2038,  0.1620, -0.1019, -0.0549,  0.2169],\n",
      "        [-0.0157,  0.2273, -0.1437,  0.2560, -0.1542,  0.0340],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0105,  0.2534,  0.0967,  0.0418, -0.2273,  0.0444],\n",
      "        [ 0.0732,  0.0444,  0.1620, -0.2456, -0.0836,  0.1620],\n",
      "        [-0.0052, -0.0758,  0.0653, -0.1359,  0.2195, -0.1176],\n",
      "        [-0.0836,  0.0131, -0.1045,  0.2012, -0.0993,  0.0732],\n",
      "        [-0.0496,  0.2508,  0.0366, -0.0914,  0.0105,  0.1359],\n",
      "        [-0.0052,  0.0444, -0.1489,  0.3318,  0.2012, -0.2900],\n",
      "        [-0.1254, -0.0261,  0.0627, -0.0653,  0.1986,  0.1332],\n",
      "        [ 0.0105, -0.1463,  0.1176, -0.2351,  0.2979,  0.0209],\n",
      "        [ 0.1123,  0.0183,  0.1359, -0.0914,  0.0941,  0.1385],\n",
      "        [ 0.0105, -0.0078, -0.2325,  0.1672,  0.1463, -0.2195]], size=(16, 6),\n",
      "       dtype=torch.qint8, quantization_scheme=torch.per_tensor_affine,\n",
      "       scale=0.002612732583656907, zero_point=0), Parameter containing:\n",
      "tensor([ 0.1991,  0.0438, -0.0503,  0.1682,  0.0972, -0.0006,  0.0336,  0.1353,\n",
      "         0.1125,  0.1762,  0.1405,  0.2128,  0.1917,  0.1886,  0.2329,  0.1985],\n",
      "       requires_grad=True))), ('cinn.module_list.12.subnet1.lin_2.scale', tensor(0.0087)), ('cinn.module_list.12.subnet1.lin_2.zero_point', tensor(40)), ('cinn.module_list.12.subnet1.lin_2._packed_params.dtype', torch.qint8), ('cinn.module_list.12.subnet1.lin_2._packed_params._packed_params', (tensor([[ 0.1203,  0.0982,  0.0000,  0.1031,  0.1105,  0.0000,  0.1203,  0.1179,\n",
      "          0.0491,  0.0958,  0.1326,  0.2406,  0.1277,  0.0982,  0.1424,  0.0467],\n",
      "        [ 0.0565,  0.1130, -0.0049,  0.1080,  0.0859,  0.0000,  0.0246,  0.1007,\n",
      "          0.1571,  0.0810,  0.1473,  0.1179,  0.2406,  0.3118,  0.1743,  0.1989],\n",
      "        [ 0.0909,  0.1154, -0.0123,  0.1277, -0.2382,  0.0000,  0.1326,  0.1645,\n",
      "          0.2087, -0.1645,  0.1571, -0.2185,  0.2013,  0.2431,  0.1277, -0.1866],\n",
      "        [ 0.1792,  0.1473,  0.0000,  0.1326,  0.1817,  0.0000,  0.0884,  0.1277,\n",
      "         -0.2087,  0.1915,  0.1473, -0.1743, -0.0368, -0.1473,  0.0270, -0.1424]],\n",
      "       size=(4, 16), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.00245544221252203,\n",
      "       zero_point=0), Parameter containing:\n",
      "tensor([ 0.1279,  0.1831, -0.0468, -0.0428], requires_grad=True))), ('cinn.module_list.12.subnet2.quant.scale', tensor([0.0222])), ('cinn.module_list.12.subnet2.quant.zero_point', tensor([62])), ('cinn.module_list.12.subnet2.lin_1.scale', tensor(0.0052)), ('cinn.module_list.12.subnet2.lin_1.zero_point', tensor(0)), ('cinn.module_list.12.subnet2.lin_1._packed_params.dtype', torch.qint8), ('cinn.module_list.12.subnet2.lin_1._packed_params._packed_params', (tensor([[ 0.0102, -0.0025,  0.0000,  0.0000,  0.0025,  0.0000],\n",
      "        [-0.1601,  0.0000,  0.1805, -0.0941, -0.2237,  0.2288],\n",
      "        [-0.0330, -0.0330, -0.2008,  0.1017, -0.1805,  0.2389],\n",
      "        [ 0.0356,  0.0102,  0.0000, -0.0305,  0.0000,  0.0000],\n",
      "        [-0.0915,  0.0076, -0.0991, -0.1246, -0.2008,  0.1627],\n",
      "        [-0.1525, -0.0025,  0.1373, -0.1398, -0.2593,  0.2262],\n",
      "        [-0.0559, -0.0458,  0.2262, -0.1195,  0.0254, -0.1169],\n",
      "        [-0.0051, -0.0025,  0.0000,  0.0127,  0.0000,  0.0000],\n",
      "        [-0.0635, -0.0432,  0.1627, -0.0915,  0.1093, -0.2161],\n",
      "        [ 0.0102, -0.2008, -0.0941,  0.1652, -0.0661,  0.2186],\n",
      "        [ 0.0407,  0.0127, -0.1754, -0.1779, -0.1500,  0.2034],\n",
      "        [-0.0407, -0.0483, -0.2440,  0.1169,  0.0458,  0.2669],\n",
      "        [-0.0102,  0.1144,  0.1957,  0.0661,  0.1601, -0.1093],\n",
      "        [ 0.0585, -0.2694,  0.0763,  0.1576,  0.0305, -0.0381],\n",
      "        [-0.0229, -0.1652, -0.3254,  0.1601, -0.0686,  0.2542],\n",
      "        [ 0.0305, -0.0661, -0.2593,  0.1144,  0.0635,  0.2466]], size=(16, 6),\n",
      "       dtype=torch.qint8, quantization_scheme=torch.per_tensor_affine,\n",
      "       scale=0.0025418950244784355, zero_point=0), Parameter containing:\n",
      "tensor([-0.0262,  0.1531,  0.1474, -0.0471,  0.1549,  0.1929,  0.1686, -0.0419,\n",
      "         0.1438,  0.2010,  0.1044,  0.1787,  0.1868,  0.1544,  0.1789,  0.1911],\n",
      "       requires_grad=True))), ('cinn.module_list.12.subnet2.lin_2.scale', tensor(0.0137)), ('cinn.module_list.12.subnet2.lin_2.zero_point', tensor(57)), ('cinn.module_list.12.subnet2.lin_2._packed_params.dtype', torch.qint8), ('cinn.module_list.12.subnet2.lin_2._packed_params._packed_params', (tensor([[ 0.0283,  0.0958,  0.0218,  0.0414,  0.1001,  0.0827,  0.0805, -0.0370,\n",
      "          0.0871,  0.0784, -0.0065,  0.0283,  0.2220,  0.1720,  0.0762,  0.0849],\n",
      "        [-0.0087,  0.1546,  0.0762,  0.0174, -0.0348,  0.1371,  0.1045, -0.0152,\n",
      "          0.1067,  0.2590, -0.0283,  0.2677,  0.1154,  0.1458,  0.2765,  0.2634],\n",
      "        [-0.0370, -0.1850,  0.1763, -0.0152,  0.0609, -0.1872, -0.2177,  0.0740,\n",
      "         -0.1741,  0.1894,  0.1676,  0.1611,  0.0087,  0.1524,  0.1850,  0.2155],\n",
      "        [-0.0022, -0.2482, -0.2199, -0.0414, -0.2264, -0.2003,  0.1741, -0.0283,\n",
      "          0.2373, -0.1110, -0.2329, -0.1785,  0.1219,  0.1763, -0.1524, -0.1415]],\n",
      "       size=(4, 16), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.0021767837461084127,\n",
      "       zero_point=0), Parameter containing:\n",
      "tensor([ 0.1845,  0.1268, -0.0824, -0.0357], requires_grad=True))), ('cinn.module_list.13.perm', tensor([0, 3, 1, 2])), ('cinn.module_list.13.perm_inv', tensor([0, 2, 3, 1])), ('cinn.module_list.14.subnet1.quant.scale', tensor([0.0365])), ('cinn.module_list.14.subnet1.quant.zero_point', tensor([65])), ('cinn.module_list.14.subnet1.lin_1.scale', tensor(0.0068)), ('cinn.module_list.14.subnet1.lin_1.zero_point', tensor(0)), ('cinn.module_list.14.subnet1.lin_1._packed_params.dtype', torch.qint8), ('cinn.module_list.14.subnet1.lin_1._packed_params._packed_params', (tensor([[-0.0758,  0.0000,  0.1083,  0.2220,  0.1300, -0.0866],\n",
      "        [ 0.0975, -0.0190, -0.3466,  0.2627, -0.2329,  0.1598],\n",
      "        [ 0.0569, -0.0054,  0.1273, -0.0948,  0.1760, -0.2166],\n",
      "        [ 0.0000,  0.0054,  0.0000,  0.0000,  0.0054,  0.0081],\n",
      "        [ 0.0460,  0.1489,  0.0298,  0.1489,  0.0081,  0.2437],\n",
      "        [-0.0758, -0.0054,  0.0921,  0.2383,  0.0975, -0.1354],\n",
      "        [-0.0108,  0.0812, -0.0839,  0.1462, -0.0785, -0.2085],\n",
      "        [-0.0623,  0.0000, -0.0460,  0.1923,  0.1056, -0.0596],\n",
      "        [ 0.1056, -0.0135, -0.3006, -0.0758, -0.2572,  0.1733],\n",
      "        [ 0.0054,  0.1381,  0.1083, -0.0704,  0.1137, -0.0975],\n",
      "        [ 0.0433,  0.0027, -0.3141,  0.2112, -0.1841,  0.1895],\n",
      "        [ 0.0027,  0.1029,  0.1462, -0.2410,  0.1164, -0.0514],\n",
      "        [-0.0271, -0.2518,  0.1841, -0.2789,  0.0812, -0.2166],\n",
      "        [ 0.0027,  0.1706,  0.1787, -0.0433,  0.1110, -0.0758],\n",
      "        [ 0.0677, -0.0054, -0.2572,  0.3006, -0.1868,  0.2058],\n",
      "        [ 0.0108,  0.0379, -0.1895,  0.2572, -0.1977,  0.2247]], size=(16, 6),\n",
      "       dtype=torch.qint8, quantization_scheme=torch.per_tensor_affine,\n",
      "       scale=0.0027077719569206238, zero_point=0), Parameter containing:\n",
      "tensor([ 0.1889,  0.1924,  0.1268, -0.0350,  0.1804,  0.2333,  0.0844,  0.1392,\n",
      "         0.2024,  0.1711,  0.2528,  0.1007,  0.0788,  0.1670,  0.1610,  0.2445],\n",
      "       requires_grad=True))), ('cinn.module_list.14.subnet1.lin_2.scale', tensor(0.0133)), ('cinn.module_list.14.subnet1.lin_2.zero_point', tensor(48)), ('cinn.module_list.14.subnet1.lin_2._packed_params.dtype', torch.qint8), ('cinn.module_list.14.subnet1.lin_2._packed_params._packed_params', (tensor([[ 0.1767,  0.0390,  0.0961, -0.0104,  0.3300,  0.0909,  0.0935,  0.1013,\n",
      "          0.0468,  0.1325,  0.2469,  0.1663,  0.2027,  0.1377,  0.1195,  0.3144],\n",
      "        [ 0.1559,  0.2417,  0.1247,  0.0078, -0.0026,  0.2235,  0.0104,  0.0572,\n",
      "          0.1429,  0.1403,  0.1455,  0.0909,  0.1845,  0.1169,  0.1767,  0.2001],\n",
      "        [ 0.1845, -0.1689,  0.1429,  0.0104, -0.1819,  0.1923,  0.1611,  0.1767,\n",
      "         -0.2313,  0.1351, -0.1741,  0.1169,  0.2001,  0.1559, -0.1689, -0.2235],\n",
      "        [-0.2001, -0.1325,  0.0935, -0.0260, -0.1325, -0.1949, -0.1871, -0.1689,\n",
      "          0.1117,  0.1195, -0.1611,  0.1221,  0.2209,  0.1429, -0.1611, -0.1819]],\n",
      "       size=(4, 16), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.002598454477265477,\n",
      "       zero_point=0), Parameter containing:\n",
      "tensor([ 0.1384,  0.1694, -0.0891, -0.0344], requires_grad=True))), ('cinn.module_list.14.subnet2.quant.scale', tensor([0.0267])), ('cinn.module_list.14.subnet2.quant.zero_point', tensor([56])), ('cinn.module_list.14.subnet2.lin_1.scale', tensor(0.0065)), ('cinn.module_list.14.subnet2.lin_1.zero_point', tensor(0)), ('cinn.module_list.14.subnet2.lin_1._packed_params.dtype', torch.qint8), ('cinn.module_list.14.subnet2.lin_1._packed_params._packed_params', (tensor([[-0.2277,  0.0264,  0.2038, -0.1558, -0.1319, -0.0863],\n",
      "        [-0.1750,  0.0312, -0.1295,  0.1007, -0.1247,  0.1343],\n",
      "        [ 0.0839,  0.2877, -0.2038,  0.1151, -0.0887, -0.0455],\n",
      "        [-0.1247,  0.0120,  0.1918, -0.1079, -0.0983,  0.1726],\n",
      "        [ 0.1031,  0.0599, -0.2134,  0.1582,  0.0120,  0.0935],\n",
      "        [ 0.1055,  0.1894,  0.0168,  0.1055, -0.0527,  0.1438],\n",
      "        [-0.0791,  0.1031, -0.2014,  0.1151, -0.1055,  0.0623],\n",
      "        [-0.0024,  0.0192,  0.1894, -0.1822,  0.2517, -0.2254],\n",
      "        [-0.1127,  0.0911,  0.1870, -0.1750, -0.1055, -0.0791],\n",
      "        [-0.0072,  0.0048,  0.0216,  0.0000,  0.0144,  0.0000],\n",
      "        [-0.2613,  0.0408,  0.3045,  0.0719, -0.0599,  0.0336],\n",
      "        [ 0.1319,  0.0240, -0.1894,  0.1510, -0.1199,  0.0983],\n",
      "        [ 0.0000, -0.0455, -0.1343,  0.1534,  0.2709,  0.0216],\n",
      "        [ 0.0839, -0.1247, -0.2589,  0.1007,  0.0216,  0.1199],\n",
      "        [-0.0072,  0.0839, -0.1366,  0.1271, -0.1462,  0.0599],\n",
      "        [-0.0096, -0.0216, -0.1151,  0.1630,  0.2254, -0.0384]], size=(16, 6),\n",
      "       dtype=torch.qint8, quantization_scheme=torch.per_tensor_affine,\n",
      "       scale=0.002397341886535287, zero_point=0), Parameter containing:\n",
      "tensor([ 0.2669, -0.0227, -0.0511,  0.1724,  0.0969,  0.1811,  0.0643,  0.2240,\n",
      "         0.1817, -0.0399,  0.1630,  0.0814,  0.1963,  0.1563,  0.0460,  0.2089],\n",
      "       requires_grad=True))), ('cinn.module_list.14.subnet2.lin_2.scale', tensor(0.0104)), ('cinn.module_list.14.subnet2.lin_2.zero_point', tensor(62)), ('cinn.module_list.14.subnet2.lin_2._packed_params.dtype', torch.qint8), ('cinn.module_list.14.subnet2.lin_2._packed_params._packed_params', (tensor([[ 0.1007,  0.1231, -0.1679,  0.0700,  0.0867,  0.1483,  0.1287,  0.1567,\n",
      "          0.1371,  0.0000,  0.2211,  0.0923,  0.0504,  0.0784,  0.1175,  0.1651],\n",
      "        [ 0.0812,  0.1427, -0.3582,  0.0923,  0.1651,  0.1567,  0.0672,  0.2239,\n",
      "          0.0728, -0.0168,  0.1203,  0.0951,  0.1399,  0.1931,  0.0839,  0.1735],\n",
      "        [-0.2155,  0.1231,  0.0923, -0.1763,  0.1343,  0.0504,  0.1203, -0.1511,\n",
      "         -0.2127,  0.0028, -0.1231,  0.1903,  0.2239,  0.1539,  0.0700,  0.1819],\n",
      "        [ 0.2267,  0.1231, -0.0616,  0.2155,  0.0672,  0.1427,  0.1119, -0.1987,\n",
      "          0.1987,  0.0280,  0.2351,  0.1931, -0.1231,  0.1511,  0.1091, -0.2043]],\n",
      "       size=(4, 16), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.0027983314357697964,\n",
      "       zero_point=0), Parameter containing:\n",
      "tensor([ 0.1437,  0.2096, -0.1401, -0.0961], requires_grad=True))), ('cinn.module_list.15.perm', tensor([2, 1, 0, 3])), ('cinn.module_list.15.perm_inv', tensor([2, 1, 0, 3])), ('cinn.module_list.16.subnet1.quant.scale', tensor([0.0521])), ('cinn.module_list.16.subnet1.quant.zero_point', tensor([67])), ('cinn.module_list.16.subnet1.lin_1.scale', tensor(0.0100)), ('cinn.module_list.16.subnet1.lin_1.zero_point', tensor(0)), ('cinn.module_list.16.subnet1.lin_1._packed_params.dtype', torch.qint8), ('cinn.module_list.16.subnet1.lin_1._packed_params._packed_params', (tensor([[-0.0072,  0.0336,  0.2088,  0.0720, -0.2664, -0.1632],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0120, -0.0984,  0.2136, -0.0216,  0.0120,  0.0576],\n",
      "        [-0.0120, -0.0336,  0.1656, -0.0816, -0.0912, -0.0960],\n",
      "        [-0.1752, -0.0264,  0.1176,  0.1248,  0.2112, -0.0048],\n",
      "        [ 0.0360, -0.1008, -0.0888,  0.2880,  0.0432,  0.0264],\n",
      "        [ 0.0600,  0.0936, -0.0192,  0.1128,  0.1680,  0.0888],\n",
      "        [-0.2352,  0.0000, -0.0720,  0.1464,  0.0768,  0.0336],\n",
      "        [ 0.0816,  0.1128,  0.2880,  0.2712, -0.0456, -0.0816],\n",
      "        [-0.0096, -0.0168,  0.2088, -0.1440, -0.0216, -0.0936],\n",
      "        [ 0.0168, -0.0120,  0.2088,  0.1248, -0.1464, -0.2424],\n",
      "        [-0.1632, -0.0192, -0.2064, -0.2112,  0.1776,  0.1824],\n",
      "        [ 0.1800,  0.1488,  0.0288,  0.0312,  0.0816,  0.1104],\n",
      "        [-0.1440, -0.0216,  0.1512, -0.2760,  0.2016,  0.0240],\n",
      "        [ 0.3048,  0.0480,  0.2136,  0.0288,  0.0864,  0.0024],\n",
      "        [-0.1488,  0.0456,  0.0456,  0.0792,  0.1344,  0.0384]], size=(16, 6),\n",
      "       dtype=torch.qint8, quantization_scheme=torch.per_tensor_affine,\n",
      "       scale=0.0024003698490560055, zero_point=0), Parameter containing:\n",
      "tensor([ 1.7829e-01, -4.9596e-12,  2.1654e-01,  1.7174e-01,  2.1714e-01,\n",
      "         2.5635e-01,  2.2796e-01,  1.6915e-01,  2.0613e-01,  1.8851e-01,\n",
      "         1.9506e-01,  6.6227e-02,  2.2926e-01,  1.3370e-01,  1.5785e-01,\n",
      "         2.5650e-01], requires_grad=True))), ('cinn.module_list.16.subnet1.lin_2.scale', tensor(0.0143)), ('cinn.module_list.16.subnet1.lin_2.zero_point', tensor(34)), ('cinn.module_list.16.subnet1.lin_2._packed_params.dtype', torch.qint8), ('cinn.module_list.16.subnet1.lin_2._packed_params._packed_params', (tensor([[ 0.1036,  0.0000,  0.1554,  0.0164,  0.1363,  0.1282,  0.1609,  0.1091,\n",
      "          0.3463,  0.0654,  0.1854,  0.1254,  0.2018,  0.1363,  0.2699,  0.1063],\n",
      "        [ 0.0873,  0.0000,  0.2263,  0.1745,  0.2618,  0.2563,  0.0927,  0.2427,\n",
      "          0.2399,  0.1009,  0.1091,  0.1581,  0.0218,  0.1363,  0.1527,  0.1990],\n",
      "        [-0.1554,  0.0000, -0.1718, -0.1827,  0.1636,  0.1145,  0.0763,  0.1745,\n",
      "         -0.1418, -0.1636, -0.1581,  0.1418,  0.0464,  0.1309, -0.0709,  0.1254],\n",
      "        [-0.1172,  0.0000,  0.1581,  0.1609,  0.0954, -0.1391, -0.0027,  0.0573,\n",
      "         -0.1472,  0.1772, -0.1718,  0.1827,  0.0600,  0.1609,  0.1909,  0.0736]],\n",
      "       size=(4, 16), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.002726626815274358,\n",
      "       zero_point=0), Parameter containing:\n",
      "tensor([ 0.1877,  0.2017, -0.0792, -0.1783], requires_grad=True))), ('cinn.module_list.16.subnet2.quant.scale', tensor([0.0332])), ('cinn.module_list.16.subnet2.quant.zero_point', tensor([70])), ('cinn.module_list.16.subnet2.lin_1.scale', tensor(0.0074)), ('cinn.module_list.16.subnet2.lin_1.zero_point', tensor(0)), ('cinn.module_list.16.subnet2.lin_1._packed_params.dtype', torch.qint8), ('cinn.module_list.16.subnet2.lin_1._packed_params._packed_params', (tensor([[ 0.1885, -0.0027,  0.1400,  0.1050, -0.1077, -0.0916],\n",
      "        [ 0.0242,  0.0754,  0.1373,  0.1239,  0.2046, -0.0565],\n",
      "        [-0.0673,  0.0054,  0.0054,  0.1643, -0.1158,  0.1966],\n",
      "        [ 0.1616, -0.2020,  0.1616, -0.0054,  0.0754,  0.0781],\n",
      "        [-0.1158,  0.0942, -0.0619,  0.1158, -0.1077,  0.2558],\n",
      "        [ 0.0215,  0.1535, -0.1777, -0.2208,  0.2100,  0.2262],\n",
      "        [-0.0754, -0.0027,  0.0862, -0.0727,  0.1939, -0.0942],\n",
      "        [-0.0377,  0.0108, -0.0781, -0.1804,  0.2235, -0.0889],\n",
      "        [ 0.0296,  0.3420, -0.3258,  0.3339, -0.3204, -0.1427],\n",
      "        [-0.0942,  0.0242,  0.0458, -0.1508,  0.1939, -0.0108],\n",
      "        [ 0.1858,  0.0296,  0.1239,  0.1185, -0.0485, -0.0242],\n",
      "        [ 0.0323, -0.1454,  0.1912,  0.0242,  0.0565, -0.2504],\n",
      "        [ 0.1023,  0.0188,  0.1750,  0.0916,  0.0700, -0.0727],\n",
      "        [-0.0889, -0.0835,  0.0835,  0.0242,  0.0916,  0.0377],\n",
      "        [-0.0646,  0.0000,  0.0835, -0.0619,  0.1831, -0.0835],\n",
      "        [ 0.0296,  0.1993, -0.0727, -0.1131,  0.1696,  0.1400]], size=(16, 6),\n",
      "       dtype=torch.qint8, quantization_scheme=torch.per_tensor_affine,\n",
      "       scale=0.0026927473954856396, zero_point=0), Parameter containing:\n",
      "tensor([ 0.2174,  0.2079,  0.2203,  0.2020,  0.2175,  0.2507,  0.2002,  0.1526,\n",
      "        -0.0312,  0.1494,  0.1590,  0.0725,  0.1540,  0.1955,  0.1720,  0.1601],\n",
      "       requires_grad=True))), ('cinn.module_list.16.subnet2.lin_2.scale', tensor(0.0109)), ('cinn.module_list.16.subnet2.lin_2.zero_point', tensor(48)), ('cinn.module_list.16.subnet2.lin_2._packed_params.dtype', torch.qint8), ('cinn.module_list.16.subnet2.lin_2._packed_params._packed_params', (tensor([[ 0.0689,  0.1377,  0.2487,  0.1989,  0.2984,  0.1836,  0.1148,  0.0612,\n",
      "         -0.4897,  0.1607,  0.1148,  0.1109,  0.0230,  0.1530,  0.1109,  0.1186],\n",
      "        [ 0.1607,  0.2295,  0.0995,  0.1951,  0.1377,  0.1186,  0.0803,  0.1109,\n",
      "         -0.1492,  0.0612,  0.1569,  0.1607,  0.1913,  0.1492,  0.1339,  0.1530],\n",
      "        [ 0.1263,  0.1530, -0.1263,  0.0842, -0.1722, -0.2104,  0.2028,  0.1530,\n",
      "         -0.0306,  0.1645,  0.0344,  0.1683,  0.0995,  0.1301,  0.2028, -0.1416],\n",
      "        [ 0.1148, -0.0765,  0.1569,  0.0803,  0.1454, -0.1569, -0.1645, -0.2104,\n",
      "         -0.0497, -0.1607,  0.0880,  0.1148,  0.0421,  0.1109, -0.1760, -0.1645]],\n",
      "       size=(4, 16), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.0038258149288594723,\n",
      "       zero_point=0), Parameter containing:\n",
      "tensor([ 0.1931,  0.1800, -0.1385, -0.0489], requires_grad=True)))])\n"
     ]
    }
   ],
   "source": [
    "model_quant = torch.quantization.convert(model_floating, inplace=False)\n",
    "print(\"Converted state dict\")\n",
    "print(model_quant.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model\n",
      "1.0\t0.0\t0.0\t0.0\n",
      "0.0\t1.0\t0.0\t0.0\n",
      "0.0\t0.0\t1.0\t0.0\n",
      "0.0\t0.0\t0.0\t1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAEICAYAAABWCOFPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAchUlEQVR4nO3de5SU9Z3n8feXbu4XoUXu0KggchEIouD1YGQUiQm6cRyYrDHZTEiycc7kbOZM3MmZxNk9Mye7s9nsZDQmOjGGmUSdTEKiGSJo4g2NAiKgREBEhLaBlrvQ3PnuH8+D1tNUdX+rqpsu8PM6p05X1fN5fvWrS3/reaqe+v3M3REROaFDe3dARCqLioKIZKgoiEiGioKIZKgoiEiGioKIZKgoSIaZfcbMFheR32hm09Pzf21m/xxcL5wNtHWzmW02s31m9pHWaPPDTEUhwMxmm9lLZrbfzBrS8//VzKy9+9aUmT1tZn/WHrft7n/v7qHbzs2a2XAzczOrLvGm/w9wh7v3cPdXSmyjVZnZtWa2xswazewpM6tt7z5FqSi0wMy+Cvwj8A/AAKA/8EXgCqDTKe5Lqf80Z7paYHUpK5pZVSv3BTPrC/wC+BugBlgGPNLat9Nm3F2nAifgLGA/8MkWcp1J3q02AduA7wNd02XTgDrgq0ADsAX4bJHrfg3YCvwL0Af4NfAusCs9PyTN/x1wDDgI7APuTq+/EHgC2AmsBW7Nuf2zgUeBvcAS4H8Ci5u5r7cBbwM7gK8DG4Hp6bK7gH/NyX46J/s3hbLpffe0z/uAy4ARwDPAHmA78EiBx31fuu5+4M30+tHA08BukmLxiZx1HgTuBRak60zP024N8COgPn2Mf1nk62Yu8ELO5e7AAeDC9n5NR07aUmjeZSQvvF+1kPtfwAXARJIX82DgGznLB5AUmMHA54B7zKxPEevWkLwbziXZuvtRenkYyYvtbgB3/zrwHB9sSt9hZt1JCsJPgX7AHOB7ZjY2bf8ekiIyEPgv6SkvMxtD8g91GzCIpKAMaSb7PeBTadsn7n8+V6d/e6f9/j1JcVpEUgSHAP/UdCV3P+TuPdKLE9z9fDPrCDyWrtsP+HPgJ2Y2KmfVPyUpoD2BfJ+f/AvQDRibtvGd9D4NM7PdzZz+NF1/LLAyp5/7gTfT6ytfe1elSj4B/xnY2uS6F0jegQ6QvJiN5B3n/JzMZcBb6flpabY6Z3kDMDW47mGgSzN9nAjsyrn8NPBnOZf/BHiuyTo/AL4JVAFHyHkHA/6eAlsKJMXq4ZzL3dP+5Xv3/wbwUE62WzPZ4STv9rmP0TzgPtKtoBaeJwdGpOevItmq6pCz/CHgrvT8g8C8ZtoaCBwH+pTxuvkh8K0m1z0PfKa9X9ORk/ZRm7cD6Gtm1e5+FMDdLwcwszqSd+1zSF7wL+d87mgk/3Dvt3Ni/VQj0CO47rvufvD9hWbdSN65ZpC8iwL0NLMqdz+W5z7UAlPMbHfOddUk74bnpOc35yx7O+8jkRiUm3X3/Wa2I5htbCabz1+RbC0sMbNdwLfd/YHAeoOAze5+POe6t8lupWymsKHATnffVURfm9oH9GpyXS/gvTLaPGW0+9C83wOHgFnNZLaTbAmMdffe6eks/2CztjmRdZv+jPWrwChgirv34oNNbyuQ3ww8k9N+b0820b9E8rnEUZJ/hBOGNdPfLbnZtECd3Ux2SE62azPZk36q6+5b3f3z7j4I+ALJLs+IZvp2Qj0w1MxyX9vDgHeau70cm4EaM+vddEG6+7CvmdOn0uhqYELOet2B8ynxw9BTTUWhGe6+G/hbkhfkLWbWw8w6mNlEkk1n0nek+4HvmFk/ADMbbGbXB9ovZd2eJIVkt5nVkOwG5NoGnJdz+dfABWZ2m5l1TE+XmNnodMviF8BdZtYt/Rzg9mZu+9+BG83sSjPrBPwPCr+G/h34uJldnmb/lg8KV1Pvkmyyv99vM/tjMztRVHaR/CPn2xJq6iWSXbK/Su/rNODjwMOBdXH3LcBvSJ7zPmkbV6fLNqUFtdDpJ2kz84FxZvZJM+tCsiu1yt3XRPrQ3lQUWuDu/xv4bySbsw0k/3Q/IPlG4IU09jVgPfCime0FniR5N48odt3/B3Ql2cp4EXi8yfJ/BG4xs11m9l13fw+4DphN8i66leTDzc5p/g6SXZmtJPvbPyp0w+6+GvgyyYeWW0j+Weuayf45yT/jFpJN5waSLa+m2UaSD/6eTz+wmwpcArxkZvtIvh35C3d/q1Dfcto6DHwCuIHkMfoe8Oki/yFvI/msZU3a568UsS7u/i7wSZL7tAuYQvL4nxYs/RBEpE2ZWQ+SD2hHRv65pf1oS0HajJl9PN0t6U5yLMarJMcqSAVTUZC2NItkl6UeGAnMdm2aVjztPohIhrYURCSjIg9eqqmp8SFD8h49e5I//OEP4XZHjx4dzq5duzacveCCC0K59evXt3qbAGvWxD9Yv/DCC8PZ1avjX6u31WNbTH9ff/31cHbcuHGh3KpVq8JtjhkzJpxtq+ds3bp1odyxY8c4duxY3q+IK3L3Yfz48b5gwYJoNtzukiVLwtlp06aFs4sWLQrlZs1q7hiorN/97nfh7OWXXx7OPv/88+Hs2LHxQ/WXLl0azl599dUth1LF9Peyyy4LZ6P/lEOHDm05lFq+fHk421bP2YwZM0K5rVu3cvjw4bxFQbsPIpJRVlEwsxlmttbM1pvZnXmWm5l9N12+yswmlXN7ItL2Si4K6eAU95AcOTYGmJMeJpvrBpKvokaS/Oz33lJvT0ROjXK2FC4F1rv7hvTQ0oc5+YdDs0h+puru/iLQ28wGlnGbItLGyikKg8n+BLWOkwfRiGQAMLO5ZrbMzJbt3LmzjG6JSDnKKQr5Prls+lVGJJNc6X6fu09298k1NTVldEtEylFOUagj+zv8ISSHsxabEZEKUk5RWAqMNLNz09/Lzyb5iWuuR4FPp99CTAX2pL9XF5EKVfIRje5+1MzuABaSDB/2gLuvNrMvpsu/TzJi7kyS8QIagc+W32URaUsVeURjly5dfPjw4aFsY2NjuN1iPsDs3r17OBt9DLt27Rpu87334sP5nXXWWeHsyJEjw9lNmzaFsx07dgxnGxoawtkePSKj2iWqq+PvcdHDgQcOjH9ZVszzMGxYc6PeZRVzSPSuXbGhJffv31/wMGcd0SgiGSoKIpKhoiAiGSoKIpKhoiAiGSoKIpKhoiAiGSoKIpKhoiAiGSoKIpJRkYc5T5o0yaODVRZzGGoxh+0WM2jp5s3NzWz+gdra2nCbP/vZz8LZthoQ9qabbgpnn3nmmXC2LUYnBrjmmmvC2Z///Oeh3JVXXhluc8WKFeHsqFHRqUZhw4YN4Wx04Na1a9fS2Niow5xFpGUqCiKSoaIgIhkqCiKSoaIgIhkqCiKSoaIgIhnlzBA11MyeMrPXzWy1mf1Fnsw0M9tjZivS0zfK666ItLVypqI/CnzV3ZebWU/gZTN7wt2bzg3/nLvfWMbtiMgpVPKWgrtvcffl6fn3gNcpMPuTiJw+WuUwZzMbDjwLjHP3vTnXTwN+TjIpTD3wl+6+ukAbc0kmoaVjx44XjxnTdK7a/NavXx/uZzH3tXfv3uFsp06dQrl333033OaAAQPC2f3794ezR48eDWej9wvabnTiXr16hbPFjBI9YsSIUO7AgQPhNs3yHjWcV5cuXcLZ1157LZw977zzQrm6ujoOHTqUt8Pl7D4AYGY9SP7xv5JbEFLLgVp332dmM4FfksxAfRJ3vw+4D6Bbt26V94MMkQ+Jsr59MLOOJAXhJ+7+i6bL3X2vu+9Lzy8AOppZ33JuU0TaVjnfPhjwQ+B1d/+/BTID0hxmdml6eztKvU0RaXvl7D5cAdwGvGpmK9Lr/hoYBu9PG3cL8CUzOwocAGZ7Jf5WW0TeV85ckovJP9V8buZu4O5Sb0NETj0d0SgiGSoKIpKhoiAiGSoKIpKhoiAiGRU5mvP48eN9wYIFoWwxI/g++eST4WwxIxkvWrQolDv//PPDbRZzKPDkyZPD2WhfAebMmRPOLl26NJwdMmRIOPvUU0+Fs7feems4Gx19Ono4NBT3nF1wwQXh7Pbt28PZc889N9zmkSNHNJqziLRMRUFEMlQURCRDRUFEMlQURCRDRUFEMlQURCRDRUFEMlQURCSjIo9o7NKliw8fPjyU3blzZ7jd6ur48BGHDh0KZzt0iNXWfv36hdvcvXt3OFuMYgZu7dixYzhbzOPVvXv3cPbYsWPhbF1dXTjbv3//UK6qqirc5sGDB8PZHj16hLNtYevWrQUHbtWWgohkqCiISEa5ozlvNLNX0ynhluVZbmb2XTNbb2arzGxSObcnIm2v7HkfgGvcvdDPuG4gmedhJDAFuDf9KyIVqq13H2YB8zzxItDbzAa28W2KSBnKLQoOLDKzl9Np35oaDGzOuVxHgfkmzWyumS0zs2XFfOIsIq2r3N2HK9y93sz6AU+Y2Rp3fzZneb6vPPJ+B5o7bVyXLl0q73tSkQ+JsrYU3L0+/dsAzAcubRKpA4bmXB5CMtGsiFSocqaN625mPU+cB64Dmk6P+yjw6fRbiKnAHnffUnJvRaTNlbP70B+Yn04VWQ381N0fN7MvwvvTxi0AZgLrgUbgs+V1V0TaWkUe5jxhwgSPDjA6derUcLtvvfVWOHvOOeeEs2vXrg3lhg4d2nIotWLFinB24sSJ4ey+ffvC2dra2nA2OtAuwLXXXhvOLlmyJJydNCl+GMzKlStDuZtvvjnc5rx588LZ8ePHh7OLFy8OZ2fPnh3K1dfX6zBnEYlRURCRDBUFEclQURCRDBUFEclQURCRDBUFEclQURCRDBUFEclQURCRjIo8zLlDhw7euXPnULZPnz7hdo8cORLO9u3bN5zds2dPKFfMSMo9e/YMZ9Pfn4QUM0r0gQMHwtliRsoeNmxYOLtp06ZwtpiRl6MjVe/fvz/cZq9evcLZYl6LZ599dji7fv36UO7YsWO4uw5zFpGWqSiISIaKgohkqCiISIaKgohkqCiISIaKgohklDNw66h0urgTp71m9pUmmWlmticn842yeywibarkgVvdfS0wEcDMqoB3SIZ5b+o5d7+x1NsRkVOrtXYfrgXedPe3W6k9EWknrTHBLMBs4KECyy4zs5Ukk8D8pbuvzhdKp52bCzBw4EB+85vfhG74xhvjGyHr1q0LZ/v16xfO1tfH5re55JJLwm0WM4pxTU1NOLt3795wdvTo0eHs888/H85Onz49nN24cWM4O2bMmHB26dKloVwxo4WvWrUqnL3ooovC2YULF4azM2fODOU2bNhQcFnZWwpm1gn4BPCzPIuXA7XuPgH4J+CXhdpx9/vcfbK7Ty7m9wwi0rpaY/fhBmC5u29rusDd97r7vvT8AqCjmcV/aSQip1xrFIU5FNh1MLMBlv6Ez8wuTW9vRyvcpoi0kbI+UzCzbsAfAV/IuS532rhbgC+Z2VHgADDbK/G32iLyvrKKgrs3Amc3ue77OefvBu4u5zZE5NTSEY0ikqGiICIZKgoikqGiICIZKgoiklGRozlXVVV5ly5dQtnjx4+H273wwgvD2V27doWzbTEycDGj/UYfK4CdO3eGs+edd144u23bSceuFRR9vACmTJkSzr7yyivh7MGDB0O5Dh3i75udOnUKZ4sZ2buYUbVra2tDuTVr1rB//36N5iwiLVNREJEMFQURyVBREJEMFQURyVBREJEMFQURyVBREJEMFQURyVBREJGM1hrNuVWNHz+ep59+OpSdMGFCuN1iRkju2zc+lOSaNWtCuauuuirc5rPPPhvOXn311eFsc6P4NjVt2rRwdvny5eHsxRdfHM7ef//94Wwxh0RHXwvR0ZGhuNGczz777JZDqZdeeimcvemmm0K55n4eoC0FEclosSiY2QNm1mBmr+VcV2NmT5jZG+nfvGOym9kMM1trZuvN7M7W7LiItI3IlsKDwIwm190J/NbdRwK/TS9npFPJ3UMyBPwYYI6ZxWfrEJF20WJRcPdngaa/t50F/Dg9/2PgpjyrXgqsd/cN7n4YeDhdT0QqWKmfKfR39y0A6d98c6wNBjbnXK5LrxORCtaWHzTmG8Ch4IguZjbXzJaZ2bIdOzRfjEh7KbUobDOzgQDp34Y8mTpgaM7lISSTzOaVO5dkMV/XiEjrKrUoPArcnp6/HfhVnsxSYKSZnZtOQjs7XU9EKljkK8mHgN8Do8yszsw+B3wL+CMze4Nk2rhvpdlBZrYAwN2PAncAC4HXgX8rNA29iFSOFo9odPc5BRZdmydbD8zMubwAWFBy70TklKvI0Zw7derkAwYMCGU3b97ccihVzKHLvXr1Cmc3btwYyp111lnhNov5XGXPnj3hbHQUY4Dq6vhR8MVkixlRuqqqKpzt2bNnONu1a9dQLp00PeTw4cPh7DnnnBPOFjPy8+7du0O57du3c+TIEY3mLCItU1EQkQwVBRHJUFEQkQwVBRHJUFEQkQwVBRHJUFEQkQwVBRHJUFEQkYyKPMx5zJgxPm/evFD2+uuvD7f75ptvhrN9+uQddjKv6Ci+H/vYx8JtPv744+Hs2LFjw9k33ngjnJ04cWI4u3LlynB2xIgR4ezWrVvD2dGjR4ez0dGyr7zyynCbL7zwQjhbzEjZmzZtCmcHDRoUyu3du5ejR4/qMGcRaZmKgohkqCiISIaKgohkqCiISIaKgohkqCiISEapc0n+g5mtMbNVZjbfzHoXWHejmb1qZivMbFkr9ltE2kipc0k+AYxz9/HAOuC/N7P+Ne4+0d0nl9ZFETmVSppL0t0XpUO4A7xIMtGLiJwBQoc5m9lw4NfuPi7PsseAR9z9X/MsewvYRTJd3A/c/b5mbmMuMBegQ4cOF/fu3Tt0B4o5HPnYsWPhbFuoqakJZ5cvXx7O1tbWhrPHjx8PZ48cOdIm2WJGtS6m3WJG9o72ITrqM0Dnzp3D2WJG1S5mROtof+vq6jh48GDew5zj43LnYWZfB44CPykQucLd682sH/CEma1JtzxOkhaM+wCqq6sr7wcZIh8SJX/7YGa3AzcCn/ICmxvp5DC4ewMwn2R6ehGpYCUVBTObAXwN+IS7NxbIdDeznifOA9cBr+XLikjlKHUuybuBniS7BCvM7Ptp9v25JIH+wGIzWwksAf7D3eO/BxaRdlHqXJI/LJB9fy5Jd98ATCirdyJyyumIRhHJUFEQkQwVBRHJUFEQkQwVBRHJKOuIxrYybtw4nnzyyVD2qquuCrf74osvhrNTpkwJZ5cuXRrKTZgQ/zJm586dLYdSI0eODGdXr14dzl56afxYs2LaHTfupKPlC1q2LP7j2sGDB4ezb731VihXTF+XLFkSzg4fPjycffnll8PZqVOnhnLNHT6uLQURyVBREJEMFQURyVBREJEMFQURyVBREJEMFQURyVBREJEMFQURyQgN3HqqdevWzUeNGhXK7tu3L9xur169wtn9+/eHs9HBMhsb8w5SldeOHTvC2WIMGRIfeHv79u3h7NGjR1sOpYoZuHXdunXhbP/+/cPZ6HNWzGtm06ZN4Wzfvn3D2WIGhO3Xr18ot2zZMvbu3Zt34FZtKYhIhoqCiGSUOm3cXWb2Tjo+4wozm1lg3RlmttbM1pvZna3ZcRFpG6VOGwfwnXQ6uInuvqDpQjOrAu4BbgDGAHPMbEw5nRWRtlfStHFBlwLr3X2Dux8GHgZmldCOiJxC5XymcEc66/QDZpZv7rbBQO48XnXpdXmZ2VwzW2Zmy4r5JFtEWlepReFe4HxgIrAF+HaeTL6vOwp+/+nu97n7ZHefXF1dkWO/iHwolFQU3H2bux9z9+PA/eSfDq4OGJpzeQhQX8rticipU+q0cQNzLt5M/unglgIjzexcM+sEzAYeLeX2ROTUaXE7PZ02bhrQ18zqgG8C08xsIsnuwEbgC2l2EPDP7j7T3Y+a2R3AQqAKeMDd4wP5iUi7qMjDnC+66CKfP39+KDtp0qRwu6+9Fp/f9vrrrw9nn3rqqVCumIFbFy9eHM5+5CMfCWdXrFgRzkYHAQV49NH4RuCsWfEvoZ555plw9qMf/Wg4G318L7nkknCbxQxeW8xr4bHHHgtnb7nlllCuoaGBw4cP6zBnEWmZioKIZKgoiEiGioKIZKgoiEiGioKIZKgoiEiGioKIZKgoiEiGioKIZFTkYc7V1dUeHUW3Y8eO4XYPHDgQzhYziu+WLVtCucGDCw4ncZKDBw+Gs8WMPxEd7RegmNfG1q1bw9linrP33nsvnC1mpOpOnTqFcnv37g23WczjVcxjUMwo0cOHDw/l6uvrOXTokA5zFpGWqSiISIaKgohkqCiISIaKgohkqCiISIaKgohkRMZofAC4EWhw93HpdY8AJ6aF7g3sdveJedbdCLwHHAOOuvvkVum1iLSZyAQLDwJ3A/NOXOHuf3LivJl9G9jTzPrXuHt8TnMRaVctFgV3f9bMhudbZmYG3ArER8wUkYpW7lRMVwHb3P2NAssdWGRmDvzA3e8r1JCZzQXmAgwaNIjnnnsu1IFiRl1+5513wtnRo0eHs9ERhz//+c+H21y4cGE4O3369HA2Oko2FDc68rZt28LZESNGhLMNDQ3hbFVVVTi7a9euUG7MmPicyEuWLAlnx44dG84Wc/h0bW1tOFtIuR80zgEeamb5Fe4+iWTm6S+b2dWFgrnTxtXU1JTZLREpVclFwcyqgf8EPFIo4+716d8GYD75p5cTkQpSzpbCdGCNu9flW2hm3c2s54nzwHXkn15ORCpIi0UhnTbu98AoM6szs8+li2bTZNfBzAaZ2YL0Yn9gsZmtBJYA/+Huj7de10WkLUS+fZhT4PrP5LmuHpiZnt8AxOfGEpGKoCMaRSRDRUFEMlQURCRDRUFEMlQURCSjIkdzTg+LDhk0aFC43WJG5i1m1ONDhw6Fch06xGtw586dw9n6+vpwtk+fPuFsly5dwtli+ltMH1555ZVwtkePHuFsY2NjKBcd9Rmga9eu4WxbvRaij8HatWtpbGzUaM4i0jIVBRHJUFEQkQwVBRHJUFEQkQwVBRHJUFEQkQwVBRHJUFEQkQwVBRHJqNTDnN8F3m5ydV/gTJw/4ky9X3Dm3rcz4X7Vuvs5+RZUZFHIx8yWnYkzTJ2p9wvO3Pt2pt6vE7T7ICIZKgoiknE6FYWCs0ud5s7U+wVn7n07U+8XcBp9piAip8bptKUgIqeAioKIZFR8UTCzGWa21szWm9md7d2f1mRmG83sVTNbYWbL2rs/pTKzB8yswcxey7muxsyeMLM30r/xMdgqSIH7dpeZvZM+byvMbGZ79rG1VXRRMLMq4B6SWavHAHPMLD43+OnhGnefeJp/7/0gMKPJdXcCv3X3kcBv08unowc5+b4BfCd93ia6+4I8y09bFV0USGapXu/uG9z9MPAwMKud+yRNuPuzwM4mV88Cfpye/zFw06nsU2spcN/OaJVeFAYDm3Mu16XXnSkcWGRmL5vZ3PbuTCvr7+5bANK/8eGxTw93mNmqdPfitNw1KqTSi0K+IajPpO9Qr3D3SSS7R182s6vbu0MSci9wPjAR2AJ8u11708oqvSjUAUNzLg8B4pMcVLh0lm7cvQGYT7K7dKbYZmYDAdK/De3cn1bj7tvc/Zi7Hwfu58x63iq+KCwFRprZuWbWCZgNPNrOfWoVZtbdzHqeOA9cB7zW/FqnlUeB29PztwO/ase+tKoTxS51M2fW80Z1e3egOe5+1MzuABYCVcAD7r66nbvVWvoD880Mkufhp+7+ePt2qTRm9hAwDehrZnXAN4FvAf9mZp8DNgF/3H49LF2B+zbNzCaS7MpuBL7QXv1rCzrMWUQyKn33QUROMRUFEclQURCRDBUFEclQURCRDBUFEclQURCRjP8PX3DXnQAKWfkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Quantized model\")\n",
    "for k in range(4):\n",
    "    show_samples(model_quant, data, config, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_quant.save(\"quantized_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/spack_views/visionary-dls/lib/python3.8/site-packages/torch/quantization/observer.py:121: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "/opt/spack_views/visionary-dls/lib/python3.8/site-packages/torch/quantization/observer.py:243: UserWarning: must run observer before calling calculate_qparams.                                        Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Quantized model\n",
      "1.0\t0.0\t0.0\t0.0\n",
      "0.0\t1.0\t0.0\t0.0\n",
      "0.0\t0.0\t1.0\t0.0\n",
      "0.0\t0.0\t0.0\t1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAEICAYAAABWCOFPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAclUlEQVR4nO3de7RU5Znn8e/DVa5yR26Kg4jAMR4VMEg0OEQHXBp1TLegY0wmPSSZ2KuzJr06Tmd1Ys+s7pWZnnS60xoTY9SkNV6mjZFWNDAuooJcNaCgKMhFjiAX5SIcbgee+WNvTO1j1TnPrjqXgv591qp1qmr/9ltv1al6au+qXe9r7o6IyAkd2rsDIlJdVBREJENFQUQyVBREJENFQUQyVBREJENFQTLM7EtmtjBHfpOZfS49/5dmdl9wvXA20NYNZrbFzPab2YUt0ea/ZSoKAWY208yWmtkBM9uRnv+vZmbt3bfGzOx3ZvYn7XHb7v637h667cKsmY00MzezTmXe9P8Bbnf3nu7++zLbaFFmNs3M1ppZvZktMLOz2rtPUSoKzTCzbwH/CPwdcAYwGPgaMAXo0sZ9KfdFc6o7C1hTzopm1rGF+4KZDQB+DfwV0A9YATzW0rfTatxdpxIn4HTgAHBjM7muJO9W7wLbgZ8A3dJlU4E64FvADmAb8OWc634beB/4Z6Av8DSwE9idnh+e5v8GOAYcAvYDd6XXnwfMBz4E3gL+uOD2+wNzgH3AMuB/AgubuK+3ApuBD4DvAJuAz6XL7gQeKsh+sSD7V6Wy6X33tM/7gcnAOcALwF5gF/BYicd9f7ruAeCd9PqxwO+APSTF4vMF6zwI3APMTdf5XJF2+wEPAFvTx/g3OZ83s4GXCy73AA4C57X3czpy0pZC0yaTPPGeaib3v4BzgVqSJ/Mw4LsFy88gKTDDgK8Ad5tZ3xzr9iN5N5xNsnX3QHr5TJIn210A7v4d4CX+sCl9u5n1ICkIvwIGAbOAH5vZ+LT9u0mKyBDgP6enosxsHMkL6lZgKElBGd5E9sfALWnbJ+5/MZenf/uk/V5MUpzmkRTB4cA/NV7J3Q+7e8/04gXuPsrMOgP/mq47CPhT4GEzG1Ow6s0kBbQXUOzzk38GugPj0zZ+mN6nM81sTxOnm9P1xwOrCvp5AHgnvb76tXdVquYT8J+A9xtd9zLJO9BBkiezkbzjjCrITAY2puenptlOBct3AJ8OrnsEOK2JPtYCuwsu/w74k4LLNwEvNVrnp8D3gI7AUQrewYC/pcSWAkmxerTgco+0f8Xe/b8LPFKQ7d5EdiTJu33hY/RL4F7SraBm/k8OnJOev4xkq6pDwfJHgDvT8w8Cv2yirSHAcaBvBc+bnwPfb3TdIuBL7f2cjpy0j9q0D4ABZtbJ3RsA3P1SADOrI3nXHkjyhH+l4HNHI3nBfdzOifVT9UDP4Lo73f3QxwvNupO8c00neRcF6GVmHd39WJH7cBZwiZntKbiuE8m74cD0/JaCZZuLPhKJoYVZdz9gZh8Es/VNZIv5C5KthWVmthv4gbvfH1hvKLDF3Y8XXLeZ7FbKFkobAXzo7rtz9LWx/UDvRtf1Bj6qoM02o92Hpi0GDgPXNZHZRbIlMN7d+6Sn0/0Pm7VNiazb+Ges3wLGAJe4e2/+sOltJfJbgBcK2u/jySb610k+l2ggeSGccGYT/d1WmE0LVP8mssMLst2ayH7ip7ru/r67/xd3Hwp8lWSX55wm+nbCVmCEmRU+t88E3mvq9gpsAfqZWZ/GC9Ldh/1NnG5Jo2uACwrW6wGMoswPQ9uaikIT3H0P8NckT8gvmFlPM+tgZrUkm86k70g/A35oZoMAzGyYmf2HQPvlrNuLpJDsMbN+JLsBhbYD/67g8tPAuWZ2q5l1Tk8TzWxsumXxa+BOM+uefg5wWxO3/S/ANWb2GTPrAvwPSj+H/gW41swuTbN/zR8KV2M7STbZP+63mf2RmZ0oKrtJXsjFtoQaW0qyS/YX6X2dClwLPBpYF3ffBjxL8j/vm7Zxebrs3bSgljo9nDbzJFBjZjea2Wkku1KvufvaSB/am4pCM9z9fwP/jWRzdgfJi+6nJN8IvJzGvg2sB5aY2T7g/5G8m0fkXfcfgG4kWxlLgOcaLf9H4AtmttvMfuTuHwFXATNJ3kXfJ/lws2uav51kV+Z9kv3tB0rdsLuvAb5B8qHlNpIXa10T2T8leTFuI9l03kGy5dU4W0/ywd+i9AO7TwMTgaVmtp/k25E/c/eNpfpW0NYR4PPADJLH6MfAF3O+IG8l+axlbdrnb+ZYF3ffCdxIcp92A5eQPP4nBUs/BBFpVWbWk+QD2tGRF7e0H20pSKsxs2vT3ZIeJMdivE5yrIJUMRUFaU3XkeyybAVGAzNdm6ZVT7sPIpKhLQURyajKg5f69OnjQ4cODWXffvvtcLvnnXdeOPvmm2+Gs+PHx45efeONN1q8TcjX13POiXzVn3jnnXfC2XPPPTeczfM4jBs3LpxdsyZ+GEBNTU27tQmwevXqVmk3+lxoaGjg+PHjRb8irsrdh3HjxvlDDz0Uyk6bNi3c7uLFi8PZSy65JJxdtWpV8yHgwgvjP/XP80KfNGlSODtnzpxw9sYbbwxn582bF85ecMEFzYdSr732Wjibp5BG30zGjh3b4m1CviKapzhffPHFodyOHTs4cuRI0aKg3QcRyaioKJjZdDN7y8zWm9kdRZabmf0oXf6amV1Uye2JSOsruyikg1PcTXLk2DhgVnqYbKEZJF9FjSb52e895d6eiLSNSrYUJgHr3X1Demjpo3zyh0PXkfxM1d19CdDHzIZUcJsi0soqKQrDyP4EtY5PDqIRyQBgZrPNbIWZrdi9u5JfrYpIJSopCsU+uWz8VUYkk1zpfq+7T3D3CX379i0WEZE2UElRqCP7O/zhJIez5s2ISBWppCgsB0ab2dnp7+VnkvzEtdAc4IvptxCfBvamv1cXkSpV9hGN7t5gZrcDvyUZPux+d19jZl9Ll/+EZMTcq0nGC6gHvlx5l0WkNVXlEY2dO3f2fv36hbIdO8aH7T9w4EA427t34yH2Squvrw/lunXrFm5z2LBSAx9/0ubNTQ2rWH4funSJT2sxYsSI5kOpPEeW5jnMeevW+J7pRx/Fhks87bTTwm3mMXDgwHB2/fr14Wz05wFbt27l8OHDOqJRRJqnoiAiGSoKIpKhoiAiGSoKIpKhoiAiGSoKIpKhoiAiGSoKIpKhoiAiGVV5mPP48eP9scceC2U/+9nPhttduzY+neCZZzY1+XLWK6+8EsrlGWR26dKl4eyUKVPC2QceKDlV5CfcfPPN4ex7773XfCiVZ0TpFStWhLOXXnppOLto0aJQbvDgweE2N26Mz4aXZ5DZdevWhbMTJkwI5Xbt2qWBW0UkRkVBRDJUFEQkQ0VBRDJUFEQkQ0VBRDJUFEQko5IZokaY2QIze9PM1pjZnxXJTDWzvWa2Mj19t7Luikhrq2Qq+gbgW+7+qpn1Al4xs/nu3nie8Zfc/ZoKbkdE2lDZWwruvs3dX03PfwS8SYnZn0Tk5NEihzmb2UjgRaDG3fcVXD8VeIJkUpitwJ+7+5oSbcwmmYSWDh06XJxntNuoPCPz5jlst3v37qHcoEGDwm1GR4iG5JDVqHPPPTeczTNSdp6RlPOMKG1W9Ejcojp37hzO7ty5M5TL85w5evRoOJtntPAjR46Es3n+D+5e9MGtZPcBADPrSfLC/2ZhQUi9Cpzl7vvN7GrgNyQzUBfr4L3AvZAM8V5pv0SkPBV9+2BmnUkKwsPu/uvGy919n7vvT8/PBTqb2YBKblNEWlcl3z4Y8HPgTXf/+xKZM9IcZjYpvb0Pyr1NEWl9lew+TAFuBV43s5XpdX8JnAkfTxv3BeDrZtYAHARmejX+VltEPlbJXJILKT7VfGHmLuCucm9DRNqejmgUkQwVBRHJUFEQkQwVBRHJUFEQkYyKj2hsDWPGjOGJJ54IZa+66qpwuy+88EI4O3LkyHB24cKFodz1118fbjPPYdZ5RgZetmxZODtkyJBwNs9jm+dxePPNN8PZyZMnh7PPPvtsKBcdHRlgy5Yt4eyFF14Yzi5YsCCcrampCeUaGhpKLtOWgohkqCiISIaKgohkqCiISIaKgohkqCiISIaKgohkqCiISIaKgohktMjArS2tU6dOHh3YcuzYseF2V61aFc7mGbQ0OhjqypUrw23mGdx0zJgx4eyKFSvC2YsuuiicPX78eDi7ffv2cHbfvsbDfpZ27NixcHbw4MGh3N69e8NtDhgQH2kwzxGrI0aMCGejj+3+/ftpaGgoOh6KthREJENFQUQyKh3NeZOZvZ5OCfeJ7VJL/MjM1pvZa2YW3x4VkXbREr+SvMLdS81GMoNknofRwCXAPelfEalSrb37cB3wS08sAfqYWfz3uCLS5iotCg7MM7NX0mnfGhsGFP7IvI4S802a2WwzW2FmK6rxGxGRfysq3X2Y4u5bzWwQMN/M1rr7iwXLi33lUfQVXzhtXKdOnVQVRNpJRVsK7r41/bsDeBKY1ChSBxR+yTqcZKJZEalSlUwb18PMep04D1wFrG4UmwN8Mf0W4tPAXnffVnZvRaTVVbL7MBh4Mp0qshPwK3d/zsy+Bh9PGzcXuBpYD9QDX66suyLS2qryMOcJEyZ49HDcUaNGhdt9/PHHw9k8g4vOnz8/lJs2bVq4zd///vfh7MSJE8PZ5cuXh7N5DnN+4403wtnLLrssnM1zWPagQYPC2ejArbfddlu4zSVLloSzo0ePDmfXrVsXzkYPud+zZw9Hjx7VYc4i0jwVBRHJUFEQkQwVBRHJUFEQkQwVBRHJUFEQkQwVBRHJUFEQkQwVBRHJqMrDnLt27epDhw5t8XY3bdoUzuYZQXfnzp2hXM+ePcNtdu3aNZzt1atXOLtnz55wduTIkeFsfX19OLt58+ZwduDAgeFsdARwiPf3wIED4TYPHjwYzuY5JDv6/IL483bt2rUcOHBAhzmLSPNUFEQkQ0VBRDJUFEQkQ0VBRDJUFEQkQ0VBRDIqGbh1TDpd3InTPjP7ZqPMVDPbW5D5bsU9FpFWVfbAre7+FlALYGYdgfdIhnlv7CV3v6bc2xGRttVSuw/TgHfcPX6omohUpZaYYBZgJvBIiWWTzWwVySQwf+7ua4qF0mnnZgMMHz6cZcuWhW64pqYm3MkPPvggnJ0xY0Y4u2rVqlDunHPOCbeZZ9TlPCNaR/sKcP7554ezGzZsCGfzPA6LFy8OZz/zmc+Es88991wod8018Y3cPCNa19bWhrMLFy4MZydNajwfU3GHDx8uuaziLQUz6wJ8Hvi/RRa/Cpzl7hcA/wT8plQ77n6vu09w9wn9+/evtFsiUqaW2H2YAbzq7tsbL3D3fe6+Pz0/F+hsZgNa4DZFpJW0RFGYRYldBzM7w9IppMxsUnp78W14EWlzFX2mYGbdgSuBrxZcVzht3BeAr5tZA3AQmOnV+FttEflYRUXB3euB/o2u+0nB+buAuyq5DRFpWzqiUUQyVBREJENFQUQyVBREJENFQUQyqnI0586dO3vfvn1D2Twj6B46dCiczfO4nHfeeaHcli1bwm2effbZ4ezu3bvD2YaGhnD22LFj4ez27Z84dq2ks846K5zt3LlzOHv06NFwdtu2baHckCFDwm3u378/nM0zsnee/9mRI0dCud27d3P06FGN5iwizVNREJEMFQURyVBREJEMFQURyVBREJEMFQURyVBREJEMFQURyVBREJGMlhrNuUXV1NSwYMGCUPbKK68Mt/voo4+Gs5dffnk4e99994VyN910U7jNOXPmhLOzZs0KZx9++OFwduLEieHsokWLwtmbb745nF26dGk4O3LkyHB29erVoVyevr788svh7NixY8PZvXv3hrOnn356KHf8+PGSy7SlICIZzRYFM7vfzHaY2eqC6/qZ2XwzW5f+LfrrJTObbmZvmdl6M7ujJTsuIq0jsqXwIDC90XV3AM+7+2jg+fRyRjqV3N0kQ8CPA2aZ2biKeisira7ZouDuLwIfNrr6OuAX6flfANcXWXUSsN7dN7j7EeDRdD0RqWLlfqYw2N23AaR/BxXJDAMKBxCoS68TkSrWmh80FhvAoeTIJWY228xWmNmKXbt2tWK3RKQp5RaF7WY2BCD9u6NIpg4YUXB5OMkks0UVziU5YIBmlhNpL+UWhTnAben524CnimSWA6PN7Ox0EtqZ6XoiUsUiX0k+AiwGxphZnZl9Bfg+cKWZrSOZNu77aXaomc0FcPcG4Hbgt8CbwOOlpqEXkerR7BGN7l7qcLlpRbJbgasLLs8F5pbdOxFpc1U7mnOfPn1C2dNOOy3cbocO8b2lPCMZR0fQHThwYLjNzZs3h7NdunQJZ/OMDDx48OBwNs+I0nlGPc7z/Iwe4gvQv3//5kNA7969w23u27cvnM0zmvP69evD2ej9qqur49ChQxrNWUSap6IgIhkqCiKSoaIgIhkqCiKSoaIgIhkqCiKSoaIgIhkqCiKSoaIgIhlVOZrz+PHjmTdvXihbU1MTbvftt98OZydMmBDOLlu2LJQ7//zzw22+++674eywYfGxa9asif8mbcqUKeHs8uXLw9mpU6eGs3lGta6trQ1n161bF8pNmjQp3OYTTzwRzt5www3hbJ5Roq+44opQrqnD+LWlICIZKgoikqGiICIZKgoikqGiICIZKgoikqGiICIZ5c4l+XdmttbMXjOzJ82sT4l1N5nZ62a20sxWtGC/RaSVlDuX5Hygxt0/BbwN/Pcm1r/C3WvdPX40kIi0m7LmknT3eekQ7gBLSCZ6EZFTQGg0ZzMbCTzt7p84ptjM/hV4zN0fKrJsI7CbZLq4n7r7vU3cxmxgNkCHDh0ujo58vH379lAOYOjQoeHshx82nlO3tI4dO4ZyeUZdzjPyc/fu3cPZ48ePh7N5pu/r1q1bOLthw4ZwNs9jlmf06fr6+lAuz8jTeWY269GjRzh76NChcDY6Cvn27ds5cuRI0dGcK/rtg5l9B2gAHi4RmeLuW81sEDDfzNamWx6fkBaMeyEZ4r2SfolI+cr+9sHMbgOuAW7xEpsb6eQwuPsO4EmS6elFpIqVVRTMbDrwbeDz7l50O8zMephZrxPngauA1cWyIlI9yp1L8i6gF8kuwUoz+0ma/XguSWAwsNDMVgHLgGfc/blWuRci0mLKnUvy5yWyH88l6e4bgAsq6p2ItDkd0SgiGSoKIpKhoiAiGSoKIpKhoiAiGVU5mvPYsWPDo/heeuml4XZfeumlcHbatGnh7KJFi0K5s88+O9xmXV1dODto0KBwdvPmzeHsxRdfHM4uXrw4nL388svD2WeeeaZV2p0/f34od+2114bb3LJlSzg7fvz4cHbTpk3hbP/+/UO5pg5315aCiGSoKIhIhoqCiGSoKIhIhoqCiGSoKIhIhoqCiGSoKIhIhoqCiGSEBm5ta926dfNRo0aFshs3bgy326tXr1bJHj16NJQ7cOBAuM0zzzwznM0zGGueIxr79esXzu7ZsyeczfPYnnHGGeFsnvsWHZC1Z8+e4TbzDMba0NDQfKiMPkTv19atWzl8+HDRgVu1pSAiGSoKIpJR7rRxd5rZe+n4jCvN7OoS6043s7fMbL2Z3dGSHReR1lHutHEAP0yng6t197mNF5pZR+BuYAYwDphlZuMq6ayItL6ypo0LmgSsd/cN7n4EeBS4rox2RKQNVfKZwu3prNP3m1nfIsuHAYU/MK9LryvKzGab2QozWxGd+kpEWl65ReEeYBRQC2wDflAkU+zrjpLff7r7ve4+wd0nROdmFJGWV1ZRcPft7n7M3Y8DP6P4dHB1wIiCy8OBreXcnoi0nXKnjRtScPEGik8HtxwYbWZnm1kXYCYQG2NNRNpNs2M0ptPGTQUGmFkd8D1gqpnVkuwObAK+mmaHAve5+9Xu3mBmtwO/BToC97v7mta4EyLScqryMOfa2lp//vnnQ9kJEyaE212yZEk4O3bs2HD2ww9jX87U1NSE23z88cfD2VtuuSWczTPAap5DrRcuXBjOTpkyJZyNDrAKMH16sW/Oi3vxxRdDuTz/s507d4azo0ePDmeXLl0azn7qU58K5err6zl27JgOcxaR5qkoiEiGioKIZKgoiEiGioKIZKgoiEiGioKIZKgoiEiGioKIZKgoiEhGVR7m3KVLFx88eHAom6f/AwYMCGd37doVzpoVPVq0ottfvbrYb8yKGz58eDibZxTh+vr6cDbPGBh5RnM+dOhQONu9e/dwNnrfevfuHW5z06ZN4WzfvsWGICluxIgRzYdS0VG1NZqziISpKIhIhoqCiGSoKIhIhoqCiGSoKIhIhoqCiGRExmi8H7gG2OHuNel1jwFj0kgfYI+71xZZdxPwEXAMaHD3+NhpItIumi0KJNPG3QX88sQV7n7TifNm9gNgbxPrX+Hu8SOBRKRdNVsU3P1FMxtZbJklh/L9MfDvW7hfItJOIlsKTbkM2O7u60osd2CemTnwU3e/t1RDZjYbmA0wZMgQnn766VAHJk6cGO7s2rVrw9k8IxkvWLAglJs8eXK4zY0bN4azF110UTi7cuXKcPbKK68MZ5966qlwdsaMGeHss88+G87OmjUrnF2+fHkoN3To0HCbb731VjgbHXUZ4JVXXglno6+HHTt2lFxW6QeNs4BHmlg+xd0vIpl5+htmdnmpYOG0cXmOCxeRllV2UTCzTsB/BB4rlXH3renfHcCTFJ9eTkSqSCVbCp8D1rp7XbGFZtbDzHqdOA9cRfHp5USkijRbFNJp4xYDY8yszsy+ki6aSaNdBzMbamZz04uDgYVmtgpYBjzj7s+1XNdFpDVEvn0o+umNu3+pyHVbgavT8xuACyrsn4i0MR3RKCIZKgoikqGiICIZKgoikqGiICIZJ/1ozp06xY/U7tq1azj70UcfhbPR0ZTff//9cJt5RlLu2bNnOHvkyJFwtqlDYRvLM5JyniNWoyNlAxw8eDCcjY5qneexPXDgQDh7/vnnh7PvvPNOONutW7dQbtOmTRw6dEijOYtI81QURCRDRUFEMlQURCRDRUFEMlQURCRDRUFEMlQURCRDRUFEMlQURCSjKg9zNrOdwOZGVw8ATsX5I07V+wWn7n07Fe7XWe4+sNiCqiwKxZjZilNxhqlT9X7BqXvfTtX7dYJ2H0QkQ0VBRDJOpqJQcnapk9yper/g1L1vp+r9Ak6izxREpG2cTFsKItIGVBREJKPqi4KZTTezt8xsvZnd0d79aUlmtsnMXjezlWa2or37Uy4zu9/MdpjZ6oLr+pnZfDNbl/49KWcNLnHf7jSz99L/20ozu7o9+9jSqroomFlH4G6SWavHAbPMbFz79qrFXeHutSf5994PAtMbXXcH8Ly7jwaeTy+fjB7kk/cN4Ifp/63W3ecWWX7SquqiQDJL9Xp33+DuR4BHgevauU/SiLu/CHzY6OrrgF+k538BXN+WfWopJe7bKa3ai8IwYEvB5br0ulOFA/PM7BUzm93enWlhg919G0D6d1A796el3W5mr6W7FyflrlEp1V4Uig1BfSp9hzrF3S8i2T36hpld3t4dkpB7gFFALbAN+EG79qaFVXtRqANGFFweDmxtp760uHSWbtx9B/Akye7SqWK7mQ0BSP/GJ5Gocu6+3d2Puftx4GecWv+3qi8Ky4HRZna2mXUBZgJz2rlPLcLMephZrxPngauA1U2vdVKZA9yWnr8NeKod+9KiThS71A2cWv834tMrtQN3bzCz24HfAh2B+919TTt3q6UMBp5MZ0DqBPzK3Z9r3y6Vx8weAaYCA8ysDvge8H3gcTP7CvAu8Eft18PylbhvU82slmRXdhPw1fbqX2vQYc4iklHtuw8i0sZUFEQkQ0VBRDJUFEQkQ0VBRDJUFEQkQ0VBRDL+P+Q85uYhJCaNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cpu_config = CONFIG\n",
    "cpu_config.device = \"cpu\"\n",
    "load_model = EXAMPLEcINN_minimal(cpu_config)\n",
    "load_model.quantize()\n",
    "load_model.load(\"quantized_model.pt\")\n",
    "\n",
    "print(\"Loaded Quantized model\")\n",
    "for k in range(4):\n",
    "    show_samples(load_model, data, config, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Quantized model\n",
      "1.0\t0.0\t0.0\t0.0\n",
      "0.0\t1.0\t0.0\t0.0\n",
      "0.0\t0.0\t1.0\t0.0\n",
      "0.0\t0.0\t0.0\t1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAEICAYAAABWCOFPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcLElEQVR4nO3de5hU9Z3n8feXu9DIRS5yESEBVDDYeEEBL6gRLyFeZpwJ7GziuDHk5j7Js5ln4maeTZydZ2azO5NkJqOJMY4xmU3QxJGMUQbDSryQERCJogQIqAgtV7nKpYGG7/5xDkydpqr7e6qq6YJ8Xs9TT1fV+dSvftVd9e1zTp3z+5m7IyJyVIf27oCI1BYVBRHJUFEQkQwVBRHJUFEQkQwVBRHJUFGQDDP7UzNbkCO/1sw+nF7/ipk9FHxcOBto6zYzW29me8xsfDXa/H2mohBgZtPNbJGZ7TWzLen1z5mZtXffmjOz58zsrvZ4bnf/G3cPPXdh1syGm5mbWacyn/rvgLvdvc7df1NmG1VjZpeZ2Twz225mW83sZ2Y2qL37FaWi0Aoz+xLwD8DfAmcCA4HPAJOBLie4L+V+aE51ZwPLy3mgmXWscl8A+gAPAsNJ+vY+8IM2eJ624e66lLgAvYC9wB+2kutK8t9qHbAZeAA4LV02BWgAvgRsATYCd+Z87JeBTcA/k7zhngK2AjvS60PT/F8Dh4FGYA9wX3r/ucA8YDuwCvjjguc/A3gS2A0sBv4KWNDCa/048A6wDfgLYC3w4XTZvcD/Lch+oiD7P0pl09fuaZ/3ABOBkcDzwC7gPeCxEr/3Pelj9wJvpvefBzwH7CQpFjcXPOYR4LvAnPQxHy7Sbl+SD/GG9Hf88wrfRxcC77f3+znc3/buQC1fgBuAJqBTK7m/Tz9YfYGewC+A/5Uum5K28T+BzsBNwD6gT47H/u/0A3Ba+iH+Q6B7mv9Z4Zs2/TDcVXC7B7AeuBPolL5B3wPGpssfBX6a5s4H3i1VFIAx6YfwyrQ/30z7V+yDfjR7Ocka1d8Bh0pkh6cf7E4FzzWLpOh0ALoBl7fw+3dgZHq9M7AG+Er6vNeQ/Kc+J13+CEmhmXy07SLtPQ08RlKAOwNXpfcPIyk0pS7/qUT/vggsbO/3c/h9394dqOUL8J+BTc3u+/f0DbA//XAYyX+cDxZkJgJvp9enpNnCN/wW4LLgYw8We+MW5OuBHQW3nyNbFD4GvNjsMd8DvgZ0TD+o5xYs+xtKF4WvAo8W3O6R9q/YB/2rwKyCbPcWssM5vij8iGQVfGjg71RYFK4gWavqULB8FnBvev0R4EcttDUIOEJatKvwHhpHsoZ2RXu/n6MXbaO2bBvQz8w6uXsTgLtPAjCzBpL/NP1J3vCvFOx3NJIP3LF2jj4+tQ+oCz52q7s3Hlto1h34FslaTJ/07p5m1tHdDxd5DWcDl5rZzoL7OpFsivRPr68vWPZO0d9EYnBh1t33mtm2YHZfC9li/pxkU2axme0AvuHuDwceNxhY7+5HCu57BxhScHs9pZ0FbHf3HTn6WpSZjQT+DfiCu79YaXsninY0tuwl4ABwSwuZ90jWBMa6e+/00svd6wLtRx7b/DTWLwHnAJe6++kkayuQFJNi+fXA8wXt9/ZkL/1nSfZLNJF8EI4a1kJ/NxZm0wJ1RgvZoQXZ01rIHneqrrtvcvdPuftg4NPAd9IPWWs2AGeZWeF7exjJZlHJ5yuwHuhrZr2bLzCzYenXnqUuf1KQPRv4f8Bfufs/B/pdM1QUWuDuO4G/JHlD3m5mdWbWwczqSVadSf8jfR/4lpkNADCzIWZ2faD9ch7bk6SQ7DSzviSbAYU2Ax8ouP0UMNrMPm5mndPLJWZ2Xrpm8QRwr5l1N7MxwB0tPPfjwDQzu9zMupDsJyn1Hnoc+KiZTUqzf8l/FK7mtpKssh/rt5n9kZkdLSo7SD7IxdaEmltEskn25+lrnQJ8lGTfSavcfSPJf/fvmFmftI0r02Xr0oJa6vLjtO9DgPnA/e7+QOR5a4mKQivc/f8A/41kdXYLyYfueyTfCPx7Gvsyyc6thWa2m+Q/xDnBp8j72L8n2eH4HrAQmNts+T8At5vZDjP7tru/D0wFppP8F93Ef+y4BLibZFNmE8n2dsmvztx9OfB54CckawI7SL4dKZX9ryQfxo0kO/u2kKx5Nc/uI/nm5NdmttPMLgMuARaZ2R6SHbFfcPe3S/WtoK2DwM3AjSS/o+8An3D3la09tsDHSfa1rEz7/MUcjwW4i6TAfa1wTSJnG+3G0p0hIm3KzOpIdtCOiny4pf1oTUHajJl9NN0s6UHyleTrJMcqSA1TUZC2dAvJJssGYBQw3bVqWvO0+SAiGVpTEJGMmjx4qXPnzt61a9fWg8DBgwfD7R46dChPH8LZI0eOtB4C8qyV5Xn+PCdrNjU1tR4qo93o7wDyvbY8v7PDhyPfWCai/W2rE2E7dmyL87Di7/H06MWiL64mi0LXrl2pr68PZdetWxdud/36lg5kyxo4cGA4u3fv3lAuzwcyz/N36RI/WXPr1q3hbLdu3cLZPXvi37gNHjw4nG1sbGw9lIr+HSDe3+g/J8hXGHv16tUm7W7cuDGUa+m9qM0HEcmoqCiY2Q1mtsrM1pjZPUWWm5l9O12+zMwurOT5RKTtlV0U0sEp7ic5cmwMMCM9TLbQjSRfRY0CZpKcxy4iNaySNYUJwBp3fys9tPRRjj9x6BaS01Td3RcCvU+mYalEfh9VUhSGkD0FtYHs6anRDABmNtPMlpjZkjw75ESkuiopCsW+zmj+/VEkk9zp/qC7X+zuF3fqVJNfioj8XqikKDSQPQ9/KMnhrHkzIlJDKikKLwOjzGxEer78dJJTXAs9CXwi/RbiMmBXer66iNSostfT3b3JzO4GniEZPuxhd19uZp9Jlz9AMmLuTSTjBewjGTxURGpYTZ4QddFFF/miRYtC2d69e4fbfffdd1sPpQYMGBDOLlu2LJQbPz4+edGmTZvC2bPPPjucXbhwYTh77rnnhrOvv/56ODtx4sRw9pVXXglnzzknOq5NvL9Tp04Nt7l8eXzqiegRuwBLly4NZ6+/vtUBvwBYsWIFe/fuLXqYs45oFJEMFQURyVBREJEMFQURyVBREJEMFQURyVBREJEMFQURyVBREJEMFQURyajJw5w7dOjg0cFI+/btG243zyjCBw4cN+VhST169Ajl8gzAuWNHfCb0PIc5r127NpzNM+Lw2LFjw9lVq1aFs3nen3nG4WiL99fu3bvD2Ty/29NOOy2cjR4ev2fPHg4fPqzDnEWkdSoKIpKhoiAiGSoKIpKhoiAiGSoKIpKhoiAiGZXMEHWWmf3KzFaY2XIz+0KRzBQz22Vmr6aXr1bWXRFpa5VMsNAEfMndl5pZT+AVM5vn7r9tlnvR3adV8DwicgKVvabg7hvdfWl6/X1gBSVmfxKRk0dVpmIys+HAeKDYEMwTzew1kklg/szdiw55a2YzSSahZdiwYbzzzjuh585ziO+TTzaflqK0SZMmhbPR0XbzjOAbff0AkydPDmdfeumlcHbmzJnh7KxZs8LZUaNGhbNbt24NZy+66KJwdt68eaHcxRdfHG4zz8jTeUa0njt3bjh74403hnItHe5e8Y5GM6sD/gX4ors3P/h7KXC2u18A/CPw81LtFE4b179//0q7JSJlqqgomFlnkoLwY3d/ovlyd9/t7nvS63OAzmbWr5LnFJG2Vcm3Dwb8E7DC3b9ZInNmmsPMJqTPt63c5xSRtlfJPoXJwMeB183s1fS+rwDD4Ni0cbcDnzWzJmA/MN1r8VxtETmmkrkkF1B8qvnCzH3AfeU+h4iceDqiUUQyVBREJENFQUQyVBREJENFQUQyanI0527duvnw4cND2W3b4oc9REfwBdiwYUM4O2zYsFBu37594TbzjOCbZ5ToPH0YNGhQOLt3795w9gMf+EA4u27dunA2z98sPXymVXlGc46OpAwwcODANmm3X7/YsYHbtm3j0KFDGs1ZRFqnoiAiGSoKIpKhoiAiGSoKIpKhoiAiGSoKIpKhoiAiGSoKIpJRlYFbq23UqFHhQVbzDLD69NNPh7N5BkNdsGBBKHfNNdeE23z++efD2QkTJoSzeQYXve2228LZF198MZyNHgEKsGvXrnB2zJgx4eybb74ZyvXq1SvcZkNDQzh74YUXhrM7d+4MZ0eMGBHOlqI1BRHJUFEQkYxKR3Nea2avp1PCLSmy3Mzs22a2xsyWmVl8nUlE2kU19ilc7e7vlVh2IzAqvVwKfDf9KSI1qq03H24BfuSJhUBvM4ufjysiJ1ylRcGBX5rZK+m0b80NAdYX3G6gxHyTZjbTzJaY2ZLt27dX2C0RKVelRWGyu19IspnweTO7stnyYoM4FB3VpXDauDwDW4hIdVVUFNx9Q/pzCzAbaP6FeQNwVsHtoSQTzYpIjapk2rgeZtbz6HVgKvBGs9iTwCfSbyEuA3a5+8ayeysiba6Sbx8GArPTse46AT9x97lm9hk4Nm3cHOAmYA2wD7izsu6KSFur2YFbzzrrrNaDQF1dXbjdxsbGcDbPQKQdOsRWuA4dOhRuM8/O1jyH4uZ5XXmyQ4YU3X9c1ObNm8PZHj16hLN53gs7duwI5fIMsBptE2DPnj3hbJ5Dl6MD3R44cIAjR45o4FYRaZ2KgohkqCiISIaKgohkqCiISIaKgohkqCiISIaKgohkqCiISIaKgohk1ORoziNGjOAHP/hBKPupT30q3O7s2bPD2euvvz6cXbVqVSg3duzYcJvbtm0LZy+55JJw9tVXXw1nr7vuunD2hRdeCGfznBr/3HPPhbN33XVXODt//vxQbsaMGeE2586dG86OGzcunF20aFE4O378+FBuw4bSJytrTUFEMlQURCRDRUFEMlQURCRDRUFEMlQURCRDRUFEMioZuPWcdLq4o5fdZvbFZpkpZrarIPPVinssIm2q7IOX3H0VUA9gZh2Bd0mGeW/uRXefVu7ziMiJVa3Nh2uBN939nSq1JyLtpCqjOZvZw8BSd7+v2f1TgH8hmRRmA/Bn7r68RBszgZnp9YuiIxSffvrp4X4OGDAgnH3rrbfC2e7du4dyeX7XW7duDWcPHz4czn7oQx8KZ1977bVwdtSoUeFsnpGq+/XrF87mGU25S5cuoVzXrl3Dbe7fvz+cff/998PZpqamcHbkyJGh3OrVq9m3b1/bjOZsZl2Am4GfFVm8FDjb3S8A/hH4eal2CqeNiw6ZLiLVV41P340kawnHDebv7rvdfU96fQ7Q2czipV9ETrhqFIUZwKxiC8zsTEunkDKzCenzxU//E5ETrqJTp82sO3Ad8OmC+wqnjbsd+KyZNQH7gelei1NSicgxFRUFd98HnNHsvgcKrt8H3Nf8cSJSu7RHT0QyVBREJENFQUQyVBREJENFQUQyqnKYc7Wdf/75/sQTT4SyH/nIR8Ltzps3L5wdMWJE1du98847w22+9NJL4ezEiRPD2V/84hfh7K233hrOLliwIJy99NJLw9mFCxeGs9Omxc+7i/4ezj///HCbL7/8cjh79dVXh7N53gtXXXVVKLdx40YOHDjQNoc5i8ipRUVBRDJUFEQkQ0VBRDJUFEQkQ0VBRDJUFEQkQ0VBRDJUFEQkQ0VBRDJq8jDnuro6jx5e2tDQEG63Z8+e4WyeEXQ3bz5ueMqizjjjjNZDqbVr14azffv2DWfzjE584MCBcDbPCM1nnnlmOBsd1Rtg1apVVW83zyDC+/btC2fzHEZfV1cXzi5dujSUO3LkCO6uw5xFpHWtFgUze9jMtpjZGwX39TWzeWa2Ov3Zp8RjbzCzVWa2xszuqWbHRaRtRNYUHgFuaHbfPcCz7j4KeDa9nZFOJXc/yRDwY4AZZjamot6KSJtrtSi4+wtA8w3GW4Afptd/CNxa5KETgDXu/pa7HwQeTR8nIjWs3H0KA919I0D6s9h8bEOA9QW3G9L7RKSGVTTEeyuK7dks+VVH4VyS0Xn+RKT6yl1T2GxmgwDSn1uKZBqAswpuDyWZZLaowrkkO3fuXGa3RKRS5RaFJ4E70ut3AP9aJPMyMMrMRqST0E5PHyciNSzyleQs4CXgHDNrMLNPAl8HrjOz1STTxn09zQ42szkA7t4E3A08A6wAflpqGnoRqR2t7lNw9xklFl1bJLsBuKng9hxgTtm9E5ETri13NJZt5MiRPP3006Fs//79w+2uWbMmnJ06dWo4Gz28dvDgweE2f/vb34azN998czi7cuXKcDbPobi//vWvw9np06eHs0899VQ4O2nSpHB2yZIlodzo0aPDbb7xxhuth1JTpkwJZ/OMQj5y5MhQ7uDBgyWX6TBnEclQURCRDBUFEclQURCRDBUFEclQURCRDBUFEclQURCRDBUFEclQURCRjJoczblz587ep0/RYR+PE80BrFu3LpxtbGwMZ6OHL+fp64YNJc8yP06evuY5bHfXrl3h7M6dO8PZ7t27h7NDhw4NZ7dsKXYGf2XZ4cOHh9uMjuoNbfdeiH6eGxsbOXLkiEZzFpHWqSiISIaKgohkqCiISIaKgohkqCiISIaKgohklDuX5N+a2UozW2Zms82sd4nHrjWz183sVTOLjX8lIu2q3Lkk5wHnu/s44HfAf2/h8Ve7e727X1xeF0XkRCprLkl3/2U6hDvAQpKJXkTkFFCN0Zz/C/BYiWUO/NLMHPieuz9YqpHCaeMGDx7Mr371q9CTX3DBBeGO7t+/P5zNM5Lxs88+G8p97GMfC7cZHSEa4LzzzgtnH3rooXD2llvi8wHnOcS3b9++4ezy5fGpQsaNGxfObt/efM7k4s4888xwm4sXLw5n84zAvXr16nB2woQJoVxLh3lXtKPRzP4CaAJ+XCIy2d0vJJmO/vNmdmWptgqnjctzXLiIVFfZRcHM7gCmAX/iJc7CSCeHwd23ALNJpqcXkRpWVlEwsxuALwM3u/u+EpkeZtbz6HVgKhCfLUNE2kW5c0neB/QE5qVfNz6QZo/NJQkMBBaY2WvAYuBpd5/bJq9CRKqm3Lkk/6lE9thcku7+FhDfCygiNUFHNIpIhoqCiGSoKIhIhoqCiGSoKIhIRk2O5pweFh3Sv3//cLt5Dq/t3LlzOPvee++Fcps2bQq3mWfE4zPOOCOczXOo98GDB8PZTp2qccT88Xr37h3OHjhwoOrPv2PHjnA2z8jPu3fvDmfr6urC2aamptZDwPr162lsbNRoziLSOhUFEclQURCRDBUFEclQURCRDBUFEclQURCRDBUFEclQURCRjLY5DK1Co0eP5oEHHghlP/e5z4XbnT9/fjg7bdq0cPb5558P5fIM3Lpo0aJwduzYsW3S7pAhQ8LZI0eOhLMDBw4MZ3/zm9+Es3mO7IwehXrxxfGZCaKDDQNce+214eycOXNaD6Wig9e2dOSj1hREJENFQUQyyp027l4zezcdn/FVM7upxGNvMLNVZrbGzO6pZsdFpG2UO20cwLfS6eDq3f24jR4z6wjcTzLnwxhghpmNqaSzItL2ypo2LmgCsMbd33L3g8CjQHzKIRFpF5XsU7g7nXX6YTMrNqXTEGB9we2G9L6izGymmS0xsyW7du2qoFsiUolyi8J3gQ8C9cBG4BtFMsUGcCg5eErhtHG9evUqs1siUqmyioK7b3b3w+5+BPg+xaeDawDOKrg9FNhQzvOJyIlT7rRxgwpu3kbx6eBeBkaZ2Qgz6wJMB54s5/lE5MRp9YjGdNq4KUA/M2sAvgZMMbN6ks2BtcCn0+xg4CF3v8ndm8zsbuAZoCPwsLvH5xUXkXZRkwO3durUyU8//fRQtq0G1tyyZUs4O3LkyFDu7bffDreZZ4DVbt26hbN5BmMdNGhQ66HUnj17wtlt27aFs126dAln8wzM29jYGM5G9ejRI5w9dOhQOLt9e/zLv65du4Zy+/fv5/Dhwxq4VURap6IgIhkqCiKSoaIgIhkqCiKSoaIgIhkqCiKSoaIgIhkqCiKSoaIgIhk1OZpzfX09S5YsCWX79Ck2lENxixcvDmevuOKKcPbRRx8N5S6//PJwm3lG8J0+fXo4+7vf/S6cHTx4cDi7Zs2acPaCCy4IZ1977bVwNs8IyY899lgod9VVV4XbbGhoCGfzjDz9xhvFzjcsLjoK+fr160su05qCiGSoKIhIhoqCiGSoKIhIhoqCiGSoKIhIhoqCiGRExmh8GJgGbHH389P7HgPOSSO9gZ3uXl/ksWuB94HDQJO7x6fwFZF2ETl46RHgPuBHR+9w92NzqpvZN4CWZm+52t1j836LSLtrtSi4+wtmNrzYMjMz4I+Ba6rcLxFpJ6HRnNOi8NTRzYeC+68Evllqs8DM3gZ2kAwF/z13f7CF55gJzATo2LHjRQMGDAi9gL1794Zyabvh7JAhJWe4O050JOM8IynX1dWFsx06xHcN5elDnuzhw4fD2bbSFu+FESNGhNvM8/vatGlTOJv8742Jjuy9adMmDh48WLThSs99mAHMamH5ZHffYGYDgHlmtjKdsPY4acF4EKBLly61N+68yO+Jsr99MLNOwB8AJc8scfcN6c8twGyKTy8nIjWkkq8kPwysdPeip4aZWQ8z63n0OjCV4tPLiUgNabUopNPGvQScY2YNZvbJdNF0mm06mNlgMzt6zu9AYIGZvQYsBp5297nV67qItIXItw8zStz/p0Xu2wDclF5/C4ifOC8iNUFHNIpIhoqCiGSoKIhIhoqCiGSoKIhIRk2O5jx69Ggef/zxUHbChPjxUC+8UPRgyqJuv/32cHbFihWh3Pjx48NtPvPMM+HspEmTwtlly5aFs2PHjg1n33777XC2V69e4ezGjRvD2fr6+nB25cqVoVye38H8+fPD2YkTJ4azq1evDmfHjRsXyrV06LTWFEQkQ0VBRDJUFEQkQ0VBRDJUFEQkQ0VBRDJUFEQkQ0VBRDJUFEQkQ0VBRDJCozmfaGa2FXin2d39gFNx/ohT9XXBqfvaToXXdba79y+2oCaLQjFmtuRUnGHqVH1dcOq+tlP1dR2lzQcRyVBREJGMk6kolJxd6iR3qr4uOHVf26n6uoCTaJ+CiJwYJ9OagoicACoKIpJR80XBzG4ws1VmtsbM7mnv/lSTma01s9fN7FUzW9Le/SmXmT1sZlvM7I2C+/qa2TwzW53+7NOefSxXidd2r5m9m/7dXjWzm9qzj9VW00XBzDoC9wM3AmOAGWY2pn17VXVXu3v9Sf699yPADc3uuwd41t1HAc+mt09Gj3D8awP4Vvp3q3f3OUWWn7RquiiQzFK9xt3fcveDwKPALe3cJ2nG3V8Atje7+xbgh+n1HwK3nsg+VUuJ13ZKq/WiMARYX3C7Ib3vVOHAL83sFTOb2d6dqbKB7r4RIP05oJ37U213m9mydPPipNw0KqXWi0KxcahPpe9QJ7v7hSSbR583syvbu0MS8l3gg0A9sBH4Rrv2pspqvSg0AGcV3B4KbGinvlRdOks37r4FmE2yuXSq2GxmgwDSn1vauT9V4+6b3f2wux8Bvs+p9Xer+aLwMjDKzEaYWRdgOvBkO/epKsysh5n1PHodmAq80fKjTipPAnek1+8A/rUd+1JVR4td6jZOrb9bbc4QdZS7N5nZ3cAzQEfgYXdf3s7dqpaBwOx0pp5OwE/cfW77dqk8ZjYLmAL0M7MG4GvA14GfmtkngXXAH7VfD8tX4rVNMbN6kk3ZtcCn26t/bUGHOYtIRq1vPojICaaiICIZKgoikqGiICIZKgoikqGiICIZKgoikvH/ARgDqNFlcTJ0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Loaded Quantized model\")\n",
    "for k in range(4):\n",
    "    show_samples(load_model, data, config, k)\n",
    "\n",
    "\n",
    "def calib_func(model, data=data, config=config):\n",
    "    for k in range(4):\n",
    "        show_samples(model, data, config, k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
